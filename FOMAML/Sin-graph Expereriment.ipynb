{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Sine Wave Regression\n",
    "$$f_\\tau(x)=a\\sin(x+b)\\ ; \\ \\tau=(a,b)$$\n",
    "which $a\\sim U([0.1,5])$ and $b\\sim U([0,2\\pi])$. In order to train the network, we will sample a few points $x_1,x_2,\\ldots,x_p\\sim U([-5,5])$\n",
    "\n",
    "Finally, our model will predict the values which minimize the loss\n",
    "$$L(f)=\\int_{-5}^{5}dx||f(x)-f_\\tau(x)||^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29ea5516710>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29ea3492e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.uniform(0.1, 5)\n",
    "b = np.random.uniform(0, 2*np.pi)\n",
    "X_plot = np.linspace(-5,5,1000)\n",
    "Y = a * np.sin(X_plot + b)\n",
    "plt.plot(X_plot, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_forward_norm(x,w,b, is_train, scope, norm, activation_fn=tf.nn.relu):\n",
    "    h = tf.matmul(x, w) + b\n",
    "    if norm:\n",
    "        h = tf.contrib.layers.batch_norm(h, activation_fn=activation_fn, reuse=True, is_training=is_train)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_forward(x,w,b, activation_fn=tf.nn.elu):\n",
    "    h = tf.matmul(x, w) + b\n",
    "    return activation_fn(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "layers_dim = [1,64,64,1]\n",
    "xavier_initializer = tf.contrib.layers.xavier_initializer()\n",
    "zero_initializer = tf.zeros_initializer()\n",
    "weights = [tf.get_variable('w_'+str(i), shape=layers_dim[i:i+2], initializer=xavier_initializer) for i in range(len(layers_dim) - 1)]\n",
    "biases = [tf.get_variable('b_'+str(i), shape=[layers_dim[i+1]], initializer=zero_initializer) for i in range(len(layers_dim) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FOMAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'sub:0' shape=<unknown> dtype=float32>, <tf.Tensor 'sub_2:0' shape=<unknown> dtype=float32>, <tf.Tensor 'sub_4:0' shape=<unknown> dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# MAML\n",
    "UPDATED_TIMES = 32\n",
    "x_train = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "x_val = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "y_train = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "y_val = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "lr1 = tf.placeholder(dtype=tf.float32)\n",
    "lr2 = tf.placeholder(dtype=tf.float32)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr2)\n",
    "\n",
    "new_weights = [None, None, None]\n",
    "new_biases = [None, None, None]\n",
    "losses_col = []\n",
    "grads_col = []\n",
    "for i in range(UPDATED_TIMES):\n",
    "    if i == 0: # First Update\n",
    "        for j in range(len(layers_dim) - 1):\n",
    "            if j == 0: hidden = dense_forward(x_train, weights[j], biases[j])\n",
    "            elif j == len(layers_dim) - 2: hidden = dense_forward(hidden, weights[j], biases[j], lambda x:x)\n",
    "            else: hidden = dense_forward(hidden, weights[j], biases[j])\n",
    "#             if j == 0: hidden = dense_forward(x_train, weights[j], biases[j], True, str(j), True)\n",
    "#             elif j == len(layers_dim) - 2: hidden = dense_forward(hidden, weights[j], biases[j], True, str(j), False)\n",
    "#             else: hidden = dense_forward(hidden, weights[j], biases[j], True, str(j), True)\n",
    "        loss = tf.losses.mean_squared_error(y_train, hidden)\n",
    "        weights_grads = tf.gradients(loss, weights)\n",
    "        biases_grads = tf.gradients(loss, biases)\n",
    "        for j in range(len(layers_dim) - 1):\n",
    "            new_weights[j] = weights[j] - lr1 * weights_grads[j]\n",
    "            new_biases[j] = biases[j] - lr1 * biases_grads[j]\n",
    "        print(new_weights)\n",
    "    \n",
    "    else:\n",
    "        for j in range(len(layers_dim) - 1):\n",
    "            if j == 0: hidden = dense_forward(x_train, new_weights[j], new_biases[j])\n",
    "            elif j == len(layers_dim) - 2: hidden = dense_forward(hidden, new_weights[j], new_biases[j], lambda x:x)\n",
    "            else: hidden = dense_forward(hidden, new_weights[j], new_biases[j])\n",
    "#             if j == 0: hidden = dense_forward(x_train, new_weights[j], new_biases[j], True, str(j), True)\n",
    "#             elif j == len(layers_dim) - 2: hidden = dense_forward(hidden, new_weights[j], new_biases[j], True, str(j), False)\n",
    "#             else: hidden = dense_forward(hidden, new_weights[j], new_biases[j], True, str(j), True)\n",
    "        loss = tf.losses.mean_squared_error(y_train, hidden)\n",
    "        weights_grads = tf.gradients(loss, new_weights)\n",
    "        biases_grads = tf.gradients(loss, new_biases)\n",
    "        for j in range(len(layers_dim) - 1):\n",
    "            new_weights[j] = new_weights[j] - lr1 * weights_grads[j]\n",
    "            new_biases[j] = new_biases[j] - lr1 * biases_grads[j]\n",
    "    losses_col.append(loss)\n",
    "    grads_col.append((weights_grads, biases_grads))\n",
    "    \n",
    "for j in range(len(layers_dim) - 1):\n",
    "    if j == 0: hidden = dense_forward(x_val, new_weights[j], new_biases[j])\n",
    "    elif j == len(layers_dim) - 2: hidden = dense_forward(hidden, new_weights[j], new_biases[j], lambda x:x)\n",
    "    else: hidden = dense_forward(hidden, new_weights[j], new_biases[j])\n",
    "        \n",
    "batch_norm_updater = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "loss = tf.losses.mean_squared_error(y_val, hidden)\n",
    "updater = tf.group([optimizer.minimize(loss), batch_norm_updater])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 - loss: 4.025770664215088\n",
      "Sample 1 - loss: 10.4058837890625\n",
      "Sample 2 - loss: 6.911056041717529\n",
      "Sample 3 - loss: 4.511169910430908\n",
      "Sample 4 - loss: 0.4779472053050995\n",
      "Sample 5 - loss: 7.480340957641602\n",
      "Sample 6 - loss: 7.6820783615112305\n",
      "Sample 7 - loss: 4.745568752288818\n",
      "Sample 8 - loss: 1.6212530136108398\n",
      "Sample 9 - loss: 4.528254985809326\n",
      "Sample 10 - loss: 5.439282417297363\n",
      "Sample 11 - loss: 12.928426742553711\n",
      "Sample 12 - loss: 1.039608120918274\n",
      "Sample 13 - loss: 0.6197744607925415\n",
      "Sample 14 - loss: 10.613470077514648\n",
      "Sample 15 - loss: 0.4884362518787384\n",
      "Sample 16 - loss: 3.2884092330932617\n",
      "Sample 17 - loss: 1.832098364830017\n",
      "Sample 18 - loss: 2.9140164852142334\n",
      "Sample 19 - loss: 11.993598937988281\n",
      "Sample 20 - loss: 10.734896659851074\n",
      "Sample 21 - loss: 10.455330848693848\n",
      "Sample 22 - loss: 10.335461616516113\n",
      "Sample 23 - loss: 1.9654393196105957\n",
      "Sample 24 - loss: 6.031429290771484\n",
      "Sample 25 - loss: 7.983871936798096\n",
      "Sample 26 - loss: 3.098771095275879\n",
      "Sample 27 - loss: 5.450328826904297\n",
      "Sample 28 - loss: 0.4251554608345032\n",
      "Sample 29 - loss: 1.735408902168274\n",
      "Sample 30 - loss: 0.09656105935573578\n",
      "Sample 31 - loss: 6.115347862243652\n",
      "Sample 32 - loss: 0.0488562285900116\n",
      "Sample 33 - loss: 0.05311889573931694\n",
      "Sample 34 - loss: 9.960224151611328\n",
      "Sample 35 - loss: 0.1377202570438385\n",
      "Sample 36 - loss: 8.832164764404297\n",
      "Sample 37 - loss: 0.3795010447502136\n",
      "Sample 38 - loss: 0.43399059772491455\n",
      "Sample 39 - loss: 5.013769626617432\n",
      "Sample 40 - loss: 7.455416679382324\n",
      "Sample 41 - loss: 6.746600151062012\n",
      "Sample 42 - loss: 8.00322151184082\n",
      "Sample 43 - loss: 0.023003719747066498\n",
      "Sample 44 - loss: 0.2662728428840637\n",
      "Sample 45 - loss: 0.7097094655036926\n",
      "Sample 46 - loss: 3.575030565261841\n",
      "Sample 47 - loss: 1.4640631675720215\n",
      "Sample 48 - loss: 0.996695876121521\n",
      "Sample 49 - loss: 2.9452271461486816\n",
      "Sample 50 - loss: 0.17259357869625092\n",
      "Sample 51 - loss: 0.2144060730934143\n",
      "Sample 52 - loss: 0.032190680503845215\n",
      "Sample 53 - loss: 0.037253011018037796\n",
      "Sample 54 - loss: 0.8762240409851074\n",
      "Sample 55 - loss: 2.665696620941162\n",
      "Sample 56 - loss: 0.06583134829998016\n",
      "Sample 57 - loss: 0.08314235508441925\n",
      "Sample 58 - loss: 0.4167826771736145\n",
      "Sample 59 - loss: 10.052209854125977\n",
      "Sample 60 - loss: 9.763602256774902\n",
      "Sample 61 - loss: 8.7706880569458\n",
      "Sample 62 - loss: 5.8710198402404785\n",
      "Sample 63 - loss: 0.9212793707847595\n",
      "Sample 64 - loss: 6.259425163269043\n",
      "Sample 65 - loss: 0.7833235859870911\n",
      "Sample 66 - loss: 0.030093643814325333\n",
      "Sample 67 - loss: 5.173608303070068\n",
      "Sample 68 - loss: 1.730139970779419\n",
      "Sample 69 - loss: 8.07165241241455\n",
      "Sample 70 - loss: 9.46042251586914\n",
      "Sample 71 - loss: 0.7105900049209595\n",
      "Sample 72 - loss: 1.8010776042938232\n",
      "Sample 73 - loss: 5.7175068855285645\n",
      "Sample 74 - loss: 2.4057443141937256\n",
      "Sample 75 - loss: 8.562777519226074\n",
      "Sample 76 - loss: 8.136801719665527\n",
      "Sample 77 - loss: 9.795547485351562\n",
      "Sample 78 - loss: 1.1071434020996094\n",
      "Sample 79 - loss: 0.13656464219093323\n",
      "Sample 80 - loss: 10.064130783081055\n",
      "Sample 81 - loss: 6.4380574226379395\n",
      "Sample 82 - loss: 0.32134872674942017\n",
      "Sample 83 - loss: 2.751854181289673\n",
      "Sample 84 - loss: 8.765549659729004\n",
      "Sample 85 - loss: 0.12398502975702286\n",
      "Sample 86 - loss: 4.11506462097168\n",
      "Sample 87 - loss: 0.6726047396659851\n",
      "Sample 88 - loss: 0.949634850025177\n",
      "Sample 89 - loss: 3.4820706844329834\n",
      "Sample 90 - loss: 7.0252838134765625\n",
      "Sample 91 - loss: 1.9869394302368164\n",
      "Sample 92 - loss: 0.4543282985687256\n",
      "Sample 93 - loss: 5.112663745880127\n",
      "Sample 94 - loss: 4.33949089050293\n",
      "Sample 95 - loss: 0.43905848264694214\n",
      "Sample 96 - loss: 0.08745653927326202\n",
      "Sample 97 - loss: 0.03691660240292549\n",
      "Sample 98 - loss: 7.487819671630859\n",
      "Sample 99 - loss: 2.7348320484161377\n",
      "Sample 100 - loss: 0.9908387660980225\n",
      "Sample 101 - loss: 0.22094787657260895\n",
      "Sample 102 - loss: 4.872469902038574\n",
      "Sample 103 - loss: 3.6854019165039062\n",
      "Sample 104 - loss: 0.3266322612762451\n",
      "Sample 105 - loss: 3.4117374420166016\n",
      "Sample 106 - loss: 0.41681525111198425\n",
      "Sample 107 - loss: 5.6782708168029785\n",
      "Sample 108 - loss: 1.1404715776443481\n",
      "Sample 109 - loss: 5.937178134918213\n",
      "Sample 110 - loss: 8.791028022766113\n",
      "Sample 111 - loss: 5.353103160858154\n",
      "Sample 112 - loss: 7.80797004699707\n",
      "Sample 113 - loss: 6.965875148773193\n",
      "Sample 114 - loss: 5.5650153160095215\n",
      "Sample 115 - loss: 12.468120574951172\n",
      "Sample 116 - loss: 1.0309932231903076\n",
      "Sample 117 - loss: 0.2468714565038681\n",
      "Sample 118 - loss: 10.225482940673828\n",
      "Sample 119 - loss: 1.1157852411270142\n",
      "Sample 120 - loss: 4.856817245483398\n",
      "Sample 121 - loss: 0.0447416827082634\n",
      "Sample 122 - loss: 0.12320926785469055\n",
      "Sample 123 - loss: 4.842568397521973\n",
      "Sample 124 - loss: 11.265429496765137\n",
      "Sample 125 - loss: 11.838335990905762\n",
      "Sample 126 - loss: 5.793583869934082\n",
      "Sample 127 - loss: 0.1274375170469284\n",
      "Sample 128 - loss: 9.318830490112305\n",
      "Sample 129 - loss: 8.296910285949707\n",
      "Sample 130 - loss: 4.700342178344727\n",
      "Sample 131 - loss: 0.1090172752737999\n",
      "Sample 132 - loss: 8.6458158493042\n",
      "Sample 133 - loss: 0.20533487200737\n",
      "Sample 134 - loss: 8.288005828857422\n",
      "Sample 135 - loss: 5.426592826843262\n",
      "Sample 136 - loss: 4.334480285644531\n",
      "Sample 137 - loss: 7.844020843505859\n",
      "Sample 138 - loss: 3.0082099437713623\n",
      "Sample 139 - loss: 1.310736894607544\n",
      "Sample 140 - loss: 3.5071463584899902\n",
      "Sample 141 - loss: 11.395201683044434\n",
      "Sample 142 - loss: 0.0768282487988472\n",
      "Sample 143 - loss: 1.248393177986145\n",
      "Sample 144 - loss: 2.7853188514709473\n",
      "Sample 145 - loss: 0.09461285918951035\n",
      "Sample 146 - loss: 0.2529171407222748\n",
      "Sample 147 - loss: 10.055357933044434\n",
      "Sample 148 - loss: 12.226873397827148\n",
      "Sample 149 - loss: 3.9485764503479004\n",
      "Sample 150 - loss: 10.041586875915527\n",
      "Sample 151 - loss: 4.832529544830322\n",
      "Sample 152 - loss: 1.1316102743148804\n",
      "Sample 153 - loss: 4.297342777252197\n",
      "Sample 154 - loss: 1.8447016477584839\n",
      "Sample 155 - loss: 4.8037214279174805\n",
      "Sample 156 - loss: 7.230289936065674\n",
      "Sample 157 - loss: 0.2248907834291458\n",
      "Sample 158 - loss: 10.603257179260254\n",
      "Sample 159 - loss: 2.548612117767334\n",
      "Sample 160 - loss: 0.035905059427022934\n",
      "Sample 161 - loss: 0.04198164492845535\n",
      "Sample 162 - loss: 8.132225036621094\n",
      "Sample 163 - loss: 2.4804165363311768\n",
      "Sample 164 - loss: 3.0166189670562744\n",
      "Sample 165 - loss: 3.5582275390625\n",
      "Sample 166 - loss: 9.840017318725586\n",
      "Sample 167 - loss: 3.237246036529541\n",
      "Sample 168 - loss: 2.9014499187469482\n",
      "Sample 169 - loss: 10.642350196838379\n",
      "Sample 170 - loss: 0.45636844635009766\n",
      "Sample 171 - loss: 1.0813028812408447\n",
      "Sample 172 - loss: 8.172492980957031\n",
      "Sample 173 - loss: 3.1958911418914795\n",
      "Sample 174 - loss: 5.684919357299805\n",
      "Sample 175 - loss: 0.04004829749464989\n",
      "Sample 176 - loss: 1.9696635007858276\n",
      "Sample 177 - loss: 0.9256505370140076\n",
      "Sample 178 - loss: 2.068843364715576\n",
      "Sample 179 - loss: 0.401062935590744\n",
      "Sample 180 - loss: 4.857640266418457\n",
      "Sample 181 - loss: 0.49279606342315674\n",
      "Sample 182 - loss: 1.3299816846847534\n",
      "Sample 183 - loss: 6.295651435852051\n",
      "Sample 184 - loss: 0.5154567956924438\n",
      "Sample 185 - loss: 0.01868397742509842\n",
      "Sample 186 - loss: 8.34554386138916\n",
      "Sample 187 - loss: 0.034144703298807144\n",
      "Sample 188 - loss: 3.1747450828552246\n",
      "Sample 189 - loss: 5.795694351196289\n",
      "Sample 190 - loss: 7.3305344581604\n",
      "Sample 191 - loss: 3.0995864868164062\n",
      "Sample 192 - loss: 7.175136566162109\n",
      "Sample 193 - loss: 1.221597671508789\n",
      "Sample 194 - loss: 3.276406764984131\n",
      "Sample 195 - loss: 0.06136814504861832\n",
      "Sample 196 - loss: 0.20430821180343628\n",
      "Sample 197 - loss: 0.15118391811847687\n",
      "Sample 198 - loss: 10.226924896240234\n",
      "Sample 199 - loss: 2.584390163421631\n",
      "Sample 200 - loss: 8.358086585998535\n",
      "Sample 201 - loss: 0.04826495051383972\n",
      "Sample 202 - loss: 0.9151521921157837\n",
      "Sample 203 - loss: 5.567523002624512\n",
      "Sample 204 - loss: 1.014122724533081\n",
      "Sample 205 - loss: 2.0313467979431152\n",
      "Sample 206 - loss: 11.172242164611816\n",
      "Sample 207 - loss: 3.671861171722412\n",
      "Sample 208 - loss: 8.194287300109863\n",
      "Sample 209 - loss: 2.5733046531677246\n",
      "Sample 210 - loss: 5.005110740661621\n",
      "Sample 211 - loss: 8.02164077758789\n",
      "Sample 212 - loss: 9.86623764038086\n",
      "Sample 213 - loss: 2.2371933460235596\n",
      "Sample 214 - loss: 7.583217144012451\n",
      "Sample 215 - loss: 0.8274672031402588\n",
      "Sample 216 - loss: 0.47915658354759216\n",
      "Sample 217 - loss: 5.310479640960693\n",
      "Sample 218 - loss: 10.502921104431152\n",
      "Sample 219 - loss: 4.092857360839844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 220 - loss: 8.876261711120605\n",
      "Sample 221 - loss: 9.592684745788574\n",
      "Sample 222 - loss: 10.434731483459473\n",
      "Sample 223 - loss: 9.432300567626953\n",
      "Sample 224 - loss: 1.1498241424560547\n",
      "Sample 225 - loss: 1.228346586227417\n",
      "Sample 226 - loss: 4.386404991149902\n",
      "Sample 227 - loss: 0.15107254683971405\n",
      "Sample 228 - loss: 11.288046836853027\n",
      "Sample 229 - loss: 11.138288497924805\n",
      "Sample 230 - loss: 4.134504795074463\n",
      "Sample 231 - loss: 10.713698387145996\n",
      "Sample 232 - loss: 6.036017894744873\n",
      "Sample 233 - loss: 1.178856372833252\n",
      "Sample 234 - loss: 1.6559869050979614\n",
      "Sample 235 - loss: 9.588109970092773\n",
      "Sample 236 - loss: 1.7596697807312012\n",
      "Sample 237 - loss: 7.469331741333008\n",
      "Sample 238 - loss: 12.108242988586426\n",
      "Sample 239 - loss: 0.13124747574329376\n",
      "Sample 240 - loss: 8.007889747619629\n",
      "Sample 241 - loss: 5.445522308349609\n",
      "Sample 242 - loss: 0.06478976458311081\n",
      "Sample 243 - loss: 6.8236165046691895\n",
      "Sample 244 - loss: 0.06621713936328888\n",
      "Sample 245 - loss: 9.342547416687012\n",
      "Sample 246 - loss: 0.05776991695165634\n",
      "Sample 247 - loss: 0.8830863237380981\n",
      "Sample 248 - loss: 3.4684343338012695\n",
      "Sample 249 - loss: 0.7326018810272217\n",
      "Sample 250 - loss: 3.324458599090576\n",
      "Sample 251 - loss: 0.11545887589454651\n",
      "Sample 252 - loss: 1.8220603466033936\n",
      "Sample 253 - loss: 3.26462459564209\n",
      "Sample 254 - loss: 2.446439743041992\n",
      "Sample 255 - loss: 1.8931100368499756\n",
      "Sample 256 - loss: 2.349532127380371\n",
      "Sample 257 - loss: 4.935129165649414\n",
      "Sample 258 - loss: 3.9513046741485596\n",
      "Sample 259 - loss: 8.849164009094238\n",
      "Sample 260 - loss: 1.9203344583511353\n",
      "Sample 261 - loss: 0.10279033333063126\n",
      "Sample 262 - loss: 0.6994217038154602\n",
      "Sample 263 - loss: 3.754051446914673\n",
      "Sample 264 - loss: 0.12612123787403107\n",
      "Sample 265 - loss: 0.08276824653148651\n",
      "Sample 266 - loss: 5.601937770843506\n",
      "Sample 267 - loss: 3.5666396617889404\n",
      "Sample 268 - loss: 2.028514862060547\n",
      "Sample 269 - loss: 2.6969985961914062\n",
      "Sample 270 - loss: 2.4920270442962646\n",
      "Sample 271 - loss: 9.5447416305542\n",
      "Sample 272 - loss: 0.005889254156500101\n",
      "Sample 273 - loss: 1.6612986326217651\n",
      "Sample 274 - loss: 1.8457494974136353\n",
      "Sample 275 - loss: 0.330784410238266\n",
      "Sample 276 - loss: 2.431411027908325\n",
      "Sample 277 - loss: 1.4038364887237549\n",
      "Sample 278 - loss: 0.2168074995279312\n",
      "Sample 279 - loss: 0.7584276795387268\n",
      "Sample 280 - loss: 9.368396759033203\n",
      "Sample 281 - loss: 1.1564815044403076\n",
      "Sample 282 - loss: 3.765878200531006\n",
      "Sample 283 - loss: 8.805440902709961\n",
      "Sample 284 - loss: 9.432150840759277\n",
      "Sample 285 - loss: 6.864434719085693\n",
      "Sample 286 - loss: 8.4030122756958\n",
      "Sample 287 - loss: 1.930679440498352\n",
      "Sample 288 - loss: 2.3117916584014893\n",
      "Sample 289 - loss: 11.467388153076172\n",
      "Sample 290 - loss: 10.45569133758545\n",
      "Sample 291 - loss: 0.1514299213886261\n",
      "Sample 292 - loss: 0.09707598388195038\n",
      "Sample 293 - loss: 1.9863356351852417\n",
      "Sample 294 - loss: 7.3115644454956055\n",
      "Sample 295 - loss: 1.8582855463027954\n",
      "Sample 296 - loss: 2.689136266708374\n",
      "Sample 297 - loss: 0.2293914258480072\n",
      "Sample 298 - loss: 2.3812551498413086\n",
      "Sample 299 - loss: 0.07521554082632065\n",
      "Sample 300 - loss: 10.859630584716797\n",
      "Sample 301 - loss: 11.560489654541016\n",
      "Sample 302 - loss: 0.09947854280471802\n",
      "Sample 303 - loss: 11.389426231384277\n",
      "Sample 304 - loss: 6.037928581237793\n",
      "Sample 305 - loss: 3.9471776485443115\n",
      "Sample 306 - loss: 0.6492791771888733\n",
      "Sample 307 - loss: 9.801263809204102\n",
      "Sample 308 - loss: 0.6114840507507324\n",
      "Sample 309 - loss: 9.166175842285156\n",
      "Sample 310 - loss: 1.6826978921890259\n",
      "Sample 311 - loss: 1.0450527667999268\n",
      "Sample 312 - loss: 11.704272270202637\n",
      "Sample 313 - loss: 10.295526504516602\n",
      "Sample 314 - loss: 0.2013019323348999\n",
      "Sample 315 - loss: 3.195547580718994\n",
      "Sample 316 - loss: 1.9699517488479614\n",
      "Sample 317 - loss: 11.207221984863281\n",
      "Sample 318 - loss: 9.194525718688965\n",
      "Sample 319 - loss: 4.963670253753662\n",
      "Sample 320 - loss: 5.590236663818359\n",
      "Sample 321 - loss: 11.780777931213379\n",
      "Sample 322 - loss: 3.4626986980438232\n",
      "Sample 323 - loss: 1.4440078735351562\n",
      "Sample 324 - loss: 2.6031877994537354\n",
      "Sample 325 - loss: 11.793865203857422\n",
      "Sample 326 - loss: 0.8244283199310303\n",
      "Sample 327 - loss: 10.188339233398438\n",
      "Sample 328 - loss: 5.377862453460693\n",
      "Sample 329 - loss: 0.2039233148097992\n",
      "Sample 330 - loss: 9.915224075317383\n",
      "Sample 331 - loss: 0.5854238271713257\n",
      "Sample 332 - loss: 0.868736207485199\n",
      "Sample 333 - loss: 1.4943116903305054\n",
      "Sample 334 - loss: 11.247254371643066\n",
      "Sample 335 - loss: 0.5775370597839355\n",
      "Sample 336 - loss: 5.432981014251709\n",
      "Sample 337 - loss: 9.650603294372559\n",
      "Sample 338 - loss: 0.05725283548235893\n",
      "Sample 339 - loss: 7.358083724975586\n",
      "Sample 340 - loss: 0.1207287609577179\n",
      "Sample 341 - loss: 4.174901008605957\n",
      "Sample 342 - loss: 1.2979694604873657\n",
      "Sample 343 - loss: 7.190001010894775\n",
      "Sample 344 - loss: 12.582032203674316\n",
      "Sample 345 - loss: 7.599484443664551\n",
      "Sample 346 - loss: 0.1703554391860962\n",
      "Sample 347 - loss: 0.5687593221664429\n",
      "Sample 348 - loss: 0.40191134810447693\n",
      "Sample 349 - loss: 1.2361350059509277\n",
      "Sample 350 - loss: 9.170422554016113\n",
      "Sample 351 - loss: 5.394215106964111\n",
      "Sample 352 - loss: 5.854459762573242\n",
      "Sample 353 - loss: 10.497933387756348\n",
      "Sample 354 - loss: 1.8087553977966309\n",
      "Sample 355 - loss: 0.30014634132385254\n",
      "Sample 356 - loss: 11.208233833312988\n",
      "Sample 357 - loss: 4.553170204162598\n",
      "Sample 358 - loss: 2.0364856719970703\n",
      "Sample 359 - loss: 3.1242058277130127\n",
      "Sample 360 - loss: 6.912804126739502\n",
      "Sample 361 - loss: 2.3605027198791504\n",
      "Sample 362 - loss: 0.1145913377404213\n",
      "Sample 363 - loss: 0.02140073850750923\n",
      "Sample 364 - loss: 3.5269827842712402\n",
      "Sample 365 - loss: 0.16036804020404816\n",
      "Sample 366 - loss: 0.26756054162979126\n",
      "Sample 367 - loss: 6.500992298126221\n",
      "Sample 368 - loss: 1.0731981992721558\n",
      "Sample 369 - loss: 0.20519141852855682\n",
      "Sample 370 - loss: 3.5489654541015625\n",
      "Sample 371 - loss: 2.0752058029174805\n",
      "Sample 372 - loss: 0.03436538577079773\n",
      "Sample 373 - loss: 11.086416244506836\n",
      "Sample 374 - loss: 8.452616691589355\n",
      "Sample 375 - loss: 3.3656511306762695\n",
      "Sample 376 - loss: 0.0500517338514328\n",
      "Sample 377 - loss: 5.152245044708252\n",
      "Sample 378 - loss: 6.363087177276611\n",
      "Sample 379 - loss: 1.0319857597351074\n",
      "Sample 380 - loss: 4.943541526794434\n",
      "Sample 381 - loss: 7.684366226196289\n",
      "Sample 382 - loss: 4.877819538116455\n",
      "Sample 383 - loss: 0.2357330173254013\n",
      "Sample 384 - loss: 1.0419602394104004\n",
      "Sample 385 - loss: 0.03556784242391586\n",
      "Sample 386 - loss: 0.6746680736541748\n",
      "Sample 387 - loss: 3.2595674991607666\n",
      "Sample 388 - loss: 5.871610164642334\n",
      "Sample 389 - loss: 0.317860871553421\n",
      "Sample 390 - loss: 0.9269607663154602\n",
      "Sample 391 - loss: 1.4192579984664917\n",
      "Sample 392 - loss: 6.99317741394043\n",
      "Sample 393 - loss: 0.21051454544067383\n",
      "Sample 394 - loss: 0.9400212168693542\n",
      "Sample 395 - loss: 0.6828131675720215\n",
      "Sample 396 - loss: 0.32901084423065186\n",
      "Sample 397 - loss: 3.3991339206695557\n",
      "Sample 398 - loss: 0.13825738430023193\n",
      "Sample 399 - loss: 0.14847208559513092\n",
      "Sample 400 - loss: 12.01956558227539\n",
      "Sample 401 - loss: 1.1520806550979614\n",
      "Sample 402 - loss: 4.9358649253845215\n",
      "Sample 403 - loss: 9.280279159545898\n",
      "Sample 404 - loss: 0.253988116979599\n",
      "Sample 405 - loss: 0.6630635261535645\n",
      "Sample 406 - loss: 3.5794456005096436\n",
      "Sample 407 - loss: 5.012409687042236\n",
      "Sample 408 - loss: 5.146726131439209\n",
      "Sample 409 - loss: 0.8145240545272827\n",
      "Sample 410 - loss: 7.657745361328125\n",
      "Sample 411 - loss: 8.014570236206055\n",
      "Sample 412 - loss: 2.0287537574768066\n",
      "Sample 413 - loss: 4.083738803863525\n",
      "Sample 414 - loss: 7.645322799682617\n",
      "Sample 415 - loss: 13.009511947631836\n",
      "Sample 416 - loss: 6.501565456390381\n",
      "Sample 417 - loss: 2.961533784866333\n",
      "Sample 418 - loss: 6.321618556976318\n",
      "Sample 419 - loss: 11.191851615905762\n",
      "Sample 420 - loss: 8.655074119567871\n",
      "Sample 421 - loss: 2.491318464279175\n",
      "Sample 422 - loss: 11.840638160705566\n",
      "Sample 423 - loss: 0.3219392001628876\n",
      "Sample 424 - loss: 8.435768127441406\n",
      "Sample 425 - loss: 2.442168712615967\n",
      "Sample 426 - loss: 4.160900115966797\n",
      "Sample 427 - loss: 0.5915195345878601\n",
      "Sample 428 - loss: 9.133910179138184\n",
      "Sample 429 - loss: 3.946920394897461\n",
      "Sample 430 - loss: 0.9334284067153931\n",
      "Sample 431 - loss: 6.942541599273682\n",
      "Sample 432 - loss: 10.979118347167969\n",
      "Sample 433 - loss: 5.447089195251465\n",
      "Sample 434 - loss: 0.2789466381072998\n",
      "Sample 435 - loss: 0.29659315943717957\n",
      "Sample 436 - loss: 0.7623111605644226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 437 - loss: 1.2954269647598267\n",
      "Sample 438 - loss: 0.28917795419692993\n",
      "Sample 439 - loss: 1.9442819356918335\n",
      "Sample 440 - loss: 6.061319351196289\n",
      "Sample 441 - loss: 1.418453335762024\n",
      "Sample 442 - loss: 7.823118686676025\n",
      "Sample 443 - loss: 3.8408801555633545\n",
      "Sample 444 - loss: 0.8344408273696899\n",
      "Sample 445 - loss: 0.12230350822210312\n",
      "Sample 446 - loss: 5.483614444732666\n",
      "Sample 447 - loss: 1.2492667436599731\n",
      "Sample 448 - loss: 3.9824953079223633\n",
      "Sample 449 - loss: 0.5234614014625549\n",
      "Sample 450 - loss: 0.28176870942115784\n",
      "Sample 451 - loss: 12.19175910949707\n",
      "Sample 452 - loss: 1.2868835926055908\n",
      "Sample 453 - loss: 9.718611717224121\n",
      "Sample 454 - loss: 0.0773186907172203\n",
      "Sample 455 - loss: 7.162784576416016\n",
      "Sample 456 - loss: 3.2251172065734863\n",
      "Sample 457 - loss: 0.13649635016918182\n",
      "Sample 458 - loss: 1.6703627109527588\n",
      "Sample 459 - loss: 0.529997706413269\n",
      "Sample 460 - loss: 0.03181826323270798\n",
      "Sample 461 - loss: 2.9124841690063477\n",
      "Sample 462 - loss: 0.2852935492992401\n",
      "Sample 463 - loss: 0.7694664001464844\n",
      "Sample 464 - loss: 0.46397149562835693\n",
      "Sample 465 - loss: 4.037907123565674\n",
      "Sample 466 - loss: 8.595250129699707\n",
      "Sample 467 - loss: 1.3483883142471313\n",
      "Sample 468 - loss: 7.0526933670043945\n",
      "Sample 469 - loss: 0.6420719027519226\n",
      "Sample 470 - loss: 0.06434938311576843\n",
      "Sample 471 - loss: 1.3722213506698608\n",
      "Sample 472 - loss: 7.509357452392578\n",
      "Sample 473 - loss: 8.204917907714844\n",
      "Sample 474 - loss: 6.692756175994873\n",
      "Sample 475 - loss: 1.874823808670044\n",
      "Sample 476 - loss: 11.057714462280273\n",
      "Sample 477 - loss: 5.211511135101318\n",
      "Sample 478 - loss: 4.261669158935547\n",
      "Sample 479 - loss: 1.9501886367797852\n",
      "Sample 480 - loss: 0.37088775634765625\n",
      "Sample 481 - loss: 4.6041765213012695\n",
      "Sample 482 - loss: 2.381474256515503\n",
      "Sample 483 - loss: 3.3537793159484863\n",
      "Sample 484 - loss: 2.884369134902954\n",
      "Sample 485 - loss: 5.426196098327637\n",
      "Sample 486 - loss: 9.38675594329834\n",
      "Sample 487 - loss: 0.1654719114303589\n",
      "Sample 488 - loss: 6.764257907867432\n",
      "Sample 489 - loss: 13.068187713623047\n",
      "Sample 490 - loss: 4.2159624099731445\n",
      "Sample 491 - loss: 7.380676746368408\n",
      "Sample 492 - loss: 1.2764016389846802\n",
      "Sample 493 - loss: 2.710116386413574\n",
      "Sample 494 - loss: 2.747520685195923\n",
      "Sample 495 - loss: 4.835279941558838\n",
      "Sample 496 - loss: 11.215900421142578\n",
      "Sample 497 - loss: 5.20269775390625\n",
      "Sample 498 - loss: 6.119973182678223\n",
      "Sample 499 - loss: 0.7948592901229858\n",
      "Sample 500 - loss: 1.785322666168213\n",
      "Sample 501 - loss: 0.2621191740036011\n",
      "Sample 502 - loss: 0.22634357213974\n",
      "Sample 503 - loss: 7.0119218826293945\n",
      "Sample 504 - loss: 5.212344169616699\n",
      "Sample 505 - loss: 8.658758163452148\n",
      "Sample 506 - loss: 0.2389986366033554\n",
      "Sample 507 - loss: 4.330358505249023\n",
      "Sample 508 - loss: 4.001772880554199\n",
      "Sample 509 - loss: 8.83902645111084\n",
      "Sample 510 - loss: 3.3412561416625977\n",
      "Sample 511 - loss: 3.3060336112976074\n",
      "Sample 512 - loss: 9.613787651062012\n",
      "Sample 513 - loss: 0.6914787888526917\n",
      "Sample 514 - loss: 1.4523006677627563\n",
      "Sample 515 - loss: 5.230701923370361\n",
      "Sample 516 - loss: 5.929807662963867\n",
      "Sample 517 - loss: 12.406808853149414\n",
      "Sample 518 - loss: 4.394163131713867\n",
      "Sample 519 - loss: 2.5820000171661377\n",
      "Sample 520 - loss: 7.8687872886657715\n",
      "Sample 521 - loss: 10.782541275024414\n",
      "Sample 522 - loss: 1.8351784944534302\n",
      "Sample 523 - loss: 0.989647626876831\n",
      "Sample 524 - loss: 9.554609298706055\n",
      "Sample 525 - loss: 11.332118034362793\n",
      "Sample 526 - loss: 0.018296772614121437\n",
      "Sample 527 - loss: 0.7608805894851685\n",
      "Sample 528 - loss: 1.782318115234375\n",
      "Sample 529 - loss: 0.11487191915512085\n",
      "Sample 530 - loss: 6.158623695373535\n",
      "Sample 531 - loss: 9.917673110961914\n",
      "Sample 532 - loss: 10.857338905334473\n",
      "Sample 533 - loss: 6.674990177154541\n",
      "Sample 534 - loss: 12.767801284790039\n",
      "Sample 535 - loss: 3.2000668048858643\n",
      "Sample 536 - loss: 0.0839465782046318\n",
      "Sample 537 - loss: 10.53196907043457\n",
      "Sample 538 - loss: 0.7738940715789795\n",
      "Sample 539 - loss: 0.1945735216140747\n",
      "Sample 540 - loss: 0.06955308467149734\n",
      "Sample 541 - loss: 9.659873962402344\n",
      "Sample 542 - loss: 1.3565912246704102\n",
      "Sample 543 - loss: 1.1542084217071533\n",
      "Sample 544 - loss: 0.1654733270406723\n",
      "Sample 545 - loss: 0.7073308825492859\n",
      "Sample 546 - loss: 0.418214350938797\n",
      "Sample 547 - loss: 0.06793548911809921\n",
      "Sample 548 - loss: 1.909792423248291\n",
      "Sample 549 - loss: 2.402676582336426\n",
      "Sample 550 - loss: 5.251611709594727\n",
      "Sample 551 - loss: 2.5480141639709473\n",
      "Sample 552 - loss: 9.588788986206055\n",
      "Sample 553 - loss: 3.3278188705444336\n",
      "Sample 554 - loss: 0.4793553650379181\n",
      "Sample 555 - loss: 4.827439308166504\n",
      "Sample 556 - loss: 4.507265090942383\n",
      "Sample 557 - loss: 2.179486036300659\n",
      "Sample 558 - loss: 0.7450774312019348\n",
      "Sample 559 - loss: 1.3636287450790405\n",
      "Sample 560 - loss: 0.44197478890419006\n",
      "Sample 561 - loss: 8.510122299194336\n",
      "Sample 562 - loss: 8.357168197631836\n",
      "Sample 563 - loss: 0.6095424890518188\n",
      "Sample 564 - loss: 4.804487228393555\n",
      "Sample 565 - loss: 1.6207693815231323\n",
      "Sample 566 - loss: 11.602932929992676\n",
      "Sample 567 - loss: 3.6443874835968018\n",
      "Sample 568 - loss: 1.5618664026260376\n",
      "Sample 569 - loss: 6.351686954498291\n",
      "Sample 570 - loss: 0.4830150306224823\n",
      "Sample 571 - loss: 2.1608192920684814\n",
      "Sample 572 - loss: 9.97995662689209\n",
      "Sample 573 - loss: 0.1380588710308075\n",
      "Sample 574 - loss: 12.418496131896973\n",
      "Sample 575 - loss: 0.6799204349517822\n",
      "Sample 576 - loss: 7.600963115692139\n",
      "Sample 577 - loss: 9.846263885498047\n",
      "Sample 578 - loss: 3.1087276935577393\n",
      "Sample 579 - loss: 1.8460065126419067\n",
      "Sample 580 - loss: 6.932209491729736\n",
      "Sample 581 - loss: 5.253810405731201\n",
      "Sample 582 - loss: 7.670799732208252\n",
      "Sample 583 - loss: 1.65602707862854\n",
      "Sample 584 - loss: 0.14346209168434143\n",
      "Sample 585 - loss: 2.5933380126953125\n",
      "Sample 586 - loss: 4.975079536437988\n",
      "Sample 587 - loss: 3.3374221324920654\n",
      "Sample 588 - loss: 5.181128025054932\n",
      "Sample 589 - loss: 0.05858050286769867\n",
      "Sample 590 - loss: 4.7589335441589355\n",
      "Sample 591 - loss: 8.101822853088379\n",
      "Sample 592 - loss: 1.008876919746399\n",
      "Sample 593 - loss: 2.5543529987335205\n",
      "Sample 594 - loss: 6.436690807342529\n",
      "Sample 595 - loss: 4.171676158905029\n",
      "Sample 596 - loss: 0.11927814781665802\n",
      "Sample 597 - loss: 9.598980903625488\n",
      "Sample 598 - loss: 0.37000393867492676\n",
      "Sample 599 - loss: 8.787986755371094\n",
      "Sample 600 - loss: 1.1195812225341797\n",
      "Sample 601 - loss: 0.1399523764848709\n",
      "Sample 602 - loss: 1.1226671934127808\n",
      "Sample 603 - loss: 9.068151473999023\n",
      "Sample 604 - loss: 9.805893898010254\n",
      "Sample 605 - loss: 0.5277864336967468\n",
      "Sample 606 - loss: 0.8655359745025635\n",
      "Sample 607 - loss: 0.09003979712724686\n",
      "Sample 608 - loss: 0.12563678622245789\n",
      "Sample 609 - loss: 0.10672464221715927\n",
      "Sample 610 - loss: 2.6551132202148438\n",
      "Sample 611 - loss: 3.9560601711273193\n",
      "Sample 612 - loss: 8.223967552185059\n",
      "Sample 613 - loss: 0.16201700270175934\n",
      "Sample 614 - loss: 12.53387451171875\n",
      "Sample 615 - loss: 6.760470390319824\n",
      "Sample 616 - loss: 8.478067398071289\n",
      "Sample 617 - loss: 4.220614433288574\n",
      "Sample 618 - loss: 0.5949367880821228\n",
      "Sample 619 - loss: 7.770765781402588\n",
      "Sample 620 - loss: 3.95974063873291\n",
      "Sample 621 - loss: 0.4662172198295593\n",
      "Sample 622 - loss: 8.289942741394043\n",
      "Sample 623 - loss: 6.469668388366699\n",
      "Sample 624 - loss: 0.063275545835495\n",
      "Sample 625 - loss: 5.695819854736328\n",
      "Sample 626 - loss: 4.994662284851074\n",
      "Sample 627 - loss: 3.9407718181610107\n",
      "Sample 628 - loss: 1.9746590852737427\n",
      "Sample 629 - loss: 10.397601127624512\n",
      "Sample 630 - loss: 6.2812395095825195\n",
      "Sample 631 - loss: 7.942835807800293\n",
      "Sample 632 - loss: 0.577567994594574\n",
      "Sample 633 - loss: 0.19648979604244232\n",
      "Sample 634 - loss: 7.644497871398926\n",
      "Sample 635 - loss: 1.2887202501296997\n",
      "Sample 636 - loss: 2.9399781227111816\n",
      "Sample 637 - loss: 7.428175449371338\n",
      "Sample 638 - loss: 4.034846305847168\n",
      "Sample 639 - loss: 4.150053977966309\n",
      "Sample 640 - loss: 0.28342878818511963\n",
      "Sample 641 - loss: 0.30181315541267395\n",
      "Sample 642 - loss: 5.480987071990967\n",
      "Sample 643 - loss: 4.167998790740967\n",
      "Sample 644 - loss: 4.1181230545043945\n",
      "Sample 645 - loss: 6.230939865112305\n",
      "Sample 646 - loss: 7.895566463470459\n",
      "Sample 647 - loss: 11.757046699523926\n",
      "Sample 648 - loss: 1.6113674640655518\n",
      "Sample 649 - loss: 2.8248250484466553\n",
      "Sample 650 - loss: 1.0260215997695923\n",
      "Sample 651 - loss: 1.1994082927703857\n",
      "Sample 652 - loss: 2.495795488357544\n",
      "Sample 653 - loss: 4.063185214996338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 654 - loss: 0.593816876411438\n",
      "Sample 655 - loss: 0.09000050276517868\n",
      "Sample 656 - loss: 3.9277889728546143\n",
      "Sample 657 - loss: 4.601937770843506\n",
      "Sample 658 - loss: 0.1147243082523346\n",
      "Sample 659 - loss: 10.128118515014648\n",
      "Sample 660 - loss: 0.0978892520070076\n",
      "Sample 661 - loss: 3.0815536975860596\n",
      "Sample 662 - loss: 0.31373974680900574\n",
      "Sample 663 - loss: 1.2400479316711426\n",
      "Sample 664 - loss: 0.06996770948171616\n",
      "Sample 665 - loss: 1.3451950550079346\n",
      "Sample 666 - loss: 0.9833320379257202\n",
      "Sample 667 - loss: 1.0314875841140747\n",
      "Sample 668 - loss: 0.5885624289512634\n",
      "Sample 669 - loss: 0.04862635210156441\n",
      "Sample 670 - loss: 0.034127820283174515\n",
      "Sample 671 - loss: 0.6919209957122803\n",
      "Sample 672 - loss: 0.6552355885505676\n",
      "Sample 673 - loss: 0.3532414138317108\n",
      "Sample 674 - loss: 1.8700320720672607\n",
      "Sample 675 - loss: 0.03457893058657646\n",
      "Sample 676 - loss: 6.7537689208984375\n",
      "Sample 677 - loss: 2.6526131629943848\n",
      "Sample 678 - loss: 1.0916333198547363\n",
      "Sample 679 - loss: 0.02213135175406933\n",
      "Sample 680 - loss: 2.160818099975586\n",
      "Sample 681 - loss: 0.18901295959949493\n",
      "Sample 682 - loss: 0.24793009459972382\n",
      "Sample 683 - loss: 0.4780995547771454\n",
      "Sample 684 - loss: 0.8124969601631165\n",
      "Sample 685 - loss: 2.9675750732421875\n",
      "Sample 686 - loss: 4.253554344177246\n",
      "Sample 687 - loss: 0.0413653627038002\n",
      "Sample 688 - loss: 8.342273712158203\n",
      "Sample 689 - loss: 4.667169094085693\n",
      "Sample 690 - loss: 4.867364883422852\n",
      "Sample 691 - loss: 5.1425580978393555\n",
      "Sample 692 - loss: 1.7734036445617676\n",
      "Sample 693 - loss: 3.299847364425659\n",
      "Sample 694 - loss: 0.009373520500957966\n",
      "Sample 695 - loss: 12.08044719696045\n",
      "Sample 696 - loss: 2.0337164402008057\n",
      "Sample 697 - loss: 0.5998139381408691\n",
      "Sample 698 - loss: 3.996147871017456\n",
      "Sample 699 - loss: 0.43075406551361084\n",
      "Sample 700 - loss: 3.0138564109802246\n",
      "Sample 701 - loss: 8.924256324768066\n",
      "Sample 702 - loss: 0.16911806166172028\n",
      "Sample 703 - loss: 8.216232299804688\n",
      "Sample 704 - loss: 0.9115825891494751\n",
      "Sample 705 - loss: 1.3724982738494873\n",
      "Sample 706 - loss: 11.813899993896484\n",
      "Sample 707 - loss: 1.2041740417480469\n",
      "Sample 708 - loss: 2.2960665225982666\n",
      "Sample 709 - loss: 0.19608469307422638\n",
      "Sample 710 - loss: 0.6607338190078735\n",
      "Sample 711 - loss: 0.7794116735458374\n",
      "Sample 712 - loss: 2.966644525527954\n",
      "Sample 713 - loss: 2.1031296253204346\n",
      "Sample 714 - loss: 8.6210355758667\n",
      "Sample 715 - loss: 10.302495956420898\n",
      "Sample 716 - loss: 9.362273216247559\n",
      "Sample 717 - loss: 6.408220291137695\n",
      "Sample 718 - loss: 2.4151723384857178\n",
      "Sample 719 - loss: 0.5214744806289673\n",
      "Sample 720 - loss: 3.2553703784942627\n",
      "Sample 721 - loss: 7.782995700836182\n",
      "Sample 722 - loss: 2.9233179092407227\n",
      "Sample 723 - loss: 9.824854850769043\n",
      "Sample 724 - loss: 0.7205791473388672\n",
      "Sample 725 - loss: 7.746309757232666\n",
      "Sample 726 - loss: 2.076552391052246\n",
      "Sample 727 - loss: 3.7751543521881104\n",
      "Sample 728 - loss: 12.096532821655273\n",
      "Sample 729 - loss: 8.1692476272583\n",
      "Sample 730 - loss: 1.4202015399932861\n",
      "Sample 731 - loss: 4.175756454467773\n",
      "Sample 732 - loss: 8.716723442077637\n",
      "Sample 733 - loss: 0.3601360321044922\n",
      "Sample 734 - loss: 6.217291355133057\n",
      "Sample 735 - loss: 7.17017936706543\n",
      "Sample 736 - loss: 1.4931172132492065\n",
      "Sample 737 - loss: 9.194091796875\n",
      "Sample 738 - loss: 10.909798622131348\n",
      "Sample 739 - loss: 6.877627372741699\n",
      "Sample 740 - loss: 5.778425693511963\n",
      "Sample 741 - loss: 6.786507606506348\n",
      "Sample 742 - loss: 1.5133421421051025\n",
      "Sample 743 - loss: 2.1236748695373535\n",
      "Sample 744 - loss: 1.2550286054611206\n",
      "Sample 745 - loss: 0.9626213312149048\n",
      "Sample 746 - loss: 10.063858985900879\n",
      "Sample 747 - loss: 4.422745227813721\n",
      "Sample 748 - loss: 8.802186012268066\n",
      "Sample 749 - loss: 0.8142762184143066\n",
      "Sample 750 - loss: 6.958799839019775\n",
      "Sample 751 - loss: 1.0777459144592285\n",
      "Sample 752 - loss: 3.2513227462768555\n",
      "Sample 753 - loss: 0.6518551111221313\n",
      "Sample 754 - loss: 0.9660885334014893\n",
      "Sample 755 - loss: 0.07402294874191284\n",
      "Sample 756 - loss: 8.247614860534668\n",
      "Sample 757 - loss: 2.612650156021118\n",
      "Sample 758 - loss: 3.7412519454956055\n",
      "Sample 759 - loss: 10.597834587097168\n",
      "Sample 760 - loss: 7.523444652557373\n",
      "Sample 761 - loss: 2.0236382484436035\n",
      "Sample 762 - loss: 6.05657958984375\n",
      "Sample 763 - loss: 1.9994292259216309\n",
      "Sample 764 - loss: 0.2703363299369812\n",
      "Sample 765 - loss: 0.08670778572559357\n",
      "Sample 766 - loss: 0.4764980375766754\n",
      "Sample 767 - loss: 0.022941280156373978\n",
      "Sample 768 - loss: 12.208137512207031\n",
      "Sample 769 - loss: 10.870128631591797\n",
      "Sample 770 - loss: 0.09557971358299255\n",
      "Sample 771 - loss: 8.545547485351562\n",
      "Sample 772 - loss: 9.557572364807129\n",
      "Sample 773 - loss: 4.002006530761719\n",
      "Sample 774 - loss: 7.001593589782715\n",
      "Sample 775 - loss: 9.522665023803711\n",
      "Sample 776 - loss: 0.3694741725921631\n",
      "Sample 777 - loss: 1.0679105520248413\n",
      "Sample 778 - loss: 5.292337417602539\n",
      "Sample 779 - loss: 1.1222491264343262\n",
      "Sample 780 - loss: 6.114266872406006\n",
      "Sample 781 - loss: 0.03462614119052887\n",
      "Sample 782 - loss: 0.4517185688018799\n",
      "Sample 783 - loss: 1.8921374082565308\n",
      "Sample 784 - loss: 0.013547439128160477\n",
      "Sample 785 - loss: 7.399616718292236\n",
      "Sample 786 - loss: 4.2810587882995605\n",
      "Sample 787 - loss: 8.050111770629883\n",
      "Sample 788 - loss: 1.7618194818496704\n",
      "Sample 789 - loss: 5.674893379211426\n",
      "Sample 790 - loss: 0.5659269690513611\n",
      "Sample 791 - loss: 0.11090798676013947\n",
      "Sample 792 - loss: 0.13601897656917572\n",
      "Sample 793 - loss: 0.21496252715587616\n",
      "Sample 794 - loss: 1.0285314321517944\n",
      "Sample 795 - loss: 0.008924406953155994\n",
      "Sample 796 - loss: 8.16230583190918\n",
      "Sample 797 - loss: 0.7529639601707458\n",
      "Sample 798 - loss: 3.5060079097747803\n",
      "Sample 799 - loss: 8.366166114807129\n",
      "Sample 800 - loss: 0.8744449019432068\n",
      "Sample 801 - loss: 4.3401641845703125\n",
      "Sample 802 - loss: 11.2973051071167\n",
      "Sample 803 - loss: 5.5844926834106445\n",
      "Sample 804 - loss: 9.370691299438477\n",
      "Sample 805 - loss: 0.012714564800262451\n",
      "Sample 806 - loss: 1.4565516710281372\n",
      "Sample 807 - loss: 0.27655029296875\n",
      "Sample 808 - loss: 0.5341187715530396\n",
      "Sample 809 - loss: 5.329145431518555\n",
      "Sample 810 - loss: 0.3674267828464508\n",
      "Sample 811 - loss: 3.3688859939575195\n",
      "Sample 812 - loss: 6.481812000274658\n",
      "Sample 813 - loss: 2.089226484298706\n",
      "Sample 814 - loss: 1.5555920600891113\n",
      "Sample 815 - loss: 2.7017154693603516\n",
      "Sample 816 - loss: 0.41341936588287354\n",
      "Sample 817 - loss: 0.4109443426132202\n",
      "Sample 818 - loss: 12.383614540100098\n",
      "Sample 819 - loss: 1.2678477764129639\n",
      "Sample 820 - loss: 5.719543933868408\n",
      "Sample 821 - loss: 0.5978527069091797\n",
      "Sample 822 - loss: 11.268383979797363\n",
      "Sample 823 - loss: 8.283288955688477\n",
      "Sample 824 - loss: 0.047276295721530914\n",
      "Sample 825 - loss: 5.4116363525390625\n",
      "Sample 826 - loss: 0.3823120594024658\n",
      "Sample 827 - loss: 0.21032024919986725\n",
      "Sample 828 - loss: 0.05788922682404518\n",
      "Sample 829 - loss: 1.5926181077957153\n",
      "Sample 830 - loss: 2.041874647140503\n",
      "Sample 831 - loss: 0.37448185682296753\n",
      "Sample 832 - loss: 0.0348944216966629\n",
      "Sample 833 - loss: 0.7611580491065979\n",
      "Sample 834 - loss: 0.4443352520465851\n",
      "Sample 835 - loss: 3.4744601249694824\n",
      "Sample 836 - loss: 1.770748257637024\n",
      "Sample 837 - loss: 8.21027946472168\n",
      "Sample 838 - loss: 3.4953689575195312\n",
      "Sample 839 - loss: 8.168530464172363\n",
      "Sample 840 - loss: 11.610709190368652\n",
      "Sample 841 - loss: 0.1372569501399994\n",
      "Sample 842 - loss: 0.3571179211139679\n",
      "Sample 843 - loss: 0.02218671329319477\n",
      "Sample 844 - loss: 0.15994054079055786\n",
      "Sample 845 - loss: 10.077831268310547\n",
      "Sample 846 - loss: 9.149710655212402\n",
      "Sample 847 - loss: 3.3934085369110107\n",
      "Sample 848 - loss: 6.594015121459961\n",
      "Sample 849 - loss: 0.9588332176208496\n",
      "Sample 850 - loss: 7.296748638153076\n",
      "Sample 851 - loss: 1.1645907163619995\n",
      "Sample 852 - loss: 11.161799430847168\n",
      "Sample 853 - loss: 7.029888153076172\n",
      "Sample 854 - loss: 10.134827613830566\n",
      "Sample 855 - loss: 3.9545505046844482\n",
      "Sample 856 - loss: 2.090304374694824\n",
      "Sample 857 - loss: 0.22019527852535248\n",
      "Sample 858 - loss: 3.508456230163574\n",
      "Sample 859 - loss: 0.32332858443260193\n",
      "Sample 860 - loss: 2.983402967453003\n",
      "Sample 861 - loss: 1.7158217430114746\n",
      "Sample 862 - loss: 0.1738087236881256\n",
      "Sample 863 - loss: 3.430966377258301\n",
      "Sample 864 - loss: 8.446770668029785\n",
      "Sample 865 - loss: 1.510082721710205\n",
      "Sample 866 - loss: 4.832219123840332\n",
      "Sample 867 - loss: 1.1348224878311157\n",
      "Sample 868 - loss: 0.07382147759199142\n",
      "Sample 869 - loss: 1.1912641525268555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 870 - loss: 10.979408264160156\n",
      "Sample 871 - loss: 10.399763107299805\n",
      "Sample 872 - loss: 3.3344085216522217\n",
      "Sample 873 - loss: 6.928989410400391\n",
      "Sample 874 - loss: 1.8729863166809082\n",
      "Sample 875 - loss: 10.818105697631836\n",
      "Sample 876 - loss: 9.152222633361816\n",
      "Sample 877 - loss: 3.1339404582977295\n",
      "Sample 878 - loss: 0.6726630926132202\n",
      "Sample 879 - loss: 4.250631809234619\n",
      "Sample 880 - loss: 4.226212024688721\n",
      "Sample 881 - loss: 0.11669163405895233\n",
      "Sample 882 - loss: 7.883131504058838\n",
      "Sample 883 - loss: 2.297197103500366\n",
      "Sample 884 - loss: 1.1252630949020386\n",
      "Sample 885 - loss: 0.8023866415023804\n",
      "Sample 886 - loss: 1.114280104637146\n",
      "Sample 887 - loss: 7.8186421394348145\n",
      "Sample 888 - loss: 0.12241210788488388\n",
      "Sample 889 - loss: 4.5605268478393555\n",
      "Sample 890 - loss: 4.308821201324463\n",
      "Sample 891 - loss: 1.5644716024398804\n",
      "Sample 892 - loss: 7.759820461273193\n",
      "Sample 893 - loss: 0.09481365978717804\n",
      "Sample 894 - loss: 4.20376443862915\n",
      "Sample 895 - loss: 2.9699926376342773\n",
      "Sample 896 - loss: 4.55721378326416\n",
      "Sample 897 - loss: 9.013304710388184\n",
      "Sample 898 - loss: 0.7306286692619324\n",
      "Sample 899 - loss: 3.1663272380828857\n",
      "Sample 900 - loss: 2.6191210746765137\n",
      "Sample 901 - loss: 0.9276602864265442\n",
      "Sample 902 - loss: 6.1789164543151855\n",
      "Sample 903 - loss: 6.820168495178223\n",
      "Sample 904 - loss: 2.1155693531036377\n",
      "Sample 905 - loss: 7.379007339477539\n",
      "Sample 906 - loss: 5.521032333374023\n",
      "Sample 907 - loss: 5.836276054382324\n",
      "Sample 908 - loss: 5.677725791931152\n",
      "Sample 909 - loss: 3.9738101959228516\n",
      "Sample 910 - loss: 3.2490546703338623\n",
      "Sample 911 - loss: 9.209911346435547\n",
      "Sample 912 - loss: 0.12717150151729584\n",
      "Sample 913 - loss: 4.833068370819092\n",
      "Sample 914 - loss: 8.057196617126465\n",
      "Sample 915 - loss: 0.07832297682762146\n",
      "Sample 916 - loss: 5.289313793182373\n",
      "Sample 917 - loss: 0.14740951359272003\n",
      "Sample 918 - loss: 1.5272831916809082\n",
      "Sample 919 - loss: 1.2630590200424194\n",
      "Sample 920 - loss: 1.6159471273422241\n",
      "Sample 921 - loss: 6.274176120758057\n",
      "Sample 922 - loss: 5.914349555969238\n",
      "Sample 923 - loss: 0.7788617014884949\n",
      "Sample 924 - loss: 1.6769778728485107\n",
      "Sample 925 - loss: 7.1433563232421875\n",
      "Sample 926 - loss: 0.2859967052936554\n",
      "Sample 927 - loss: 0.4888194799423218\n",
      "Sample 928 - loss: 0.6254985928535461\n",
      "Sample 929 - loss: 7.872335433959961\n",
      "Sample 930 - loss: 3.272965669631958\n",
      "Sample 931 - loss: 4.557680130004883\n",
      "Sample 932 - loss: 0.06063785031437874\n",
      "Sample 933 - loss: 9.184633255004883\n",
      "Sample 934 - loss: 10.523024559020996\n",
      "Sample 935 - loss: 7.736220836639404\n",
      "Sample 936 - loss: 12.011462211608887\n",
      "Sample 937 - loss: 3.7696213722229004\n",
      "Sample 938 - loss: 7.283824920654297\n",
      "Sample 939 - loss: 5.598516464233398\n",
      "Sample 940 - loss: 4.848575592041016\n",
      "Sample 941 - loss: 4.330276012420654\n",
      "Sample 942 - loss: 6.9151129722595215\n",
      "Sample 943 - loss: 5.665224552154541\n",
      "Sample 944 - loss: 4.619269847869873\n",
      "Sample 945 - loss: 6.191014289855957\n",
      "Sample 946 - loss: 6.585777759552002\n",
      "Sample 947 - loss: 8.681087493896484\n",
      "Sample 948 - loss: 3.6113317012786865\n",
      "Sample 949 - loss: 3.010394811630249\n",
      "Sample 950 - loss: 9.749481201171875\n",
      "Sample 951 - loss: 0.8804506659507751\n",
      "Sample 952 - loss: 10.55248737335205\n",
      "Sample 953 - loss: 6.117184638977051\n",
      "Sample 954 - loss: 0.6271617412567139\n",
      "Sample 955 - loss: 11.942996978759766\n",
      "Sample 956 - loss: 0.36842676997184753\n",
      "Sample 957 - loss: 0.9895877838134766\n",
      "Sample 958 - loss: 9.855944633483887\n",
      "Sample 959 - loss: 7.969883441925049\n",
      "Sample 960 - loss: 0.9452817440032959\n",
      "Sample 961 - loss: 7.7454400062561035\n",
      "Sample 962 - loss: 10.092277526855469\n",
      "Sample 963 - loss: 8.357990264892578\n",
      "Sample 964 - loss: 4.670807361602783\n",
      "Sample 965 - loss: 4.9717206954956055\n",
      "Sample 966 - loss: 1.74711275100708\n",
      "Sample 967 - loss: 12.234981536865234\n",
      "Sample 968 - loss: 1.5254000425338745\n",
      "Sample 969 - loss: 6.795841693878174\n",
      "Sample 970 - loss: 10.586051940917969\n",
      "Sample 971 - loss: 1.9208961725234985\n",
      "Sample 972 - loss: 11.229514122009277\n",
      "Sample 973 - loss: 4.8597564697265625\n",
      "Sample 974 - loss: 5.9506306648254395\n",
      "Sample 975 - loss: 5.271869659423828\n",
      "Sample 976 - loss: 10.04296588897705\n",
      "Sample 977 - loss: 2.0122759342193604\n",
      "Sample 978 - loss: 6.363353729248047\n",
      "Sample 979 - loss: 0.12109723687171936\n",
      "Sample 980 - loss: 1.4865350723266602\n",
      "Sample 981 - loss: 0.2696180045604706\n",
      "Sample 982 - loss: 1.4969685077667236\n",
      "Sample 983 - loss: 10.802285194396973\n",
      "Sample 984 - loss: 0.5235675573348999\n",
      "Sample 985 - loss: 7.475368499755859\n",
      "Sample 986 - loss: 2.3855626583099365\n",
      "Sample 987 - loss: 10.930619239807129\n",
      "Sample 988 - loss: 2.377535820007324\n",
      "Sample 989 - loss: 1.3310068845748901\n",
      "Sample 990 - loss: 8.144075393676758\n",
      "Sample 991 - loss: 2.4667775630950928\n",
      "Sample 992 - loss: 7.692561149597168\n",
      "Sample 993 - loss: 0.02798018977046013\n",
      "Sample 994 - loss: 2.6734931468963623\n",
      "Sample 995 - loss: 1.880010724067688\n",
      "Sample 996 - loss: 2.336980104446411\n",
      "Sample 997 - loss: 0.031326793134212494\n",
      "Sample 998 - loss: 0.1408248394727707\n",
      "Sample 999 - loss: 0.5258083343505859\n",
      "Sample 1000 - loss: 5.8801422119140625\n",
      "Sample 1001 - loss: 0.022632703185081482\n",
      "Sample 1002 - loss: 1.8067371845245361\n",
      "Sample 1003 - loss: 0.16708685457706451\n",
      "Sample 1004 - loss: 8.55508041381836\n",
      "Sample 1005 - loss: 12.47289752960205\n",
      "Sample 1006 - loss: 8.414230346679688\n",
      "Sample 1007 - loss: 9.470918655395508\n",
      "Sample 1008 - loss: 11.363768577575684\n",
      "Sample 1009 - loss: 3.7522780895233154\n",
      "Sample 1010 - loss: 0.2238159030675888\n",
      "Sample 1011 - loss: 10.30787467956543\n",
      "Sample 1012 - loss: 1.2380282878875732\n",
      "Sample 1013 - loss: 0.3451974093914032\n",
      "Sample 1014 - loss: 6.498727321624756\n",
      "Sample 1015 - loss: 0.017092633992433548\n",
      "Sample 1016 - loss: 6.633296012878418\n",
      "Sample 1017 - loss: 0.4661504030227661\n",
      "Sample 1018 - loss: 1.0266457796096802\n",
      "Sample 1019 - loss: 2.8417470455169678\n",
      "Sample 1020 - loss: 1.9406073093414307\n",
      "Sample 1021 - loss: 5.089440822601318\n",
      "Sample 1022 - loss: 0.8612719178199768\n",
      "Sample 1023 - loss: 1.796267032623291\n",
      "Sample 1024 - loss: 6.684259414672852\n",
      "Sample 1025 - loss: 13.448046684265137\n",
      "Sample 1026 - loss: 5.311580657958984\n",
      "Sample 1027 - loss: 0.10193846374750137\n",
      "Sample 1028 - loss: 3.143664836883545\n",
      "Sample 1029 - loss: 2.7433524131774902\n",
      "Sample 1030 - loss: 6.3225626945495605\n",
      "Sample 1031 - loss: 4.401436805725098\n",
      "Sample 1032 - loss: 12.524935722351074\n",
      "Sample 1033 - loss: 6.190420627593994\n",
      "Sample 1034 - loss: 4.237503528594971\n",
      "Sample 1035 - loss: 8.311688423156738\n",
      "Sample 1036 - loss: 9.248016357421875\n",
      "Sample 1037 - loss: 5.19351053237915\n",
      "Sample 1038 - loss: 0.24377670884132385\n",
      "Sample 1039 - loss: 3.653179883956909\n",
      "Sample 1040 - loss: 4.519960403442383\n",
      "Sample 1041 - loss: 0.42980116605758667\n",
      "Sample 1042 - loss: 6.609135627746582\n",
      "Sample 1043 - loss: 9.617776870727539\n",
      "Sample 1044 - loss: 6.083024501800537\n",
      "Sample 1045 - loss: 0.7546991109848022\n",
      "Sample 1046 - loss: 1.6750843524932861\n",
      "Sample 1047 - loss: 0.14338424801826477\n",
      "Sample 1048 - loss: 1.96844482421875\n",
      "Sample 1049 - loss: 0.01589953899383545\n",
      "Sample 1050 - loss: 6.8125481605529785\n",
      "Sample 1051 - loss: 5.1354146003723145\n",
      "Sample 1052 - loss: 4.913456439971924\n",
      "Sample 1053 - loss: 2.418072462081909\n",
      "Sample 1054 - loss: 8.102334976196289\n",
      "Sample 1055 - loss: 0.012440689839422703\n",
      "Sample 1056 - loss: 1.4841256141662598\n",
      "Sample 1057 - loss: 5.2333598136901855\n",
      "Sample 1058 - loss: 2.041841506958008\n",
      "Sample 1059 - loss: 0.19374677538871765\n",
      "Sample 1060 - loss: 1.005645513534546\n",
      "Sample 1061 - loss: 5.054898262023926\n",
      "Sample 1062 - loss: 11.252021789550781\n",
      "Sample 1063 - loss: 7.963854789733887\n",
      "Sample 1064 - loss: 6.6968512535095215\n",
      "Sample 1065 - loss: 8.86772346496582\n",
      "Sample 1066 - loss: 0.0842481330037117\n",
      "Sample 1067 - loss: 0.010942845605313778\n",
      "Sample 1068 - loss: 7.27243185043335\n",
      "Sample 1069 - loss: 4.199910640716553\n",
      "Sample 1070 - loss: 0.4237334728240967\n",
      "Sample 1071 - loss: 7.665836811065674\n",
      "Sample 1072 - loss: 6.509814262390137\n",
      "Sample 1073 - loss: 4.195868968963623\n",
      "Sample 1074 - loss: 3.4402847290039062\n",
      "Sample 1075 - loss: 7.314030170440674\n",
      "Sample 1076 - loss: 0.8049330711364746\n",
      "Sample 1077 - loss: 6.207676887512207\n",
      "Sample 1078 - loss: 10.369967460632324\n",
      "Sample 1079 - loss: 0.5978095531463623\n",
      "Sample 1080 - loss: 3.561539888381958\n",
      "Sample 1081 - loss: 0.44068238139152527\n",
      "Sample 1082 - loss: 2.4498987197875977\n",
      "Sample 1083 - loss: 9.07354736328125\n",
      "Sample 1084 - loss: 0.057098694145679474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1085 - loss: 11.068643569946289\n",
      "Sample 1086 - loss: 0.33241668343544006\n",
      "Sample 1087 - loss: 5.403116226196289\n",
      "Sample 1088 - loss: 1.3528494834899902\n",
      "Sample 1089 - loss: 0.4113645851612091\n",
      "Sample 1090 - loss: 2.4435079097747803\n",
      "Sample 1091 - loss: 2.7240970134735107\n",
      "Sample 1092 - loss: 4.622714519500732\n",
      "Sample 1093 - loss: 4.961891174316406\n",
      "Sample 1094 - loss: 2.2100021839141846\n",
      "Sample 1095 - loss: 1.4774565696716309\n",
      "Sample 1096 - loss: 10.754996299743652\n",
      "Sample 1097 - loss: 9.136032104492188\n",
      "Sample 1098 - loss: 9.225688934326172\n",
      "Sample 1099 - loss: 2.8254711627960205\n",
      "Sample 1100 - loss: 7.055125713348389\n",
      "Sample 1101 - loss: 9.158773422241211\n",
      "Sample 1102 - loss: 0.554445207118988\n",
      "Sample 1103 - loss: 0.2695577144622803\n",
      "Sample 1104 - loss: 5.11665153503418\n",
      "Sample 1105 - loss: 2.253380060195923\n",
      "Sample 1106 - loss: 1.4797056913375854\n",
      "Sample 1107 - loss: 10.55767822265625\n",
      "Sample 1108 - loss: 1.459333062171936\n",
      "Sample 1109 - loss: 5.221444606781006\n",
      "Sample 1110 - loss: 4.4947710037231445\n",
      "Sample 1111 - loss: 0.4829256534576416\n",
      "Sample 1112 - loss: 4.730576038360596\n",
      "Sample 1113 - loss: 3.0371875762939453\n",
      "Sample 1114 - loss: 8.977466583251953\n",
      "Sample 1115 - loss: 6.122091770172119\n",
      "Sample 1116 - loss: 0.13378137350082397\n",
      "Sample 1117 - loss: 8.911508560180664\n",
      "Sample 1118 - loss: 0.04325849190354347\n",
      "Sample 1119 - loss: 0.14989160001277924\n",
      "Sample 1120 - loss: 1.1789227724075317\n",
      "Sample 1121 - loss: 3.410726547241211\n",
      "Sample 1122 - loss: 5.785943984985352\n",
      "Sample 1123 - loss: 1.677067756652832\n",
      "Sample 1124 - loss: 2.5998685359954834\n",
      "Sample 1125 - loss: 3.1274752616882324\n",
      "Sample 1126 - loss: 1.4116512537002563\n",
      "Sample 1127 - loss: 1.9474685192108154\n",
      "Sample 1128 - loss: 1.9063159227371216\n",
      "Sample 1129 - loss: 2.2198615074157715\n",
      "Sample 1130 - loss: 7.492244243621826\n",
      "Sample 1131 - loss: 3.208834171295166\n",
      "Sample 1132 - loss: 4.652228832244873\n",
      "Sample 1133 - loss: 8.932840347290039\n",
      "Sample 1134 - loss: 7.534628868103027\n",
      "Sample 1135 - loss: 8.278848648071289\n",
      "Sample 1136 - loss: 9.027125358581543\n",
      "Sample 1137 - loss: 0.1274334192276001\n",
      "Sample 1138 - loss: 5.070064544677734\n",
      "Sample 1139 - loss: 6.260650634765625\n",
      "Sample 1140 - loss: 2.904670000076294\n",
      "Sample 1141 - loss: 9.027837753295898\n",
      "Sample 1142 - loss: 0.8313255906105042\n",
      "Sample 1143 - loss: 1.78287672996521\n",
      "Sample 1144 - loss: 9.764742851257324\n",
      "Sample 1145 - loss: 0.6040317416191101\n",
      "Sample 1146 - loss: 0.03595487028360367\n",
      "Sample 1147 - loss: 2.767009973526001\n",
      "Sample 1148 - loss: 4.896155834197998\n",
      "Sample 1149 - loss: 7.9871625900268555\n",
      "Sample 1150 - loss: 2.729226589202881\n",
      "Sample 1151 - loss: 1.5893396139144897\n",
      "Sample 1152 - loss: 2.031365394592285\n",
      "Sample 1153 - loss: 5.743142604827881\n",
      "Sample 1154 - loss: 4.352084159851074\n",
      "Sample 1155 - loss: 5.027257442474365\n",
      "Sample 1156 - loss: 11.747149467468262\n",
      "Sample 1157 - loss: 3.351970911026001\n",
      "Sample 1158 - loss: 8.927062034606934\n",
      "Sample 1159 - loss: 4.06834602355957\n",
      "Sample 1160 - loss: 3.820967674255371\n",
      "Sample 1161 - loss: 11.893332481384277\n",
      "Sample 1162 - loss: 11.48951530456543\n",
      "Sample 1163 - loss: 9.092790603637695\n",
      "Sample 1164 - loss: 0.07178053259849548\n",
      "Sample 1165 - loss: 4.4815592765808105\n",
      "Sample 1166 - loss: 0.1449597328901291\n",
      "Sample 1167 - loss: 9.999384880065918\n",
      "Sample 1168 - loss: 3.244997024536133\n",
      "Sample 1169 - loss: 1.8801831007003784\n",
      "Sample 1170 - loss: 0.1310221254825592\n",
      "Sample 1171 - loss: 4.637700080871582\n",
      "Sample 1172 - loss: 1.6162739992141724\n",
      "Sample 1173 - loss: 7.0812554359436035\n",
      "Sample 1174 - loss: 0.11308404803276062\n",
      "Sample 1175 - loss: 5.384713172912598\n",
      "Sample 1176 - loss: 2.217757225036621\n",
      "Sample 1177 - loss: 1.870393991470337\n",
      "Sample 1178 - loss: 3.7384841442108154\n",
      "Sample 1179 - loss: 0.943936288356781\n",
      "Sample 1180 - loss: 0.4739900827407837\n",
      "Sample 1181 - loss: 1.4569340944290161\n",
      "Sample 1182 - loss: 1.92433762550354\n",
      "Sample 1183 - loss: 0.07459259778261185\n",
      "Sample 1184 - loss: 7.32276725769043\n",
      "Sample 1185 - loss: 6.381908416748047\n",
      "Sample 1186 - loss: 1.1571528911590576\n",
      "Sample 1187 - loss: 0.7743992805480957\n",
      "Sample 1188 - loss: 0.3949090242385864\n",
      "Sample 1189 - loss: 4.187906265258789\n",
      "Sample 1190 - loss: 9.482280731201172\n",
      "Sample 1191 - loss: 2.1388847827911377\n",
      "Sample 1192 - loss: 1.0949199199676514\n",
      "Sample 1193 - loss: 1.8948551416397095\n",
      "Sample 1194 - loss: 0.2581549882888794\n",
      "Sample 1195 - loss: 8.664460182189941\n",
      "Sample 1196 - loss: 10.06194019317627\n",
      "Sample 1197 - loss: 1.8719979524612427\n",
      "Sample 1198 - loss: 11.774789810180664\n",
      "Sample 1199 - loss: 0.3038523197174072\n",
      "Sample 1200 - loss: 2.623345136642456\n",
      "Sample 1201 - loss: 1.137567162513733\n",
      "Sample 1202 - loss: 9.40922737121582\n",
      "Sample 1203 - loss: 2.3463711738586426\n",
      "Sample 1204 - loss: 2.8751935958862305\n",
      "Sample 1205 - loss: 0.10346569120883942\n",
      "Sample 1206 - loss: 3.725188970565796\n",
      "Sample 1207 - loss: 0.33374279737472534\n",
      "Sample 1208 - loss: 10.067134857177734\n",
      "Sample 1209 - loss: 0.4635177254676819\n",
      "Sample 1210 - loss: 4.10168981552124\n",
      "Sample 1211 - loss: 10.783098220825195\n",
      "Sample 1212 - loss: 1.2694612741470337\n",
      "Sample 1213 - loss: 1.1841853857040405\n",
      "Sample 1214 - loss: 2.3092081546783447\n",
      "Sample 1215 - loss: 2.851879835128784\n",
      "Sample 1216 - loss: 10.046552658081055\n",
      "Sample 1217 - loss: 0.5618049502372742\n",
      "Sample 1218 - loss: 5.733567714691162\n",
      "Sample 1219 - loss: 0.061492670327425\n",
      "Sample 1220 - loss: 6.086223125457764\n",
      "Sample 1221 - loss: 1.8149380683898926\n",
      "Sample 1222 - loss: 4.096511363983154\n",
      "Sample 1223 - loss: 6.670392990112305\n",
      "Sample 1224 - loss: 2.280297040939331\n",
      "Sample 1225 - loss: 3.265212297439575\n",
      "Sample 1226 - loss: 4.706279754638672\n",
      "Sample 1227 - loss: 7.623028755187988\n",
      "Sample 1228 - loss: 0.6428664326667786\n",
      "Sample 1229 - loss: 12.267833709716797\n",
      "Sample 1230 - loss: 5.482334613800049\n",
      "Sample 1231 - loss: 12.57448959350586\n",
      "Sample 1232 - loss: 0.518304705619812\n",
      "Sample 1233 - loss: 0.8461796641349792\n",
      "Sample 1234 - loss: 9.897253036499023\n",
      "Sample 1235 - loss: 0.10652490705251694\n",
      "Sample 1236 - loss: 2.093264102935791\n",
      "Sample 1237 - loss: 1.15004301071167\n",
      "Sample 1238 - loss: 0.9485868811607361\n",
      "Sample 1239 - loss: 0.8903921246528625\n",
      "Sample 1240 - loss: 0.3321162462234497\n",
      "Sample 1241 - loss: 0.22375380992889404\n",
      "Sample 1242 - loss: 6.99832010269165\n",
      "Sample 1243 - loss: 2.767625093460083\n",
      "Sample 1244 - loss: 0.43379175662994385\n",
      "Sample 1245 - loss: 3.6087987422943115\n",
      "Sample 1246 - loss: 0.9275129437446594\n",
      "Sample 1247 - loss: 1.6279586553573608\n",
      "Sample 1248 - loss: 1.2522227764129639\n",
      "Sample 1249 - loss: 6.524904251098633\n",
      "Sample 1250 - loss: 3.702467679977417\n",
      "Sample 1251 - loss: 3.6336004734039307\n",
      "Sample 1252 - loss: 6.9444403648376465\n",
      "Sample 1253 - loss: 5.534672737121582\n",
      "Sample 1254 - loss: 6.228278160095215\n",
      "Sample 1255 - loss: 0.09510239958763123\n",
      "Sample 1256 - loss: 1.4798790216445923\n",
      "Sample 1257 - loss: 12.218842506408691\n",
      "Sample 1258 - loss: 4.811172008514404\n",
      "Sample 1259 - loss: 0.10042908787727356\n",
      "Sample 1260 - loss: 0.7804269194602966\n",
      "Sample 1261 - loss: 7.338581562042236\n",
      "Sample 1262 - loss: 1.4450105428695679\n",
      "Sample 1263 - loss: 5.17600154876709\n",
      "Sample 1264 - loss: 11.12707805633545\n",
      "Sample 1265 - loss: 1.5930026769638062\n",
      "Sample 1266 - loss: 6.6553144454956055\n",
      "Sample 1267 - loss: 0.8825564384460449\n",
      "Sample 1268 - loss: 7.337815761566162\n",
      "Sample 1269 - loss: 0.6145730018615723\n",
      "Sample 1270 - loss: 4.118594646453857\n",
      "Sample 1271 - loss: 5.455270767211914\n",
      "Sample 1272 - loss: 8.10116195678711\n",
      "Sample 1273 - loss: 13.066581726074219\n",
      "Sample 1274 - loss: 6.541921615600586\n",
      "Sample 1275 - loss: 1.3809858560562134\n",
      "Sample 1276 - loss: 0.8929372429847717\n",
      "Sample 1277 - loss: 5.7296247482299805\n",
      "Sample 1278 - loss: 1.6403090953826904\n",
      "Sample 1279 - loss: 11.601676940917969\n",
      "Sample 1280 - loss: 0.059772782027721405\n",
      "Sample 1281 - loss: 4.334938049316406\n",
      "Sample 1282 - loss: 0.1411847174167633\n",
      "Sample 1283 - loss: 10.859245300292969\n",
      "Sample 1284 - loss: 0.7926205992698669\n",
      "Sample 1285 - loss: 8.701616287231445\n",
      "Sample 1286 - loss: 4.792592525482178\n",
      "Sample 1287 - loss: 7.4558868408203125\n",
      "Sample 1288 - loss: 2.306756019592285\n",
      "Sample 1289 - loss: 0.9781294465065002\n",
      "Sample 1290 - loss: 8.180152893066406\n",
      "Sample 1291 - loss: 6.375641345977783\n",
      "Sample 1292 - loss: 1.7953615188598633\n",
      "Sample 1293 - loss: 0.030648237094283104\n",
      "Sample 1294 - loss: 0.27510178089141846\n",
      "Sample 1295 - loss: 1.5805343389511108\n",
      "Sample 1296 - loss: 0.9534566402435303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1297 - loss: 2.4320921897888184\n",
      "Sample 1298 - loss: 3.553309440612793\n",
      "Sample 1299 - loss: 1.082969307899475\n",
      "Sample 1300 - loss: 1.161039113998413\n",
      "Sample 1301 - loss: 0.7574547529220581\n",
      "Sample 1302 - loss: 8.933148384094238\n",
      "Sample 1303 - loss: 6.5272603034973145\n",
      "Sample 1304 - loss: 6.188070774078369\n",
      "Sample 1305 - loss: 0.5922688841819763\n",
      "Sample 1306 - loss: 6.3806586265563965\n",
      "Sample 1307 - loss: 2.2181012630462646\n",
      "Sample 1308 - loss: 0.6539517045021057\n",
      "Sample 1309 - loss: 0.21769922971725464\n",
      "Sample 1310 - loss: 0.21160516142845154\n",
      "Sample 1311 - loss: 6.00286865234375\n",
      "Sample 1312 - loss: 2.3660154342651367\n",
      "Sample 1313 - loss: 1.4013906717300415\n",
      "Sample 1314 - loss: 0.3242185115814209\n",
      "Sample 1315 - loss: 0.7411477565765381\n",
      "Sample 1316 - loss: 4.442996978759766\n",
      "Sample 1317 - loss: 2.430950880050659\n",
      "Sample 1318 - loss: 1.8359254598617554\n",
      "Sample 1319 - loss: 2.5986597537994385\n",
      "Sample 1320 - loss: 8.175793647766113\n",
      "Sample 1321 - loss: 0.26673126220703125\n",
      "Sample 1322 - loss: 0.11649776250123978\n",
      "Sample 1323 - loss: 0.1312524676322937\n",
      "Sample 1324 - loss: 5.637033462524414\n",
      "Sample 1325 - loss: 2.5275046825408936\n",
      "Sample 1326 - loss: 2.7932448387145996\n",
      "Sample 1327 - loss: 5.338158130645752\n",
      "Sample 1328 - loss: 0.09039606899023056\n",
      "Sample 1329 - loss: 8.822212219238281\n",
      "Sample 1330 - loss: 3.5067789554595947\n",
      "Sample 1331 - loss: 9.613313674926758\n",
      "Sample 1332 - loss: 4.89411735534668\n",
      "Sample 1333 - loss: 0.09694909304380417\n",
      "Sample 1334 - loss: 2.1155166625976562\n",
      "Sample 1335 - loss: 0.048415545374155045\n",
      "Sample 1336 - loss: 0.32877442240715027\n",
      "Sample 1337 - loss: 1.1170620918273926\n",
      "Sample 1338 - loss: 9.050522804260254\n",
      "Sample 1339 - loss: 8.892813682556152\n",
      "Sample 1340 - loss: 7.883509635925293\n",
      "Sample 1341 - loss: 3.8364529609680176\n",
      "Sample 1342 - loss: 4.115701675415039\n",
      "Sample 1343 - loss: 2.358240842819214\n",
      "Sample 1344 - loss: 2.4914629459381104\n",
      "Sample 1345 - loss: 4.014657497406006\n",
      "Sample 1346 - loss: 0.2362971156835556\n",
      "Sample 1347 - loss: 2.6867825984954834\n",
      "Sample 1348 - loss: 6.7494354248046875\n",
      "Sample 1349 - loss: 6.7067060470581055\n",
      "Sample 1350 - loss: 10.795209884643555\n",
      "Sample 1351 - loss: 4.398618698120117\n",
      "Sample 1352 - loss: 0.9811226725578308\n",
      "Sample 1353 - loss: 2.8444247245788574\n",
      "Sample 1354 - loss: 10.38612174987793\n",
      "Sample 1355 - loss: 9.616683006286621\n",
      "Sample 1356 - loss: 9.014054298400879\n",
      "Sample 1357 - loss: 5.13410758972168\n",
      "Sample 1358 - loss: 1.7175345420837402\n",
      "Sample 1359 - loss: 7.2088775634765625\n",
      "Sample 1360 - loss: 0.608874499797821\n",
      "Sample 1361 - loss: 1.730770468711853\n",
      "Sample 1362 - loss: 1.148833990097046\n",
      "Sample 1363 - loss: 0.9468196034431458\n",
      "Sample 1364 - loss: 10.493195533752441\n",
      "Sample 1365 - loss: 5.252598285675049\n",
      "Sample 1366 - loss: 5.980335235595703\n",
      "Sample 1367 - loss: 6.864494800567627\n",
      "Sample 1368 - loss: 1.3715275526046753\n",
      "Sample 1369 - loss: 0.10706846415996552\n",
      "Sample 1370 - loss: 0.06644368916749954\n",
      "Sample 1371 - loss: 3.578958511352539\n",
      "Sample 1372 - loss: 0.5915386080741882\n",
      "Sample 1373 - loss: 0.07489064335823059\n",
      "Sample 1374 - loss: 11.158289909362793\n",
      "Sample 1375 - loss: 0.19255898892879486\n",
      "Sample 1376 - loss: 1.1819803714752197\n",
      "Sample 1377 - loss: 3.782463312149048\n",
      "Sample 1378 - loss: 7.402430534362793\n",
      "Sample 1379 - loss: 0.35433128476142883\n",
      "Sample 1380 - loss: 8.117185592651367\n",
      "Sample 1381 - loss: 0.7103720903396606\n",
      "Sample 1382 - loss: 4.231962203979492\n",
      "Sample 1383 - loss: 8.530477523803711\n",
      "Sample 1384 - loss: 6.758526802062988\n",
      "Sample 1385 - loss: 3.9624545574188232\n",
      "Sample 1386 - loss: 0.06739578396081924\n",
      "Sample 1387 - loss: 10.544275283813477\n",
      "Sample 1388 - loss: 4.187379360198975\n",
      "Sample 1389 - loss: 10.66107177734375\n",
      "Sample 1390 - loss: 6.32259464263916\n",
      "Sample 1391 - loss: 1.090135097503662\n",
      "Sample 1392 - loss: 5.31497049331665\n",
      "Sample 1393 - loss: 6.731757640838623\n",
      "Sample 1394 - loss: 1.1162917613983154\n",
      "Sample 1395 - loss: 0.9435310959815979\n",
      "Sample 1396 - loss: 7.3393449783325195\n",
      "Sample 1397 - loss: 4.427168369293213\n",
      "Sample 1398 - loss: 1.4670569896697998\n",
      "Sample 1399 - loss: 9.980273246765137\n",
      "Sample 1400 - loss: 3.0724399089813232\n",
      "Sample 1401 - loss: 4.380725860595703\n",
      "Sample 1402 - loss: 0.3807625472545624\n",
      "Sample 1403 - loss: 1.64213228225708\n",
      "Sample 1404 - loss: 6.909090518951416\n",
      "Sample 1405 - loss: 0.2787158191204071\n",
      "Sample 1406 - loss: 0.04803862050175667\n",
      "Sample 1407 - loss: 0.40746864676475525\n",
      "Sample 1408 - loss: 4.0422163009643555\n",
      "Sample 1409 - loss: 0.34534239768981934\n",
      "Sample 1410 - loss: 5.907244682312012\n",
      "Sample 1411 - loss: 1.937599539756775\n",
      "Sample 1412 - loss: 6.120655536651611\n",
      "Sample 1413 - loss: 0.6555697917938232\n",
      "Sample 1414 - loss: 0.023745892569422722\n",
      "Sample 1415 - loss: 6.2851762771606445\n",
      "Sample 1416 - loss: 0.04303387552499771\n",
      "Sample 1417 - loss: 0.2621954083442688\n",
      "Sample 1418 - loss: 5.604510307312012\n",
      "Sample 1419 - loss: 9.274249076843262\n",
      "Sample 1420 - loss: 6.19772481918335\n",
      "Sample 1421 - loss: 0.38279345631599426\n",
      "Sample 1422 - loss: 3.8298065662384033\n",
      "Sample 1423 - loss: 9.391463279724121\n",
      "Sample 1424 - loss: 0.7064144015312195\n",
      "Sample 1425 - loss: 2.321580171585083\n",
      "Sample 1426 - loss: 4.535167217254639\n",
      "Sample 1427 - loss: 1.5124118328094482\n",
      "Sample 1428 - loss: 5.954298496246338\n",
      "Sample 1429 - loss: 7.474234580993652\n",
      "Sample 1430 - loss: 1.206183671951294\n",
      "Sample 1431 - loss: 1.0782866477966309\n",
      "Sample 1432 - loss: 4.618243217468262\n",
      "Sample 1433 - loss: 10.423449516296387\n",
      "Sample 1434 - loss: 4.746427536010742\n",
      "Sample 1435 - loss: 1.8968610763549805\n",
      "Sample 1436 - loss: 6.685124397277832\n",
      "Sample 1437 - loss: 0.24925321340560913\n",
      "Sample 1438 - loss: 9.739336967468262\n",
      "Sample 1439 - loss: 0.21414701640605927\n",
      "Sample 1440 - loss: 9.217329025268555\n",
      "Sample 1441 - loss: 0.38959163427352905\n",
      "Sample 1442 - loss: 7.209051609039307\n",
      "Sample 1443 - loss: 5.989428520202637\n",
      "Sample 1444 - loss: 3.6985950469970703\n",
      "Sample 1445 - loss: 0.795561671257019\n",
      "Sample 1446 - loss: 0.016522299498319626\n",
      "Sample 1447 - loss: 8.656482696533203\n",
      "Sample 1448 - loss: 6.076654434204102\n",
      "Sample 1449 - loss: 0.11651850491762161\n",
      "Sample 1450 - loss: 0.23367378115653992\n",
      "Sample 1451 - loss: 1.4881651401519775\n",
      "Sample 1452 - loss: 3.7863614559173584\n",
      "Sample 1453 - loss: 0.26945820450782776\n",
      "Sample 1454 - loss: 11.147482872009277\n",
      "Sample 1455 - loss: 0.5176176428794861\n",
      "Sample 1456 - loss: 6.089378833770752\n",
      "Sample 1457 - loss: 0.28860408067703247\n",
      "Sample 1458 - loss: 0.8115972280502319\n",
      "Sample 1459 - loss: 0.357178270816803\n",
      "Sample 1460 - loss: 3.6568634510040283\n",
      "Sample 1461 - loss: 11.050263404846191\n",
      "Sample 1462 - loss: 9.140117645263672\n",
      "Sample 1463 - loss: 0.12171705067157745\n",
      "Sample 1464 - loss: 7.65631103515625\n",
      "Sample 1465 - loss: 0.5686509609222412\n",
      "Sample 1466 - loss: 0.8512433767318726\n",
      "Sample 1467 - loss: 12.345702171325684\n",
      "Sample 1468 - loss: 0.9719592928886414\n",
      "Sample 1469 - loss: 8.571464538574219\n",
      "Sample 1470 - loss: 2.383601427078247\n",
      "Sample 1471 - loss: 0.8085315823554993\n",
      "Sample 1472 - loss: 5.237829208374023\n",
      "Sample 1473 - loss: 4.3675947189331055\n",
      "Sample 1474 - loss: 1.202501893043518\n",
      "Sample 1475 - loss: 3.4390065670013428\n",
      "Sample 1476 - loss: 1.943983793258667\n",
      "Sample 1477 - loss: 9.241769790649414\n",
      "Sample 1478 - loss: 6.481076240539551\n",
      "Sample 1479 - loss: 5.119064807891846\n",
      "Sample 1480 - loss: 1.1464568376541138\n",
      "Sample 1481 - loss: 0.1465713232755661\n",
      "Sample 1482 - loss: 7.100927829742432\n",
      "Sample 1483 - loss: 2.9981319904327393\n",
      "Sample 1484 - loss: 10.68918228149414\n",
      "Sample 1485 - loss: 13.634984970092773\n",
      "Sample 1486 - loss: 0.050614651292562485\n",
      "Sample 1487 - loss: 0.19651174545288086\n",
      "Sample 1488 - loss: 10.068231582641602\n",
      "Sample 1489 - loss: 1.919291377067566\n",
      "Sample 1490 - loss: 7.411450386047363\n",
      "Sample 1491 - loss: 3.764529228210449\n",
      "Sample 1492 - loss: 5.3728928565979\n",
      "Sample 1493 - loss: 1.021310567855835\n",
      "Sample 1494 - loss: 0.44713330268859863\n",
      "Sample 1495 - loss: 7.033696174621582\n",
      "Sample 1496 - loss: 1.141216516494751\n",
      "Sample 1497 - loss: 0.4508393108844757\n",
      "Sample 1498 - loss: 0.10693883150815964\n",
      "Sample 1499 - loss: 7.150970935821533\n",
      "Sample 1500 - loss: 0.12001759558916092\n",
      "Sample 1501 - loss: 0.0481928214430809\n",
      "Sample 1502 - loss: 0.18427042663097382\n",
      "Sample 1503 - loss: 8.064164161682129\n",
      "Sample 1504 - loss: 0.05865123122930527\n",
      "Sample 1505 - loss: 2.2501559257507324\n",
      "Sample 1506 - loss: 0.07933782786130905\n",
      "Sample 1507 - loss: 9.578171730041504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1508 - loss: 2.6481761932373047\n",
      "Sample 1509 - loss: 0.2853509783744812\n",
      "Sample 1510 - loss: 7.555361270904541\n",
      "Sample 1511 - loss: 5.415019989013672\n",
      "Sample 1512 - loss: 6.781798839569092\n",
      "Sample 1513 - loss: 8.066425323486328\n",
      "Sample 1514 - loss: 2.6477255821228027\n",
      "Sample 1515 - loss: 0.6268280148506165\n",
      "Sample 1516 - loss: 1.5581163167953491\n",
      "Sample 1517 - loss: 3.7102301120758057\n",
      "Sample 1518 - loss: 0.06601014733314514\n",
      "Sample 1519 - loss: 7.451640605926514\n",
      "Sample 1520 - loss: 0.07446747273206711\n",
      "Sample 1521 - loss: 0.6720986366271973\n",
      "Sample 1522 - loss: 0.29902705550193787\n",
      "Sample 1523 - loss: 5.184765815734863\n",
      "Sample 1524 - loss: 0.17273086309432983\n",
      "Sample 1525 - loss: 4.090208530426025\n",
      "Sample 1526 - loss: 11.356894493103027\n",
      "Sample 1527 - loss: 8.491116523742676\n",
      "Sample 1528 - loss: 7.6378960609436035\n",
      "Sample 1529 - loss: 4.73820686340332\n",
      "Sample 1530 - loss: 1.9603071212768555\n",
      "Sample 1531 - loss: 6.928829193115234\n",
      "Sample 1532 - loss: 0.14384281635284424\n",
      "Sample 1533 - loss: 1.789251446723938\n",
      "Sample 1534 - loss: 3.9914777278900146\n",
      "Sample 1535 - loss: 8.15429973602295\n",
      "Sample 1536 - loss: 0.5292472243309021\n",
      "Sample 1537 - loss: 7.263670444488525\n",
      "Sample 1538 - loss: 5.644552230834961\n",
      "Sample 1539 - loss: 8.368041038513184\n",
      "Sample 1540 - loss: 0.05411483719944954\n",
      "Sample 1541 - loss: 0.03224989399313927\n",
      "Sample 1542 - loss: 3.2038309574127197\n",
      "Sample 1543 - loss: 0.15863819420337677\n",
      "Sample 1544 - loss: 0.7986623644828796\n",
      "Sample 1545 - loss: 0.22619886696338654\n",
      "Sample 1546 - loss: 0.28106698393821716\n",
      "Sample 1547 - loss: 1.8304872512817383\n",
      "Sample 1548 - loss: 0.9138253927230835\n",
      "Sample 1549 - loss: 7.144154071807861\n",
      "Sample 1550 - loss: 0.5214366912841797\n",
      "Sample 1551 - loss: 1.1191778182983398\n",
      "Sample 1552 - loss: 13.199536323547363\n",
      "Sample 1553 - loss: 4.427887439727783\n",
      "Sample 1554 - loss: 1.3472131490707397\n",
      "Sample 1555 - loss: 1.514777660369873\n",
      "Sample 1556 - loss: 1.295255184173584\n",
      "Sample 1557 - loss: 11.264631271362305\n",
      "Sample 1558 - loss: 2.9217450618743896\n",
      "Sample 1559 - loss: 2.9550163745880127\n",
      "Sample 1560 - loss: 6.127188682556152\n",
      "Sample 1561 - loss: 7.087578296661377\n",
      "Sample 1562 - loss: 1.6563785076141357\n",
      "Sample 1563 - loss: 2.234067440032959\n",
      "Sample 1564 - loss: 3.9256584644317627\n",
      "Sample 1565 - loss: 0.14969953894615173\n",
      "Sample 1566 - loss: 6.532313823699951\n",
      "Sample 1567 - loss: 6.332269191741943\n",
      "Sample 1568 - loss: 9.399216651916504\n",
      "Sample 1569 - loss: 2.1707422733306885\n",
      "Sample 1570 - loss: 3.563868999481201\n",
      "Sample 1571 - loss: 0.7219579219818115\n",
      "Sample 1572 - loss: 0.029904065653681755\n",
      "Sample 1573 - loss: 10.918525695800781\n",
      "Sample 1574 - loss: 3.31498384475708\n",
      "Sample 1575 - loss: 2.8765759468078613\n",
      "Sample 1576 - loss: 0.420089989900589\n",
      "Sample 1577 - loss: 1.7042959928512573\n",
      "Sample 1578 - loss: 0.7068532705307007\n",
      "Sample 1579 - loss: 6.092464447021484\n",
      "Sample 1580 - loss: 3.8674449920654297\n",
      "Sample 1581 - loss: 4.544328689575195\n",
      "Sample 1582 - loss: 6.264107704162598\n",
      "Sample 1583 - loss: 5.745542049407959\n",
      "Sample 1584 - loss: 1.4468094110488892\n",
      "Sample 1585 - loss: 12.440069198608398\n",
      "Sample 1586 - loss: 9.233614921569824\n",
      "Sample 1587 - loss: 3.00972843170166\n",
      "Sample 1588 - loss: 8.531388282775879\n",
      "Sample 1589 - loss: 0.05754729360342026\n",
      "Sample 1590 - loss: 2.530066728591919\n",
      "Sample 1591 - loss: 1.4396388530731201\n",
      "Sample 1592 - loss: 0.37334173917770386\n",
      "Sample 1593 - loss: 0.42267417907714844\n",
      "Sample 1594 - loss: 3.9146499633789062\n",
      "Sample 1595 - loss: 0.800639808177948\n",
      "Sample 1596 - loss: 5.5529255867004395\n",
      "Sample 1597 - loss: 0.18272113800048828\n",
      "Sample 1598 - loss: 10.68700885772705\n",
      "Sample 1599 - loss: 0.7462727427482605\n",
      "Sample 1600 - loss: 1.541243553161621\n",
      "Sample 1601 - loss: 0.06674975156784058\n",
      "Sample 1602 - loss: 6.865439414978027\n",
      "Sample 1603 - loss: 1.52463698387146\n",
      "Sample 1604 - loss: 2.696773052215576\n",
      "Sample 1605 - loss: 0.1025799959897995\n",
      "Sample 1606 - loss: 2.32119083404541\n",
      "Sample 1607 - loss: 9.168907165527344\n",
      "Sample 1608 - loss: 8.74157428741455\n",
      "Sample 1609 - loss: 0.9185218811035156\n",
      "Sample 1610 - loss: 2.5708770751953125\n",
      "Sample 1611 - loss: 0.8569392561912537\n",
      "Sample 1612 - loss: 0.6760673522949219\n",
      "Sample 1613 - loss: 7.288532257080078\n",
      "Sample 1614 - loss: 0.011622249148786068\n",
      "Sample 1615 - loss: 1.1779725551605225\n",
      "Sample 1616 - loss: 5.877284526824951\n",
      "Sample 1617 - loss: 6.637904167175293\n",
      "Sample 1618 - loss: 0.35392895340919495\n",
      "Sample 1619 - loss: 0.4427739381790161\n",
      "Sample 1620 - loss: 0.14722123742103577\n",
      "Sample 1621 - loss: 13.316401481628418\n",
      "Sample 1622 - loss: 1.6131727695465088\n",
      "Sample 1623 - loss: 1.0614359378814697\n",
      "Sample 1624 - loss: 4.84811544418335\n",
      "Sample 1625 - loss: 1.8719326257705688\n",
      "Sample 1626 - loss: 5.669764518737793\n",
      "Sample 1627 - loss: 8.599176406860352\n",
      "Sample 1628 - loss: 4.051948070526123\n",
      "Sample 1629 - loss: 12.011696815490723\n",
      "Sample 1630 - loss: 15.168283462524414\n",
      "Sample 1631 - loss: 1.7788009643554688\n",
      "Sample 1632 - loss: 9.956804275512695\n",
      "Sample 1633 - loss: 1.9060581922531128\n",
      "Sample 1634 - loss: 2.7012391090393066\n",
      "Sample 1635 - loss: 6.181866645812988\n",
      "Sample 1636 - loss: 3.1054604053497314\n",
      "Sample 1637 - loss: 2.898287057876587\n",
      "Sample 1638 - loss: 10.288496971130371\n",
      "Sample 1639 - loss: 3.035160779953003\n",
      "Sample 1640 - loss: 0.8737560510635376\n",
      "Sample 1641 - loss: 4.979966163635254\n",
      "Sample 1642 - loss: 7.187457084655762\n",
      "Sample 1643 - loss: 8.377801895141602\n",
      "Sample 1644 - loss: 2.995859146118164\n",
      "Sample 1645 - loss: 1.4986392259597778\n",
      "Sample 1646 - loss: 0.19898605346679688\n",
      "Sample 1647 - loss: 1.7032709121704102\n",
      "Sample 1648 - loss: 3.7055487632751465\n",
      "Sample 1649 - loss: 7.041315078735352\n",
      "Sample 1650 - loss: 5.1074957847595215\n",
      "Sample 1651 - loss: 0.029194466769695282\n",
      "Sample 1652 - loss: 0.18768467009067535\n",
      "Sample 1653 - loss: 3.601891279220581\n",
      "Sample 1654 - loss: 11.806737899780273\n",
      "Sample 1655 - loss: 0.10007867217063904\n",
      "Sample 1656 - loss: 1.1463619470596313\n",
      "Sample 1657 - loss: 0.016255352646112442\n",
      "Sample 1658 - loss: 3.8348052501678467\n",
      "Sample 1659 - loss: 1.2637064456939697\n",
      "Sample 1660 - loss: 2.272885322570801\n",
      "Sample 1661 - loss: 0.19040293991565704\n",
      "Sample 1662 - loss: 1.4136838912963867\n",
      "Sample 1663 - loss: 2.337986707687378\n",
      "Sample 1664 - loss: 2.168175458908081\n",
      "Sample 1665 - loss: 6.015240669250488\n",
      "Sample 1666 - loss: 1.1006221771240234\n",
      "Sample 1667 - loss: 1.084884524345398\n",
      "Sample 1668 - loss: 10.440337181091309\n",
      "Sample 1669 - loss: 6.764995574951172\n",
      "Sample 1670 - loss: 0.3695242404937744\n",
      "Sample 1671 - loss: 1.109757423400879\n",
      "Sample 1672 - loss: 0.13218921422958374\n",
      "Sample 1673 - loss: 0.6516103148460388\n",
      "Sample 1674 - loss: 6.892086029052734\n",
      "Sample 1675 - loss: 3.0548388957977295\n",
      "Sample 1676 - loss: 0.04036072641611099\n",
      "Sample 1677 - loss: 4.640242099761963\n",
      "Sample 1678 - loss: 5.773467540740967\n",
      "Sample 1679 - loss: 0.09728118777275085\n",
      "Sample 1680 - loss: 0.04672586917877197\n",
      "Sample 1681 - loss: 2.437040090560913\n",
      "Sample 1682 - loss: 1.3945038318634033\n",
      "Sample 1683 - loss: 3.7577829360961914\n",
      "Sample 1684 - loss: 3.8822879791259766\n",
      "Sample 1685 - loss: 2.6643762588500977\n",
      "Sample 1686 - loss: 4.5793657302856445\n",
      "Sample 1687 - loss: 0.5993373990058899\n",
      "Sample 1688 - loss: 3.608982563018799\n",
      "Sample 1689 - loss: 4.6995015144348145\n",
      "Sample 1690 - loss: 0.012558186426758766\n",
      "Sample 1691 - loss: 1.7490241527557373\n",
      "Sample 1692 - loss: 0.3621305823326111\n",
      "Sample 1693 - loss: 3.104628801345825\n",
      "Sample 1694 - loss: 9.171723365783691\n",
      "Sample 1695 - loss: 3.317751884460449\n",
      "Sample 1696 - loss: 0.8937115669250488\n",
      "Sample 1697 - loss: 4.173366069793701\n",
      "Sample 1698 - loss: 7.738006591796875\n",
      "Sample 1699 - loss: 5.4041924476623535\n",
      "Sample 1700 - loss: 7.437356948852539\n",
      "Sample 1701 - loss: 5.501222133636475\n",
      "Sample 1702 - loss: 1.625773310661316\n",
      "Sample 1703 - loss: 0.2629493772983551\n",
      "Sample 1704 - loss: 0.1701701134443283\n",
      "Sample 1705 - loss: 4.671779632568359\n",
      "Sample 1706 - loss: 12.579550743103027\n",
      "Sample 1707 - loss: 0.07946354150772095\n",
      "Sample 1708 - loss: 8.624709129333496\n",
      "Sample 1709 - loss: 4.599391937255859\n",
      "Sample 1710 - loss: 5.013540267944336\n",
      "Sample 1711 - loss: 0.5015627145767212\n",
      "Sample 1712 - loss: 1.080154299736023\n",
      "Sample 1713 - loss: 6.318208694458008\n",
      "Sample 1714 - loss: 3.3332343101501465\n",
      "Sample 1715 - loss: 8.86262321472168\n",
      "Sample 1716 - loss: 1.724272608757019\n",
      "Sample 1717 - loss: 3.531015634536743\n",
      "Sample 1718 - loss: 0.048672229051589966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1719 - loss: 7.49069881439209\n",
      "Sample 1720 - loss: 4.834867000579834\n",
      "Sample 1721 - loss: 4.316546440124512\n",
      "Sample 1722 - loss: 10.449579238891602\n",
      "Sample 1723 - loss: 0.0937257707118988\n",
      "Sample 1724 - loss: 0.9532036781311035\n",
      "Sample 1725 - loss: 0.03810171037912369\n",
      "Sample 1726 - loss: 0.021877145394682884\n",
      "Sample 1727 - loss: 8.315752029418945\n",
      "Sample 1728 - loss: 7.548727989196777\n",
      "Sample 1729 - loss: 1.8858188390731812\n",
      "Sample 1730 - loss: 0.11534395068883896\n",
      "Sample 1731 - loss: 0.7976087331771851\n",
      "Sample 1732 - loss: 4.270883083343506\n",
      "Sample 1733 - loss: 9.780811309814453\n",
      "Sample 1734 - loss: 1.7073354721069336\n",
      "Sample 1735 - loss: 0.013376329094171524\n",
      "Sample 1736 - loss: 8.607697486877441\n",
      "Sample 1737 - loss: 2.2999508380889893\n",
      "Sample 1738 - loss: 4.765040397644043\n",
      "Sample 1739 - loss: 2.974398136138916\n",
      "Sample 1740 - loss: 6.465885639190674\n",
      "Sample 1741 - loss: 2.0288853645324707\n",
      "Sample 1742 - loss: 3.2981555461883545\n",
      "Sample 1743 - loss: 11.783700942993164\n",
      "Sample 1744 - loss: 1.5788229703903198\n",
      "Sample 1745 - loss: 0.6977182030677795\n",
      "Sample 1746 - loss: 0.4168110191822052\n",
      "Sample 1747 - loss: 5.1865949630737305\n",
      "Sample 1748 - loss: 0.022412020713090897\n",
      "Sample 1749 - loss: 0.7528259754180908\n",
      "Sample 1750 - loss: 0.011367673985660076\n",
      "Sample 1751 - loss: 0.09551034867763519\n",
      "Sample 1752 - loss: 8.983467102050781\n",
      "Sample 1753 - loss: 2.900951862335205\n",
      "Sample 1754 - loss: 1.6895757913589478\n",
      "Sample 1755 - loss: 10.22490406036377\n",
      "Sample 1756 - loss: 9.997036933898926\n",
      "Sample 1757 - loss: 4.480952262878418\n",
      "Sample 1758 - loss: 1.4353506565093994\n",
      "Sample 1759 - loss: 6.220040798187256\n",
      "Sample 1760 - loss: 7.921787261962891\n",
      "Sample 1761 - loss: 2.497037410736084\n",
      "Sample 1762 - loss: 5.3031110763549805\n",
      "Sample 1763 - loss: 1.8372923135757446\n",
      "Sample 1764 - loss: 2.841217041015625\n",
      "Sample 1765 - loss: 2.18354868888855\n",
      "Sample 1766 - loss: 10.492127418518066\n",
      "Sample 1767 - loss: 10.072305679321289\n",
      "Sample 1768 - loss: 1.0073493719100952\n",
      "Sample 1769 - loss: 1.1067763566970825\n",
      "Sample 1770 - loss: 4.116818428039551\n",
      "Sample 1771 - loss: 0.1495041698217392\n",
      "Sample 1772 - loss: 0.19620084762573242\n",
      "Sample 1773 - loss: 0.18750450015068054\n",
      "Sample 1774 - loss: 5.694333553314209\n",
      "Sample 1775 - loss: 3.5542654991149902\n",
      "Sample 1776 - loss: 2.094050645828247\n",
      "Sample 1777 - loss: 8.843149185180664\n",
      "Sample 1778 - loss: 1.8637996912002563\n",
      "Sample 1779 - loss: 1.4236451387405396\n",
      "Sample 1780 - loss: 0.773662805557251\n",
      "Sample 1781 - loss: 4.203813076019287\n",
      "Sample 1782 - loss: 0.15520070493221283\n",
      "Sample 1783 - loss: 11.322919845581055\n",
      "Sample 1784 - loss: 4.697977542877197\n",
      "Sample 1785 - loss: 6.877875804901123\n",
      "Sample 1786 - loss: 4.706339359283447\n",
      "Sample 1787 - loss: 2.175562858581543\n",
      "Sample 1788 - loss: 3.428598403930664\n",
      "Sample 1789 - loss: 0.43923231959342957\n",
      "Sample 1790 - loss: 14.107525825500488\n",
      "Sample 1791 - loss: 1.2303003072738647\n",
      "Sample 1792 - loss: 1.052014946937561\n",
      "Sample 1793 - loss: 5.454742908477783\n",
      "Sample 1794 - loss: 2.4605400562286377\n",
      "Sample 1795 - loss: 3.623906135559082\n",
      "Sample 1796 - loss: 1.000747561454773\n",
      "Sample 1797 - loss: 10.307703971862793\n",
      "Sample 1798 - loss: 10.206168174743652\n",
      "Sample 1799 - loss: 3.2946693897247314\n",
      "Sample 1800 - loss: 0.1305631846189499\n",
      "Sample 1801 - loss: 1.2238234281539917\n",
      "Sample 1802 - loss: 1.9228568077087402\n",
      "Sample 1803 - loss: 1.7268060445785522\n",
      "Sample 1804 - loss: 6.498456954956055\n",
      "Sample 1805 - loss: 0.9838047623634338\n",
      "Sample 1806 - loss: 1.5819604396820068\n",
      "Sample 1807 - loss: 1.57572603225708\n",
      "Sample 1808 - loss: 12.309734344482422\n",
      "Sample 1809 - loss: 1.2333829402923584\n",
      "Sample 1810 - loss: 1.1454248428344727\n",
      "Sample 1811 - loss: 0.6144011616706848\n",
      "Sample 1812 - loss: 5.9193806648254395\n",
      "Sample 1813 - loss: 0.11315785348415375\n",
      "Sample 1814 - loss: 3.4566736221313477\n",
      "Sample 1815 - loss: 0.0400606207549572\n",
      "Sample 1816 - loss: 0.3018067479133606\n",
      "Sample 1817 - loss: 7.3458075523376465\n",
      "Sample 1818 - loss: 0.6561187505722046\n",
      "Sample 1819 - loss: 0.22640080749988556\n",
      "Sample 1820 - loss: 4.360355854034424\n",
      "Sample 1821 - loss: 8.77406120300293\n",
      "Sample 1822 - loss: 5.337342739105225\n",
      "Sample 1823 - loss: 11.637255668640137\n",
      "Sample 1824 - loss: 4.472562789916992\n",
      "Sample 1825 - loss: 2.6484384536743164\n",
      "Sample 1826 - loss: 0.058036819100379944\n",
      "Sample 1827 - loss: 12.31344223022461\n",
      "Sample 1828 - loss: 5.9269537925720215\n",
      "Sample 1829 - loss: 5.8643903732299805\n",
      "Sample 1830 - loss: 3.049013376235962\n",
      "Sample 1831 - loss: 13.145513534545898\n",
      "Sample 1832 - loss: 0.2056947946548462\n",
      "Sample 1833 - loss: 0.27984678745269775\n",
      "Sample 1834 - loss: 2.0285050868988037\n",
      "Sample 1835 - loss: 3.7006049156188965\n",
      "Sample 1836 - loss: 0.2788013815879822\n",
      "Sample 1837 - loss: 3.0948402881622314\n",
      "Sample 1838 - loss: 1.7066575288772583\n",
      "Sample 1839 - loss: 3.1572210788726807\n",
      "Sample 1840 - loss: 10.779901504516602\n",
      "Sample 1841 - loss: 0.8322970867156982\n",
      "Sample 1842 - loss: 1.428400993347168\n",
      "Sample 1843 - loss: 0.040682923048734665\n",
      "Sample 1844 - loss: 3.8319265842437744\n",
      "Sample 1845 - loss: 1.399713158607483\n",
      "Sample 1846 - loss: 0.24207209050655365\n",
      "Sample 1847 - loss: 3.046405076980591\n",
      "Sample 1848 - loss: 0.4220312237739563\n",
      "Sample 1849 - loss: 0.40972092747688293\n",
      "Sample 1850 - loss: 12.715948104858398\n",
      "Sample 1851 - loss: 2.3208119869232178\n",
      "Sample 1852 - loss: 6.516053676605225\n",
      "Sample 1853 - loss: 5.976634979248047\n",
      "Sample 1854 - loss: 3.983203411102295\n",
      "Sample 1855 - loss: 12.769020080566406\n",
      "Sample 1856 - loss: 1.6547945737838745\n",
      "Sample 1857 - loss: 5.502331733703613\n",
      "Sample 1858 - loss: 12.792075157165527\n",
      "Sample 1859 - loss: 0.6756916046142578\n",
      "Sample 1860 - loss: 0.8724468350410461\n",
      "Sample 1861 - loss: 4.351607322692871\n",
      "Sample 1862 - loss: 1.461029052734375\n",
      "Sample 1863 - loss: 9.03054141998291\n",
      "Sample 1864 - loss: 2.940246820449829\n",
      "Sample 1865 - loss: 4.222856521606445\n",
      "Sample 1866 - loss: 3.8612375259399414\n",
      "Sample 1867 - loss: 9.866293907165527\n",
      "Sample 1868 - loss: 1.0324559211730957\n",
      "Sample 1869 - loss: 0.9964926242828369\n",
      "Sample 1870 - loss: 0.10974089801311493\n",
      "Sample 1871 - loss: 5.0614914894104\n",
      "Sample 1872 - loss: 0.12987612187862396\n",
      "Sample 1873 - loss: 0.08537250757217407\n",
      "Sample 1874 - loss: 4.1824049949646\n",
      "Sample 1875 - loss: 0.04957982152700424\n",
      "Sample 1876 - loss: 7.668651580810547\n",
      "Sample 1877 - loss: 6.120583534240723\n",
      "Sample 1878 - loss: 4.4450788497924805\n",
      "Sample 1879 - loss: 0.8189427256584167\n",
      "Sample 1880 - loss: 8.956724166870117\n",
      "Sample 1881 - loss: 6.613194465637207\n",
      "Sample 1882 - loss: 2.727569818496704\n",
      "Sample 1883 - loss: 0.17132116854190826\n",
      "Sample 1884 - loss: 0.49387240409851074\n",
      "Sample 1885 - loss: 0.7062766551971436\n",
      "Sample 1886 - loss: 0.04394172132015228\n",
      "Sample 1887 - loss: 8.256643295288086\n",
      "Sample 1888 - loss: 10.543318748474121\n",
      "Sample 1889 - loss: 3.896693706512451\n",
      "Sample 1890 - loss: 3.585524559020996\n",
      "Sample 1891 - loss: 8.189436912536621\n",
      "Sample 1892 - loss: 2.9597723484039307\n",
      "Sample 1893 - loss: 0.13308478891849518\n",
      "Sample 1894 - loss: 9.865348815917969\n",
      "Sample 1895 - loss: 2.031623363494873\n",
      "Sample 1896 - loss: 1.0968451499938965\n",
      "Sample 1897 - loss: 12.086895942687988\n",
      "Sample 1898 - loss: 5.672112941741943\n",
      "Sample 1899 - loss: 0.44575756788253784\n",
      "Sample 1900 - loss: 4.687785625457764\n",
      "Sample 1901 - loss: 6.837058067321777\n",
      "Sample 1902 - loss: 0.060845665633678436\n",
      "Sample 1903 - loss: 0.34044724702835083\n",
      "Sample 1904 - loss: 8.867794036865234\n",
      "Sample 1905 - loss: 1.4955347776412964\n",
      "Sample 1906 - loss: 3.0160512924194336\n",
      "Sample 1907 - loss: 0.8602821230888367\n",
      "Sample 1908 - loss: 4.657696723937988\n",
      "Sample 1909 - loss: 2.511394739151001\n",
      "Sample 1910 - loss: 3.5942578315734863\n",
      "Sample 1911 - loss: 0.2929617762565613\n",
      "Sample 1912 - loss: 0.07580405473709106\n",
      "Sample 1913 - loss: 0.06832879781723022\n",
      "Sample 1914 - loss: 8.689658164978027\n",
      "Sample 1915 - loss: 0.08552809804677963\n",
      "Sample 1916 - loss: 1.0026339292526245\n",
      "Sample 1917 - loss: 6.531450271606445\n",
      "Sample 1918 - loss: 0.9786064624786377\n",
      "Sample 1919 - loss: 5.2232136726379395\n",
      "Sample 1920 - loss: 7.214784145355225\n",
      "Sample 1921 - loss: 8.191468238830566\n",
      "Sample 1922 - loss: 0.05520031601190567\n",
      "Sample 1923 - loss: 2.5335848331451416\n",
      "Sample 1924 - loss: 2.591710090637207\n",
      "Sample 1925 - loss: 1.6251276731491089\n",
      "Sample 1926 - loss: 0.6427942514419556\n",
      "Sample 1927 - loss: 2.9730639457702637\n",
      "Sample 1928 - loss: 7.478638172149658\n",
      "Sample 1929 - loss: 0.8492935299873352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1930 - loss: 5.4095869064331055\n",
      "Sample 1931 - loss: 3.7497363090515137\n",
      "Sample 1932 - loss: 3.7070298194885254\n",
      "Sample 1933 - loss: 7.857230186462402\n",
      "Sample 1934 - loss: 7.535129547119141\n",
      "Sample 1935 - loss: 8.296435356140137\n",
      "Sample 1936 - loss: 4.477169036865234\n",
      "Sample 1937 - loss: 0.058912526816129684\n",
      "Sample 1938 - loss: 5.370750904083252\n",
      "Sample 1939 - loss: 2.030932903289795\n",
      "Sample 1940 - loss: 3.3806638717651367\n",
      "Sample 1941 - loss: 0.17607350647449493\n",
      "Sample 1942 - loss: 0.8754231929779053\n",
      "Sample 1943 - loss: 2.297161102294922\n",
      "Sample 1944 - loss: 0.08832790702581406\n",
      "Sample 1945 - loss: 4.594562530517578\n",
      "Sample 1946 - loss: 10.821863174438477\n",
      "Sample 1947 - loss: 2.856387138366699\n",
      "Sample 1948 - loss: 3.8506436347961426\n",
      "Sample 1949 - loss: 4.4152140617370605\n",
      "Sample 1950 - loss: 0.8922690749168396\n",
      "Sample 1951 - loss: 1.0876455307006836\n",
      "Sample 1952 - loss: 2.9242734909057617\n",
      "Sample 1953 - loss: 4.170801162719727\n",
      "Sample 1954 - loss: 3.594228744506836\n",
      "Sample 1955 - loss: 7.021543979644775\n",
      "Sample 1956 - loss: 11.167699813842773\n",
      "Sample 1957 - loss: 6.907968521118164\n",
      "Sample 1958 - loss: 0.044974733144044876\n",
      "Sample 1959 - loss: 1.2471941709518433\n",
      "Sample 1960 - loss: 1.123266339302063\n",
      "Sample 1961 - loss: 8.747904777526855\n",
      "Sample 1962 - loss: 0.1161665990948677\n",
      "Sample 1963 - loss: 9.66150951385498\n",
      "Sample 1964 - loss: 5.417322158813477\n",
      "Sample 1965 - loss: 0.08310913294553757\n",
      "Sample 1966 - loss: 5.5487494468688965\n",
      "Sample 1967 - loss: 10.715849876403809\n",
      "Sample 1968 - loss: 8.311701774597168\n",
      "Sample 1969 - loss: 0.20735697448253632\n",
      "Sample 1970 - loss: 2.650989055633545\n",
      "Sample 1971 - loss: 10.037525177001953\n",
      "Sample 1972 - loss: 0.4044303596019745\n",
      "Sample 1973 - loss: 5.378004550933838\n",
      "Sample 1974 - loss: 0.07376942783594131\n",
      "Sample 1975 - loss: 12.673613548278809\n",
      "Sample 1976 - loss: 0.6171438097953796\n",
      "Sample 1977 - loss: 6.995038032531738\n",
      "Sample 1978 - loss: 0.11746636033058167\n",
      "Sample 1979 - loss: 4.476963996887207\n",
      "Sample 1980 - loss: 1.2730368375778198\n",
      "Sample 1981 - loss: 4.304069995880127\n",
      "Sample 1982 - loss: 2.1553640365600586\n",
      "Sample 1983 - loss: 4.8538031578063965\n",
      "Sample 1984 - loss: 6.694840908050537\n",
      "Sample 1985 - loss: 2.0503151416778564\n",
      "Sample 1986 - loss: 0.24951639771461487\n",
      "Sample 1987 - loss: 4.828921318054199\n",
      "Sample 1988 - loss: 0.10153233259916306\n",
      "Sample 1989 - loss: 2.1592507362365723\n",
      "Sample 1990 - loss: 2.509089946746826\n",
      "Sample 1991 - loss: 5.060688018798828\n",
      "Sample 1992 - loss: 3.4958865642547607\n",
      "Sample 1993 - loss: 4.756515979766846\n",
      "Sample 1994 - loss: 0.05870915949344635\n",
      "Sample 1995 - loss: 3.9221553802490234\n",
      "Sample 1996 - loss: 2.529360771179199\n",
      "Sample 1997 - loss: 0.8038695454597473\n",
      "Sample 1998 - loss: 2.3567726612091064\n",
      "Sample 1999 - loss: 0.7133200764656067\n",
      "Sample 2000 - loss: 3.827972173690796\n",
      "Sample 2001 - loss: 0.7474974989891052\n",
      "Sample 2002 - loss: 0.3506971299648285\n",
      "Sample 2003 - loss: 9.728240966796875\n",
      "Sample 2004 - loss: 4.880749702453613\n",
      "Sample 2005 - loss: 6.0569024085998535\n",
      "Sample 2006 - loss: 2.352184534072876\n",
      "Sample 2007 - loss: 3.5096490383148193\n",
      "Sample 2008 - loss: 0.10342710465192795\n",
      "Sample 2009 - loss: 1.7534921169281006\n",
      "Sample 2010 - loss: 3.4209296703338623\n",
      "Sample 2011 - loss: 0.32025936245918274\n",
      "Sample 2012 - loss: 0.7138470411300659\n",
      "Sample 2013 - loss: 2.462848424911499\n",
      "Sample 2014 - loss: 3.2240447998046875\n",
      "Sample 2015 - loss: 2.7090847492218018\n",
      "Sample 2016 - loss: 4.933714389801025\n",
      "Sample 2017 - loss: 4.752748489379883\n",
      "Sample 2018 - loss: 1.5676835775375366\n",
      "Sample 2019 - loss: 8.24230670928955\n",
      "Sample 2020 - loss: 0.0827617421746254\n",
      "Sample 2021 - loss: 10.548623085021973\n",
      "Sample 2022 - loss: 5.787436008453369\n",
      "Sample 2023 - loss: 3.0691280364990234\n",
      "Sample 2024 - loss: 4.028667449951172\n",
      "Sample 2025 - loss: 3.5290796756744385\n",
      "Sample 2026 - loss: 0.7524855732917786\n",
      "Sample 2027 - loss: 0.06135720759630203\n",
      "Sample 2028 - loss: 8.934117317199707\n",
      "Sample 2029 - loss: 0.9752134084701538\n",
      "Sample 2030 - loss: 7.162492275238037\n",
      "Sample 2031 - loss: 1.857023000717163\n",
      "Sample 2032 - loss: 0.6132721900939941\n",
      "Sample 2033 - loss: 0.21367977559566498\n",
      "Sample 2034 - loss: 0.038783930242061615\n",
      "Sample 2035 - loss: 4.042718887329102\n",
      "Sample 2036 - loss: 1.9210025072097778\n",
      "Sample 2037 - loss: 10.925556182861328\n",
      "Sample 2038 - loss: 0.022114481776952744\n",
      "Sample 2039 - loss: 5.738571643829346\n",
      "Sample 2040 - loss: 11.535578727722168\n",
      "Sample 2041 - loss: 7.942086696624756\n",
      "Sample 2042 - loss: 2.4640138149261475\n",
      "Sample 2043 - loss: 7.23445987701416\n",
      "Sample 2044 - loss: 1.9421533346176147\n",
      "Sample 2045 - loss: 0.07568099349737167\n",
      "Sample 2046 - loss: 7.820298671722412\n",
      "Sample 2047 - loss: 7.570741176605225\n",
      "Sample 2048 - loss: 3.77474308013916\n",
      "Sample 2049 - loss: 1.6370766162872314\n",
      "Sample 2050 - loss: 4.972538948059082\n",
      "Sample 2051 - loss: 2.597912549972534\n",
      "Sample 2052 - loss: 5.578853130340576\n",
      "Sample 2053 - loss: 5.1224045753479\n",
      "Sample 2054 - loss: 6.273097515106201\n",
      "Sample 2055 - loss: 4.0052971839904785\n",
      "Sample 2056 - loss: 0.8910748958587646\n",
      "Sample 2057 - loss: 6.48891544342041\n",
      "Sample 2058 - loss: 0.8901811242103577\n",
      "Sample 2059 - loss: 8.173011779785156\n",
      "Sample 2060 - loss: 1.5907233953475952\n",
      "Sample 2061 - loss: 0.0683709904551506\n",
      "Sample 2062 - loss: 4.429337024688721\n",
      "Sample 2063 - loss: 6.968708515167236\n",
      "Sample 2064 - loss: 3.0469698905944824\n",
      "Sample 2065 - loss: 1.9721719026565552\n",
      "Sample 2066 - loss: 7.796888828277588\n",
      "Sample 2067 - loss: 12.085646629333496\n",
      "Sample 2068 - loss: 7.790247917175293\n",
      "Sample 2069 - loss: 12.080314636230469\n",
      "Sample 2070 - loss: 0.8948590159416199\n",
      "Sample 2071 - loss: 3.954517126083374\n",
      "Sample 2072 - loss: 2.023491859436035\n",
      "Sample 2073 - loss: 2.0027716159820557\n",
      "Sample 2074 - loss: 6.3253912925720215\n",
      "Sample 2075 - loss: 4.01318359375\n",
      "Sample 2076 - loss: 10.278979301452637\n",
      "Sample 2077 - loss: 0.7495983839035034\n",
      "Sample 2078 - loss: 9.616430282592773\n",
      "Sample 2079 - loss: 6.369040489196777\n",
      "Sample 2080 - loss: 0.3346681296825409\n",
      "Sample 2081 - loss: 1.1752426624298096\n",
      "Sample 2082 - loss: 1.4093797206878662\n",
      "Sample 2083 - loss: 1.7734326124191284\n",
      "Sample 2084 - loss: 0.24340350925922394\n",
      "Sample 2085 - loss: 2.8059258460998535\n",
      "Sample 2086 - loss: 0.3510783910751343\n",
      "Sample 2087 - loss: 2.6835293769836426\n",
      "Sample 2088 - loss: 3.8636302947998047\n",
      "Sample 2089 - loss: 1.4280521869659424\n",
      "Sample 2090 - loss: 0.49742966890335083\n",
      "Sample 2091 - loss: 0.38619935512542725\n",
      "Sample 2092 - loss: 0.19414669275283813\n",
      "Sample 2093 - loss: 3.5040907859802246\n",
      "Sample 2094 - loss: 4.478954315185547\n",
      "Sample 2095 - loss: 1.6855639219284058\n",
      "Sample 2096 - loss: 0.8129209280014038\n",
      "Sample 2097 - loss: 8.571219444274902\n",
      "Sample 2098 - loss: 6.17344856262207\n",
      "Sample 2099 - loss: 8.710894584655762\n",
      "Sample 2100 - loss: 1.4504883289337158\n",
      "Sample 2101 - loss: 0.07980530709028244\n",
      "Sample 2102 - loss: 0.0399012453854084\n",
      "Sample 2103 - loss: 3.6465446949005127\n",
      "Sample 2104 - loss: 4.78500509262085\n",
      "Sample 2105 - loss: 3.233431816101074\n",
      "Sample 2106 - loss: 1.0108821392059326\n",
      "Sample 2107 - loss: 3.8199963569641113\n",
      "Sample 2108 - loss: 9.4534330368042\n",
      "Sample 2109 - loss: 4.0073041915893555\n",
      "Sample 2110 - loss: 0.26933175325393677\n",
      "Sample 2111 - loss: 6.675775051116943\n",
      "Sample 2112 - loss: 0.5112875699996948\n",
      "Sample 2113 - loss: 1.433090329170227\n",
      "Sample 2114 - loss: 0.5410199761390686\n",
      "Sample 2115 - loss: 5.062238693237305\n",
      "Sample 2116 - loss: 0.8350004553794861\n",
      "Sample 2117 - loss: 9.399867057800293\n",
      "Sample 2118 - loss: 0.1135823130607605\n",
      "Sample 2119 - loss: 4.2077507972717285\n",
      "Sample 2120 - loss: 0.7476316690444946\n",
      "Sample 2121 - loss: 0.13359570503234863\n",
      "Sample 2122 - loss: 3.743119239807129\n",
      "Sample 2123 - loss: 2.678579330444336\n",
      "Sample 2124 - loss: 1.2934813499450684\n",
      "Sample 2125 - loss: 0.43051719665527344\n",
      "Sample 2126 - loss: 3.023325204849243\n",
      "Sample 2127 - loss: 0.9693815112113953\n",
      "Sample 2128 - loss: 0.3870334327220917\n",
      "Sample 2129 - loss: 9.03441333770752\n",
      "Sample 2130 - loss: 7.711777210235596\n",
      "Sample 2131 - loss: 0.36334094405174255\n",
      "Sample 2132 - loss: 2.1381735801696777\n",
      "Sample 2133 - loss: 3.675173759460449\n",
      "Sample 2134 - loss: 0.7191991209983826\n",
      "Sample 2135 - loss: 0.4380633533000946\n",
      "Sample 2136 - loss: 5.454841136932373\n",
      "Sample 2137 - loss: 3.31416392326355\n",
      "Sample 2138 - loss: 0.012949212454259396\n",
      "Sample 2139 - loss: 4.374929428100586\n",
      "Sample 2140 - loss: 7.74435567855835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2141 - loss: 0.059026751667261124\n",
      "Sample 2142 - loss: 0.7262815833091736\n",
      "Sample 2143 - loss: 0.4949285089969635\n",
      "Sample 2144 - loss: 0.01036472711712122\n",
      "Sample 2145 - loss: 0.9822327494621277\n",
      "Sample 2146 - loss: 5.341798305511475\n",
      "Sample 2147 - loss: 0.017256176099181175\n",
      "Sample 2148 - loss: 2.2678542137145996\n",
      "Sample 2149 - loss: 7.737095355987549\n",
      "Sample 2150 - loss: 11.18739128112793\n",
      "Sample 2151 - loss: 1.9345884323120117\n",
      "Sample 2152 - loss: 3.3845303058624268\n",
      "Sample 2153 - loss: 0.2627103328704834\n",
      "Sample 2154 - loss: 0.05906543880701065\n",
      "Sample 2155 - loss: 0.0615750215947628\n",
      "Sample 2156 - loss: 0.13462120294570923\n",
      "Sample 2157 - loss: 9.616873741149902\n",
      "Sample 2158 - loss: 13.110099792480469\n",
      "Sample 2159 - loss: 0.16864368319511414\n",
      "Sample 2160 - loss: 8.4060697555542\n",
      "Sample 2161 - loss: 2.775850296020508\n",
      "Sample 2162 - loss: 0.3240000605583191\n",
      "Sample 2163 - loss: 3.638035535812378\n",
      "Sample 2164 - loss: 6.444900989532471\n",
      "Sample 2165 - loss: 2.051400899887085\n",
      "Sample 2166 - loss: 0.8550705909729004\n",
      "Sample 2167 - loss: 2.770380973815918\n",
      "Sample 2168 - loss: 6.4654459953308105\n",
      "Sample 2169 - loss: 0.8819879293441772\n",
      "Sample 2170 - loss: 8.002043724060059\n",
      "Sample 2171 - loss: 2.4125466346740723\n",
      "Sample 2172 - loss: 4.766287803649902\n",
      "Sample 2173 - loss: 0.30401885509490967\n",
      "Sample 2174 - loss: 6.196800708770752\n",
      "Sample 2175 - loss: 0.4185781180858612\n",
      "Sample 2176 - loss: 1.505640983581543\n",
      "Sample 2177 - loss: 0.12446984648704529\n",
      "Sample 2178 - loss: 0.1815553903579712\n",
      "Sample 2179 - loss: 1.782903790473938\n",
      "Sample 2180 - loss: 10.486197471618652\n",
      "Sample 2181 - loss: 1.1994259357452393\n",
      "Sample 2182 - loss: 2.0250234603881836\n",
      "Sample 2183 - loss: 5.516902446746826\n",
      "Sample 2184 - loss: 2.0142297744750977\n",
      "Sample 2185 - loss: 3.5621531009674072\n",
      "Sample 2186 - loss: 3.5712037086486816\n",
      "Sample 2187 - loss: 6.3467230796813965\n",
      "Sample 2188 - loss: 0.07292789220809937\n",
      "Sample 2189 - loss: 1.0360851287841797\n",
      "Sample 2190 - loss: 9.044565200805664\n",
      "Sample 2191 - loss: 0.02290947176516056\n",
      "Sample 2192 - loss: 1.6034667491912842\n",
      "Sample 2193 - loss: 9.629185676574707\n",
      "Sample 2194 - loss: 0.08676394820213318\n",
      "Sample 2195 - loss: 3.1541640758514404\n",
      "Sample 2196 - loss: 4.957379341125488\n",
      "Sample 2197 - loss: 1.8860154151916504\n",
      "Sample 2198 - loss: 10.604416847229004\n",
      "Sample 2199 - loss: 3.2531447410583496\n",
      "Sample 2200 - loss: 2.6496548652648926\n",
      "Sample 2201 - loss: 1.390864372253418\n",
      "Sample 2202 - loss: 5.9170451164245605\n",
      "Sample 2203 - loss: 6.295907020568848\n",
      "Sample 2204 - loss: 2.625356674194336\n",
      "Sample 2205 - loss: 4.3040666580200195\n",
      "Sample 2206 - loss: 2.432302474975586\n",
      "Sample 2207 - loss: 6.06240701675415\n",
      "Sample 2208 - loss: 8.082923889160156\n",
      "Sample 2209 - loss: 3.2687485218048096\n",
      "Sample 2210 - loss: 5.880091667175293\n",
      "Sample 2211 - loss: 4.146096229553223\n",
      "Sample 2212 - loss: 4.555967807769775\n",
      "Sample 2213 - loss: 1.181777000427246\n",
      "Sample 2214 - loss: 2.698737382888794\n",
      "Sample 2215 - loss: 5.059475898742676\n",
      "Sample 2216 - loss: 1.2266980409622192\n",
      "Sample 2217 - loss: 12.069977760314941\n",
      "Sample 2218 - loss: 0.20579876005649567\n",
      "Sample 2219 - loss: 0.6758725643157959\n",
      "Sample 2220 - loss: 0.905068039894104\n",
      "Sample 2221 - loss: 0.09513930976390839\n",
      "Sample 2222 - loss: 0.9009611010551453\n",
      "Sample 2223 - loss: 3.7168691158294678\n",
      "Sample 2224 - loss: 3.1411190032958984\n",
      "Sample 2225 - loss: 1.5771175622940063\n",
      "Sample 2226 - loss: 4.900974750518799\n",
      "Sample 2227 - loss: 5.831233501434326\n",
      "Sample 2228 - loss: 4.0391764640808105\n",
      "Sample 2229 - loss: 0.4321681559085846\n",
      "Sample 2230 - loss: 2.959594964981079\n",
      "Sample 2231 - loss: 0.038976460695266724\n",
      "Sample 2232 - loss: 6.4818291664123535\n",
      "Sample 2233 - loss: 10.631805419921875\n",
      "Sample 2234 - loss: 0.4528474807739258\n",
      "Sample 2235 - loss: 8.785490989685059\n",
      "Sample 2236 - loss: 8.109908103942871\n",
      "Sample 2237 - loss: 3.4566221237182617\n",
      "Sample 2238 - loss: 1.0135079622268677\n",
      "Sample 2239 - loss: 1.4784656763076782\n",
      "Sample 2240 - loss: 0.0559934563934803\n",
      "Sample 2241 - loss: 5.498126983642578\n",
      "Sample 2242 - loss: 0.39250290393829346\n",
      "Sample 2243 - loss: 4.647769451141357\n",
      "Sample 2244 - loss: 0.08676081895828247\n",
      "Sample 2245 - loss: 4.438846588134766\n",
      "Sample 2246 - loss: 8.447481155395508\n",
      "Sample 2247 - loss: 3.4715981483459473\n",
      "Sample 2248 - loss: 10.47661018371582\n",
      "Sample 2249 - loss: 0.2697886824607849\n",
      "Sample 2250 - loss: 4.067203521728516\n",
      "Sample 2251 - loss: 0.05069069564342499\n",
      "Sample 2252 - loss: 9.601480484008789\n",
      "Sample 2253 - loss: 9.277267456054688\n",
      "Sample 2254 - loss: 6.1372504234313965\n",
      "Sample 2255 - loss: 2.377056360244751\n",
      "Sample 2256 - loss: 2.5471158027648926\n",
      "Sample 2257 - loss: 6.543681621551514\n",
      "Sample 2258 - loss: 10.688493728637695\n",
      "Sample 2259 - loss: 8.819341659545898\n",
      "Sample 2260 - loss: 1.6783053874969482\n",
      "Sample 2261 - loss: 0.24013221263885498\n",
      "Sample 2262 - loss: 0.025153398513793945\n",
      "Sample 2263 - loss: 0.4566635191440582\n",
      "Sample 2264 - loss: 7.270930290222168\n",
      "Sample 2265 - loss: 2.41343355178833\n",
      "Sample 2266 - loss: 4.092134475708008\n",
      "Sample 2267 - loss: 4.15727424621582\n",
      "Sample 2268 - loss: 0.9449179768562317\n",
      "Sample 2269 - loss: 8.584061622619629\n",
      "Sample 2270 - loss: 1.2684638500213623\n",
      "Sample 2271 - loss: 2.848872661590576\n",
      "Sample 2272 - loss: 0.04291023686528206\n",
      "Sample 2273 - loss: 3.745823621749878\n",
      "Sample 2274 - loss: 4.4382195472717285\n",
      "Sample 2275 - loss: 4.105148792266846\n",
      "Sample 2276 - loss: 7.708731174468994\n",
      "Sample 2277 - loss: 6.035399913787842\n",
      "Sample 2278 - loss: 5.70429801940918\n",
      "Sample 2279 - loss: 5.293532848358154\n",
      "Sample 2280 - loss: 3.843186378479004\n",
      "Sample 2281 - loss: 4.310357570648193\n",
      "Sample 2282 - loss: 1.6838889122009277\n",
      "Sample 2283 - loss: 9.3556489944458\n",
      "Sample 2284 - loss: 12.164262771606445\n",
      "Sample 2285 - loss: 0.42756885290145874\n",
      "Sample 2286 - loss: 8.241840362548828\n",
      "Sample 2287 - loss: 9.343735694885254\n",
      "Sample 2288 - loss: 6.863433837890625\n",
      "Sample 2289 - loss: 4.6225996017456055\n",
      "Sample 2290 - loss: 1.1167106628417969\n",
      "Sample 2291 - loss: 2.360424280166626\n",
      "Sample 2292 - loss: 6.9946393966674805\n",
      "Sample 2293 - loss: 7.055199146270752\n",
      "Sample 2294 - loss: 0.8104277849197388\n",
      "Sample 2295 - loss: 0.6371936202049255\n",
      "Sample 2296 - loss: 0.506030797958374\n",
      "Sample 2297 - loss: 10.073407173156738\n",
      "Sample 2298 - loss: 3.1499600410461426\n",
      "Sample 2299 - loss: 6.040099620819092\n",
      "Sample 2300 - loss: 8.980563163757324\n",
      "Sample 2301 - loss: 7.642329216003418\n",
      "Sample 2302 - loss: 3.239556312561035\n",
      "Sample 2303 - loss: 9.541712760925293\n",
      "Sample 2304 - loss: 8.060749053955078\n",
      "Sample 2305 - loss: 6.550837516784668\n",
      "Sample 2306 - loss: 3.213461399078369\n",
      "Sample 2307 - loss: 4.714315414428711\n",
      "Sample 2308 - loss: 0.9676303863525391\n",
      "Sample 2309 - loss: 4.856408596038818\n",
      "Sample 2310 - loss: 0.4629706144332886\n",
      "Sample 2311 - loss: 5.799384593963623\n",
      "Sample 2312 - loss: 0.011027066968381405\n",
      "Sample 2313 - loss: 0.4056929349899292\n",
      "Sample 2314 - loss: 2.732149600982666\n",
      "Sample 2315 - loss: 6.091557502746582\n",
      "Sample 2316 - loss: 9.30331802368164\n",
      "Sample 2317 - loss: 4.487635612487793\n",
      "Sample 2318 - loss: 2.521794319152832\n",
      "Sample 2319 - loss: 7.371585845947266\n",
      "Sample 2320 - loss: 6.879940032958984\n",
      "Sample 2321 - loss: 0.019389953464269638\n",
      "Sample 2322 - loss: 6.458388805389404\n",
      "Sample 2323 - loss: 12.498165130615234\n",
      "Sample 2324 - loss: 0.7057282328605652\n",
      "Sample 2325 - loss: 4.64899206161499\n",
      "Sample 2326 - loss: 5.554715156555176\n",
      "Sample 2327 - loss: 6.063663482666016\n",
      "Sample 2328 - loss: 7.78798770904541\n",
      "Sample 2329 - loss: 0.05722854286432266\n",
      "Sample 2330 - loss: 0.06450636684894562\n",
      "Sample 2331 - loss: 4.263035774230957\n",
      "Sample 2332 - loss: 2.7784271240234375\n",
      "Sample 2333 - loss: 0.2835618853569031\n",
      "Sample 2334 - loss: 5.908734321594238\n",
      "Sample 2335 - loss: 0.15846383571624756\n",
      "Sample 2336 - loss: 0.3050999343395233\n",
      "Sample 2337 - loss: 2.491847038269043\n",
      "Sample 2338 - loss: 9.731854438781738\n",
      "Sample 2339 - loss: 2.1869988441467285\n",
      "Sample 2340 - loss: 1.653645634651184\n",
      "Sample 2341 - loss: 4.680586814880371\n",
      "Sample 2342 - loss: 0.650248646736145\n",
      "Sample 2343 - loss: 4.907552242279053\n",
      "Sample 2344 - loss: 0.3122439980506897\n",
      "Sample 2345 - loss: 3.5388741493225098\n",
      "Sample 2346 - loss: 0.29129713773727417\n",
      "Sample 2347 - loss: 11.100054740905762\n",
      "Sample 2348 - loss: 5.300885200500488\n",
      "Sample 2349 - loss: 9.208868026733398\n",
      "Sample 2350 - loss: 6.67165994644165\n",
      "Sample 2351 - loss: 0.02237504906952381\n",
      "Sample 2352 - loss: 1.0300918817520142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2353 - loss: 12.81308364868164\n",
      "Sample 2354 - loss: 8.437860488891602\n",
      "Sample 2355 - loss: 0.5440267324447632\n",
      "Sample 2356 - loss: 1.0548231601715088\n",
      "Sample 2357 - loss: 2.010972499847412\n",
      "Sample 2358 - loss: 3.289721965789795\n",
      "Sample 2359 - loss: 1.7305915355682373\n",
      "Sample 2360 - loss: 3.7548882961273193\n",
      "Sample 2361 - loss: 1.93720281124115\n",
      "Sample 2362 - loss: 4.744126796722412\n",
      "Sample 2363 - loss: 8.291250228881836\n",
      "Sample 2364 - loss: 8.348125457763672\n",
      "Sample 2365 - loss: 0.11641261726617813\n",
      "Sample 2366 - loss: 2.7717831134796143\n",
      "Sample 2367 - loss: 1.9195348024368286\n",
      "Sample 2368 - loss: 0.2819198668003082\n",
      "Sample 2369 - loss: 4.291763782501221\n",
      "Sample 2370 - loss: 0.9385929107666016\n",
      "Sample 2371 - loss: 6.286184787750244\n",
      "Sample 2372 - loss: 0.42288193106651306\n",
      "Sample 2373 - loss: 11.040702819824219\n",
      "Sample 2374 - loss: 2.290844678878784\n",
      "Sample 2375 - loss: 4.10054349899292\n",
      "Sample 2376 - loss: 4.840351104736328\n",
      "Sample 2377 - loss: 0.3282802104949951\n",
      "Sample 2378 - loss: 0.06917688995599747\n",
      "Sample 2379 - loss: 7.727554798126221\n",
      "Sample 2380 - loss: 9.38695240020752\n",
      "Sample 2381 - loss: 2.144698143005371\n",
      "Sample 2382 - loss: 0.3933531939983368\n",
      "Sample 2383 - loss: 9.212852478027344\n",
      "Sample 2384 - loss: 6.237278938293457\n",
      "Sample 2385 - loss: 0.8459376692771912\n",
      "Sample 2386 - loss: 1.2310158014297485\n",
      "Sample 2387 - loss: 1.217738151550293\n",
      "Sample 2388 - loss: 3.282682418823242\n",
      "Sample 2389 - loss: 8.177294731140137\n",
      "Sample 2390 - loss: 0.04432538524270058\n",
      "Sample 2391 - loss: 5.450306415557861\n",
      "Sample 2392 - loss: 7.782034397125244\n",
      "Sample 2393 - loss: 0.13592158257961273\n",
      "Sample 2394 - loss: 6.438388824462891\n",
      "Sample 2395 - loss: 0.13406023383140564\n",
      "Sample 2396 - loss: 1.0218267440795898\n",
      "Sample 2397 - loss: 1.8995423316955566\n",
      "Sample 2398 - loss: 0.010876884683966637\n",
      "Sample 2399 - loss: 9.363554954528809\n",
      "Sample 2400 - loss: 10.374887466430664\n",
      "Sample 2401 - loss: 1.6512588262557983\n",
      "Sample 2402 - loss: 2.9768378734588623\n",
      "Sample 2403 - loss: 2.4037413597106934\n",
      "Sample 2404 - loss: 10.961666107177734\n",
      "Sample 2405 - loss: 9.50860595703125\n",
      "Sample 2406 - loss: 4.230485439300537\n",
      "Sample 2407 - loss: 7.196742534637451\n",
      "Sample 2408 - loss: 1.6890209913253784\n",
      "Sample 2409 - loss: 0.6697169542312622\n",
      "Sample 2410 - loss: 0.6455825567245483\n",
      "Sample 2411 - loss: 4.556305885314941\n",
      "Sample 2412 - loss: 2.0879995822906494\n",
      "Sample 2413 - loss: 1.9106522798538208\n",
      "Sample 2414 - loss: 12.116384506225586\n",
      "Sample 2415 - loss: 3.9139881134033203\n",
      "Sample 2416 - loss: 8.370840072631836\n",
      "Sample 2417 - loss: 2.956210136413574\n",
      "Sample 2418 - loss: 0.7487139701843262\n",
      "Sample 2419 - loss: 2.8612236976623535\n",
      "Sample 2420 - loss: 8.868691444396973\n",
      "Sample 2421 - loss: 1.7326512336730957\n",
      "Sample 2422 - loss: 1.8661370277404785\n",
      "Sample 2423 - loss: 3.945084571838379\n",
      "Sample 2424 - loss: 2.447352409362793\n",
      "Sample 2425 - loss: 1.630789041519165\n",
      "Sample 2426 - loss: 0.41928908228874207\n",
      "Sample 2427 - loss: 2.4456217288970947\n",
      "Sample 2428 - loss: 7.4478960037231445\n",
      "Sample 2429 - loss: 2.2857666015625\n",
      "Sample 2430 - loss: 1.8812801837921143\n",
      "Sample 2431 - loss: 3.68975830078125\n",
      "Sample 2432 - loss: 0.467589408159256\n",
      "Sample 2433 - loss: 7.1945953369140625\n",
      "Sample 2434 - loss: 0.26548150181770325\n",
      "Sample 2435 - loss: 0.4489878714084625\n",
      "Sample 2436 - loss: 9.351262092590332\n",
      "Sample 2437 - loss: 0.18614590167999268\n",
      "Sample 2438 - loss: 0.2886866331100464\n",
      "Sample 2439 - loss: 0.037538740783929825\n",
      "Sample 2440 - loss: 1.8993241786956787\n",
      "Sample 2441 - loss: 0.3767855167388916\n",
      "Sample 2442 - loss: 1.8114203214645386\n",
      "Sample 2443 - loss: 9.368029594421387\n",
      "Sample 2444 - loss: 6.89658260345459\n",
      "Sample 2445 - loss: 0.6684444546699524\n",
      "Sample 2446 - loss: 3.611368179321289\n",
      "Sample 2447 - loss: 5.138700008392334\n",
      "Sample 2448 - loss: 5.8323822021484375\n",
      "Sample 2449 - loss: 12.242829322814941\n",
      "Sample 2450 - loss: 8.626470565795898\n",
      "Sample 2451 - loss: 7.536790370941162\n",
      "Sample 2452 - loss: 0.5031309723854065\n",
      "Sample 2453 - loss: 7.133411407470703\n",
      "Sample 2454 - loss: 3.4924097061157227\n",
      "Sample 2455 - loss: 0.059679172933101654\n",
      "Sample 2456 - loss: 0.2836439311504364\n",
      "Sample 2457 - loss: 0.02191901206970215\n",
      "Sample 2458 - loss: 11.43350601196289\n",
      "Sample 2459 - loss: 12.216540336608887\n",
      "Sample 2460 - loss: 9.70069408416748\n",
      "Sample 2461 - loss: 0.18081159889698029\n",
      "Sample 2462 - loss: 1.9230666160583496\n",
      "Sample 2463 - loss: 1.888831615447998\n",
      "Sample 2464 - loss: 8.786877632141113\n",
      "Sample 2465 - loss: 2.6250715255737305\n",
      "Sample 2466 - loss: 7.552318572998047\n",
      "Sample 2467 - loss: 11.578068733215332\n",
      "Sample 2468 - loss: 0.403645396232605\n",
      "Sample 2469 - loss: 1.4140249490737915\n",
      "Sample 2470 - loss: 4.408078193664551\n",
      "Sample 2471 - loss: 0.5574471950531006\n",
      "Sample 2472 - loss: 2.489567518234253\n",
      "Sample 2473 - loss: 0.25020453333854675\n",
      "Sample 2474 - loss: 0.4019591808319092\n",
      "Sample 2475 - loss: 0.2785983681678772\n",
      "Sample 2476 - loss: 0.9486244320869446\n",
      "Sample 2477 - loss: 0.6094765663146973\n",
      "Sample 2478 - loss: 4.477957248687744\n",
      "Sample 2479 - loss: 0.24624258279800415\n",
      "Sample 2480 - loss: 0.3629772663116455\n",
      "Sample 2481 - loss: 1.2244937419891357\n",
      "Sample 2482 - loss: 0.0018515439005568624\n",
      "Sample 2483 - loss: 2.4212799072265625\n",
      "Sample 2484 - loss: 0.22872807085514069\n",
      "Sample 2485 - loss: 8.058260917663574\n",
      "Sample 2486 - loss: 9.99718189239502\n",
      "Sample 2487 - loss: 1.3397271633148193\n",
      "Sample 2488 - loss: 1.3825362920761108\n",
      "Sample 2489 - loss: 8.044769287109375\n",
      "Sample 2490 - loss: 2.2317259311676025\n",
      "Sample 2491 - loss: 10.589574813842773\n",
      "Sample 2492 - loss: 0.12391605228185654\n",
      "Sample 2493 - loss: 3.9068987369537354\n",
      "Sample 2494 - loss: 1.7637828588485718\n",
      "Sample 2495 - loss: 2.0343430042266846\n",
      "Sample 2496 - loss: 7.1926140785217285\n",
      "Sample 2497 - loss: 1.9216408729553223\n",
      "Sample 2498 - loss: 0.6931045055389404\n",
      "Sample 2499 - loss: 3.267775774002075\n",
      "Sample 2500 - loss: 2.0241332054138184\n",
      "Sample 2501 - loss: 8.429788589477539\n",
      "Sample 2502 - loss: 2.031994104385376\n",
      "Sample 2503 - loss: 7.191149711608887\n",
      "Sample 2504 - loss: 1.2737191915512085\n",
      "Sample 2505 - loss: 2.0662193298339844\n",
      "Sample 2506 - loss: 0.0544934943318367\n",
      "Sample 2507 - loss: 6.992696762084961\n",
      "Sample 2508 - loss: 7.152830600738525\n",
      "Sample 2509 - loss: 0.2145446389913559\n",
      "Sample 2510 - loss: 0.01053746696561575\n",
      "Sample 2511 - loss: 2.4528310298919678\n",
      "Sample 2512 - loss: 0.3981410264968872\n",
      "Sample 2513 - loss: 6.999629974365234\n",
      "Sample 2514 - loss: 8.231919288635254\n",
      "Sample 2515 - loss: 7.050753593444824\n",
      "Sample 2516 - loss: 6.128289222717285\n",
      "Sample 2517 - loss: 1.1337863206863403\n",
      "Sample 2518 - loss: 2.233686923980713\n",
      "Sample 2519 - loss: 4.595454216003418\n",
      "Sample 2520 - loss: 9.455770492553711\n",
      "Sample 2521 - loss: 9.708189964294434\n",
      "Sample 2522 - loss: 7.374504566192627\n",
      "Sample 2523 - loss: 0.976656436920166\n",
      "Sample 2524 - loss: 0.7014021873474121\n",
      "Sample 2525 - loss: 0.18874576687812805\n",
      "Sample 2526 - loss: 3.7922301292419434\n",
      "Sample 2527 - loss: 6.374688625335693\n",
      "Sample 2528 - loss: 1.2488270998001099\n",
      "Sample 2529 - loss: 0.7644560933113098\n",
      "Sample 2530 - loss: 5.96630859375\n",
      "Sample 2531 - loss: 1.8556809425354004\n",
      "Sample 2532 - loss: 3.769022226333618\n",
      "Sample 2533 - loss: 0.6807217597961426\n",
      "Sample 2534 - loss: 6.084908485412598\n",
      "Sample 2535 - loss: 3.5173187255859375\n",
      "Sample 2536 - loss: 0.7521212697029114\n",
      "Sample 2537 - loss: 12.107209205627441\n",
      "Sample 2538 - loss: 0.190450519323349\n",
      "Sample 2539 - loss: 0.9855372905731201\n",
      "Sample 2540 - loss: 5.595537185668945\n",
      "Sample 2541 - loss: 0.6772521734237671\n",
      "Sample 2542 - loss: 2.3712167739868164\n",
      "Sample 2543 - loss: 6.677717208862305\n",
      "Sample 2544 - loss: 0.969268262386322\n",
      "Sample 2545 - loss: 9.4502534866333\n",
      "Sample 2546 - loss: 6.201821327209473\n",
      "Sample 2547 - loss: 2.043482542037964\n",
      "Sample 2548 - loss: 4.178427696228027\n",
      "Sample 2549 - loss: 0.35544833540916443\n",
      "Sample 2550 - loss: 5.069650650024414\n",
      "Sample 2551 - loss: 0.05493540316820145\n",
      "Sample 2552 - loss: 9.065339088439941\n",
      "Sample 2553 - loss: 0.020506976172327995\n",
      "Sample 2554 - loss: 4.291699409484863\n",
      "Sample 2555 - loss: 0.27598902583122253\n",
      "Sample 2556 - loss: 2.1284830570220947\n",
      "Sample 2557 - loss: 1.7281209230422974\n",
      "Sample 2558 - loss: 0.3623058795928955\n",
      "Sample 2559 - loss: 0.5184221863746643\n",
      "Sample 2560 - loss: 3.47078275680542\n",
      "Sample 2561 - loss: 0.9742091298103333\n",
      "Sample 2562 - loss: 3.978539228439331\n",
      "Sample 2563 - loss: 0.42784708738327026\n",
      "Sample 2564 - loss: 2.150789737701416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2565 - loss: 10.075042724609375\n",
      "Sample 2566 - loss: 8.241927146911621\n",
      "Sample 2567 - loss: 0.6015828847885132\n",
      "Sample 2568 - loss: 1.6609209775924683\n",
      "Sample 2569 - loss: 2.0712015628814697\n",
      "Sample 2570 - loss: 5.308690071105957\n",
      "Sample 2571 - loss: 5.365098476409912\n",
      "Sample 2572 - loss: 2.35371470451355\n",
      "Sample 2573 - loss: 7.954948902130127\n",
      "Sample 2574 - loss: 6.423425197601318\n",
      "Sample 2575 - loss: 5.758338451385498\n",
      "Sample 2576 - loss: 0.9319648146629333\n",
      "Sample 2577 - loss: 0.6982539892196655\n",
      "Sample 2578 - loss: 8.511853218078613\n",
      "Sample 2579 - loss: 3.5998048782348633\n",
      "Sample 2580 - loss: 1.4027317762374878\n",
      "Sample 2581 - loss: 2.399557590484619\n",
      "Sample 2582 - loss: 5.510629177093506\n",
      "Sample 2583 - loss: 9.89793872833252\n",
      "Sample 2584 - loss: 0.04519004002213478\n",
      "Sample 2585 - loss: 10.556002616882324\n",
      "Sample 2586 - loss: 2.889773368835449\n",
      "Sample 2587 - loss: 11.854623794555664\n",
      "Sample 2588 - loss: 0.4883522689342499\n",
      "Sample 2589 - loss: 8.351871490478516\n",
      "Sample 2590 - loss: 10.250897407531738\n",
      "Sample 2591 - loss: 0.48352763056755066\n",
      "Sample 2592 - loss: 4.203864097595215\n",
      "Sample 2593 - loss: 0.6697648763656616\n",
      "Sample 2594 - loss: 5.9621405601501465\n",
      "Sample 2595 - loss: 8.0838623046875\n",
      "Sample 2596 - loss: 3.3765981197357178\n",
      "Sample 2597 - loss: 0.503385603427887\n",
      "Sample 2598 - loss: 3.6065704822540283\n",
      "Sample 2599 - loss: 2.0196242332458496\n",
      "Sample 2600 - loss: 2.2498764991760254\n",
      "Sample 2601 - loss: 2.3886547088623047\n",
      "Sample 2602 - loss: 10.118976593017578\n",
      "Sample 2603 - loss: 6.303678512573242\n",
      "Sample 2604 - loss: 6.406207084655762\n",
      "Sample 2605 - loss: 1.3208613395690918\n",
      "Sample 2606 - loss: 8.332475662231445\n",
      "Sample 2607 - loss: 0.5290369391441345\n",
      "Sample 2608 - loss: 7.660962104797363\n",
      "Sample 2609 - loss: 1.3880047798156738\n",
      "Sample 2610 - loss: 5.77828311920166\n",
      "Sample 2611 - loss: 4.641854763031006\n",
      "Sample 2612 - loss: 9.215497016906738\n",
      "Sample 2613 - loss: 1.7664389610290527\n",
      "Sample 2614 - loss: 6.129727363586426\n",
      "Sample 2615 - loss: 6.69822883605957\n",
      "Sample 2616 - loss: 3.711215019226074\n",
      "Sample 2617 - loss: 0.41505444049835205\n",
      "Sample 2618 - loss: 0.09199035912752151\n",
      "Sample 2619 - loss: 2.383877754211426\n",
      "Sample 2620 - loss: 3.898207902908325\n",
      "Sample 2621 - loss: 10.198057174682617\n",
      "Sample 2622 - loss: 0.04212412238121033\n",
      "Sample 2623 - loss: 1.692778468132019\n",
      "Sample 2624 - loss: 1.6584718227386475\n",
      "Sample 2625 - loss: 4.1036248207092285\n",
      "Sample 2626 - loss: 6.724842548370361\n",
      "Sample 2627 - loss: 1.7126829624176025\n",
      "Sample 2628 - loss: 7.44565486907959\n",
      "Sample 2629 - loss: 4.691490650177002\n",
      "Sample 2630 - loss: 0.21184636652469635\n",
      "Sample 2631 - loss: 1.9535610675811768\n",
      "Sample 2632 - loss: 0.5774132609367371\n",
      "Sample 2633 - loss: 5.621008396148682\n",
      "Sample 2634 - loss: 0.8671749234199524\n",
      "Sample 2635 - loss: 0.056633662432432175\n",
      "Sample 2636 - loss: 1.3411839008331299\n",
      "Sample 2637 - loss: 0.5393351912498474\n",
      "Sample 2638 - loss: 0.5844416618347168\n",
      "Sample 2639 - loss: 8.156883239746094\n",
      "Sample 2640 - loss: 2.974461078643799\n",
      "Sample 2641 - loss: 0.01639181561768055\n",
      "Sample 2642 - loss: 1.735163688659668\n",
      "Sample 2643 - loss: 0.1390811800956726\n",
      "Sample 2644 - loss: 0.27115166187286377\n",
      "Sample 2645 - loss: 2.0302042961120605\n",
      "Sample 2646 - loss: 0.5314016938209534\n",
      "Sample 2647 - loss: 7.631118297576904\n",
      "Sample 2648 - loss: 2.29479718208313\n",
      "Sample 2649 - loss: 5.43050479888916\n",
      "Sample 2650 - loss: 3.861508369445801\n",
      "Sample 2651 - loss: 6.581056594848633\n",
      "Sample 2652 - loss: 0.07007043063640594\n",
      "Sample 2653 - loss: 1.915703535079956\n",
      "Sample 2654 - loss: 3.3330700397491455\n",
      "Sample 2655 - loss: 6.555594444274902\n",
      "Sample 2656 - loss: 2.9111382961273193\n",
      "Sample 2657 - loss: 0.3548518419265747\n",
      "Sample 2658 - loss: 0.23751790821552277\n",
      "Sample 2659 - loss: 0.005897987633943558\n",
      "Sample 2660 - loss: 1.09580397605896\n",
      "Sample 2661 - loss: 0.006536147091537714\n",
      "Sample 2662 - loss: 0.2689047157764435\n",
      "Sample 2663 - loss: 0.34685787558555603\n",
      "Sample 2664 - loss: 0.9277177453041077\n",
      "Sample 2665 - loss: 4.109496593475342\n",
      "Sample 2666 - loss: 2.043513298034668\n",
      "Sample 2667 - loss: 0.11846569925546646\n",
      "Sample 2668 - loss: 1.0902659893035889\n",
      "Sample 2669 - loss: 0.04684286564588547\n",
      "Sample 2670 - loss: 3.550504684448242\n",
      "Sample 2671 - loss: 6.266242504119873\n",
      "Sample 2672 - loss: 3.0641043186187744\n",
      "Sample 2673 - loss: 0.19856175780296326\n",
      "Sample 2674 - loss: 11.487678527832031\n",
      "Sample 2675 - loss: 1.1720070838928223\n",
      "Sample 2676 - loss: 0.3828625977039337\n",
      "Sample 2677 - loss: 3.2425522804260254\n",
      "Sample 2678 - loss: 0.5198619961738586\n",
      "Sample 2679 - loss: 5.005465030670166\n",
      "Sample 2680 - loss: 1.2130742073059082\n",
      "Sample 2681 - loss: 1.8169732093811035\n",
      "Sample 2682 - loss: 5.984663009643555\n",
      "Sample 2683 - loss: 4.8112993240356445\n",
      "Sample 2684 - loss: 3.4010891914367676\n",
      "Sample 2685 - loss: 3.3673019409179688\n",
      "Sample 2686 - loss: 5.277518272399902\n",
      "Sample 2687 - loss: 7.551010608673096\n",
      "Sample 2688 - loss: 0.6228408813476562\n",
      "Sample 2689 - loss: 8.553566932678223\n",
      "Sample 2690 - loss: 0.09559603780508041\n",
      "Sample 2691 - loss: 8.006294250488281\n",
      "Sample 2692 - loss: 5.228114604949951\n",
      "Sample 2693 - loss: 1.5644447803497314\n",
      "Sample 2694 - loss: 3.7916300296783447\n",
      "Sample 2695 - loss: 2.4249908924102783\n",
      "Sample 2696 - loss: 0.8212947249412537\n",
      "Sample 2697 - loss: 1.4694874286651611\n",
      "Sample 2698 - loss: 1.446169137954712\n",
      "Sample 2699 - loss: 1.8466190099716187\n",
      "Sample 2700 - loss: 4.5922698974609375\n",
      "Sample 2701 - loss: 0.500318706035614\n",
      "Sample 2702 - loss: 3.7402281761169434\n",
      "Sample 2703 - loss: 0.05978076532483101\n",
      "Sample 2704 - loss: 7.5950117111206055\n",
      "Sample 2705 - loss: 6.453452110290527\n",
      "Sample 2706 - loss: 0.7232578992843628\n",
      "Sample 2707 - loss: 2.3463027477264404\n",
      "Sample 2708 - loss: 7.528954982757568\n",
      "Sample 2709 - loss: 0.7914541363716125\n",
      "Sample 2710 - loss: 0.3050934374332428\n",
      "Sample 2711 - loss: 0.28330716490745544\n",
      "Sample 2712 - loss: 5.837210655212402\n",
      "Sample 2713 - loss: 0.06140495836734772\n",
      "Sample 2714 - loss: 0.04172864928841591\n",
      "Sample 2715 - loss: 0.10535723716020584\n",
      "Sample 2716 - loss: 3.796444892883301\n",
      "Sample 2717 - loss: 6.727054595947266\n",
      "Sample 2718 - loss: 9.532975196838379\n",
      "Sample 2719 - loss: 4.890963554382324\n",
      "Sample 2720 - loss: 0.4529029428958893\n",
      "Sample 2721 - loss: 8.7854642868042\n",
      "Sample 2722 - loss: 5.852328300476074\n",
      "Sample 2723 - loss: 2.807053804397583\n",
      "Sample 2724 - loss: 1.3210560083389282\n",
      "Sample 2725 - loss: 1.5362002849578857\n",
      "Sample 2726 - loss: 4.833906173706055\n",
      "Sample 2727 - loss: 10.98974609375\n",
      "Sample 2728 - loss: 4.118955612182617\n",
      "Sample 2729 - loss: 1.0945496559143066\n",
      "Sample 2730 - loss: 1.0721805095672607\n",
      "Sample 2731 - loss: 0.16993379592895508\n",
      "Sample 2732 - loss: 7.132061958312988\n",
      "Sample 2733 - loss: 7.1291422843933105\n",
      "Sample 2734 - loss: 0.19754323363304138\n",
      "Sample 2735 - loss: 0.15567553043365479\n",
      "Sample 2736 - loss: 7.718048095703125\n",
      "Sample 2737 - loss: 1.5467734336853027\n",
      "Sample 2738 - loss: 7.091679573059082\n",
      "Sample 2739 - loss: 3.492189407348633\n",
      "Sample 2740 - loss: 1.934116005897522\n",
      "Sample 2741 - loss: 0.04185017570853233\n",
      "Sample 2742 - loss: 0.024440407752990723\n",
      "Sample 2743 - loss: 0.5647333860397339\n",
      "Sample 2744 - loss: 1.7197349071502686\n",
      "Sample 2745 - loss: 4.583425045013428\n",
      "Sample 2746 - loss: 5.234335422515869\n",
      "Sample 2747 - loss: 1.3405985832214355\n",
      "Sample 2748 - loss: 1.2356510162353516\n",
      "Sample 2749 - loss: 8.195297241210938\n",
      "Sample 2750 - loss: 0.865230917930603\n",
      "Sample 2751 - loss: 5.152049541473389\n",
      "Sample 2752 - loss: 8.414743423461914\n",
      "Sample 2753 - loss: 0.01747237890958786\n",
      "Sample 2754 - loss: 0.21653591096401215\n",
      "Sample 2755 - loss: 8.164249420166016\n",
      "Sample 2756 - loss: 0.3642287850379944\n",
      "Sample 2757 - loss: 5.403116226196289\n",
      "Sample 2758 - loss: 1.1358919143676758\n",
      "Sample 2759 - loss: 1.259027123451233\n",
      "Sample 2760 - loss: 5.0494818687438965\n",
      "Sample 2761 - loss: 4.768329620361328\n",
      "Sample 2762 - loss: 1.113410234451294\n",
      "Sample 2763 - loss: 6.1982645988464355\n",
      "Sample 2764 - loss: 5.149137496948242\n",
      "Sample 2765 - loss: 7.711859703063965\n",
      "Sample 2766 - loss: 1.592421054840088\n",
      "Sample 2767 - loss: 7.774293422698975\n",
      "Sample 2768 - loss: 0.03170115873217583\n",
      "Sample 2769 - loss: 8.016669273376465\n",
      "Sample 2770 - loss: 2.8220856189727783\n",
      "Sample 2771 - loss: 5.315762519836426\n",
      "Sample 2772 - loss: 0.6281418204307556\n",
      "Sample 2773 - loss: 0.11721239984035492\n",
      "Sample 2774 - loss: 7.271535873413086\n",
      "Sample 2775 - loss: 2.721684217453003\n",
      "Sample 2776 - loss: 3.8379967212677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2777 - loss: 7.882070541381836\n",
      "Sample 2778 - loss: 0.3325187563896179\n",
      "Sample 2779 - loss: 1.4362363815307617\n",
      "Sample 2780 - loss: 2.9381978511810303\n",
      "Sample 2781 - loss: 9.062932014465332\n",
      "Sample 2782 - loss: 0.07662412524223328\n",
      "Sample 2783 - loss: 3.2387077808380127\n",
      "Sample 2784 - loss: 6.876713275909424\n",
      "Sample 2785 - loss: 4.032163143157959\n",
      "Sample 2786 - loss: 0.11654737591743469\n",
      "Sample 2787 - loss: 1.4198861122131348\n",
      "Sample 2788 - loss: 10.518380165100098\n",
      "Sample 2789 - loss: 5.338935375213623\n",
      "Sample 2790 - loss: 1.439542531967163\n",
      "Sample 2791 - loss: 4.245683193206787\n",
      "Sample 2792 - loss: 2.501201629638672\n",
      "Sample 2793 - loss: 10.950133323669434\n",
      "Sample 2794 - loss: 0.08368270844221115\n",
      "Sample 2795 - loss: 0.4494283199310303\n",
      "Sample 2796 - loss: 8.211779594421387\n",
      "Sample 2797 - loss: 5.184431552886963\n",
      "Sample 2798 - loss: 1.8830276727676392\n",
      "Sample 2799 - loss: 0.8324276804924011\n",
      "Sample 2800 - loss: 1.9836825132369995\n",
      "Sample 2801 - loss: 1.7833452224731445\n",
      "Sample 2802 - loss: 2.0120136737823486\n",
      "Sample 2803 - loss: 5.036525726318359\n",
      "Sample 2804 - loss: 1.8858410120010376\n",
      "Sample 2805 - loss: 0.30513060092926025\n",
      "Sample 2806 - loss: 0.034418217837810516\n",
      "Sample 2807 - loss: 2.081725835800171\n",
      "Sample 2808 - loss: 2.8734445571899414\n",
      "Sample 2809 - loss: 0.3351997435092926\n",
      "Sample 2810 - loss: 4.017877578735352\n",
      "Sample 2811 - loss: 2.2014074325561523\n",
      "Sample 2812 - loss: 5.558804988861084\n",
      "Sample 2813 - loss: 4.0915608406066895\n",
      "Sample 2814 - loss: 0.007425474934279919\n",
      "Sample 2815 - loss: 4.254540920257568\n",
      "Sample 2816 - loss: 0.8354290127754211\n",
      "Sample 2817 - loss: 7.9367194175720215\n",
      "Sample 2818 - loss: 0.1232750341296196\n",
      "Sample 2819 - loss: 6.043076992034912\n",
      "Sample 2820 - loss: 4.973973751068115\n",
      "Sample 2821 - loss: 1.9879928827285767\n",
      "Sample 2822 - loss: 1.6986169815063477\n",
      "Sample 2823 - loss: 2.3995580673217773\n",
      "Sample 2824 - loss: 0.34913215041160583\n",
      "Sample 2825 - loss: 0.3840690851211548\n",
      "Sample 2826 - loss: 0.5859901905059814\n",
      "Sample 2827 - loss: 0.6777932047843933\n",
      "Sample 2828 - loss: 3.1694555282592773\n",
      "Sample 2829 - loss: 3.569317102432251\n",
      "Sample 2830 - loss: 3.729571580886841\n",
      "Sample 2831 - loss: 2.4439826011657715\n",
      "Sample 2832 - loss: 1.7273329496383667\n",
      "Sample 2833 - loss: 0.2424049973487854\n",
      "Sample 2834 - loss: 1.05173659324646\n",
      "Sample 2835 - loss: 11.39341926574707\n",
      "Sample 2836 - loss: 4.013091087341309\n",
      "Sample 2837 - loss: 10.29857063293457\n",
      "Sample 2838 - loss: 0.05242716148495674\n",
      "Sample 2839 - loss: 0.29531916975975037\n",
      "Sample 2840 - loss: 0.09225192666053772\n",
      "Sample 2841 - loss: 2.9858717918395996\n",
      "Sample 2842 - loss: 11.970844268798828\n",
      "Sample 2843 - loss: 5.938210487365723\n",
      "Sample 2844 - loss: 0.37871891260147095\n",
      "Sample 2845 - loss: 0.08242195099592209\n",
      "Sample 2846 - loss: 2.6001598834991455\n",
      "Sample 2847 - loss: 0.1403028815984726\n",
      "Sample 2848 - loss: 0.5839380621910095\n",
      "Sample 2849 - loss: 9.987285614013672\n",
      "Sample 2850 - loss: 7.534208297729492\n",
      "Sample 2851 - loss: 1.024119257926941\n",
      "Sample 2852 - loss: 8.842242240905762\n",
      "Sample 2853 - loss: 8.638492584228516\n",
      "Sample 2854 - loss: 0.020797953009605408\n",
      "Sample 2855 - loss: 4.1247453689575195\n",
      "Sample 2856 - loss: 8.079215049743652\n",
      "Sample 2857 - loss: 7.315090179443359\n",
      "Sample 2858 - loss: 4.737809658050537\n",
      "Sample 2859 - loss: 2.3041985034942627\n",
      "Sample 2860 - loss: 6.91140604019165\n",
      "Sample 2861 - loss: 0.019944924861192703\n",
      "Sample 2862 - loss: 2.4301629066467285\n",
      "Sample 2863 - loss: 0.015440201386809349\n",
      "Sample 2864 - loss: 1.6393508911132812\n",
      "Sample 2865 - loss: 1.5985534191131592\n",
      "Sample 2866 - loss: 2.172269582748413\n",
      "Sample 2867 - loss: 10.663752555847168\n",
      "Sample 2868 - loss: 0.15103773772716522\n",
      "Sample 2869 - loss: 6.901093006134033\n",
      "Sample 2870 - loss: 0.04425209388136864\n",
      "Sample 2871 - loss: 3.1586415767669678\n",
      "Sample 2872 - loss: 0.34776100516319275\n",
      "Sample 2873 - loss: 0.04904632270336151\n",
      "Sample 2874 - loss: 6.757340908050537\n",
      "Sample 2875 - loss: 2.7321689128875732\n",
      "Sample 2876 - loss: 3.284747838973999\n",
      "Sample 2877 - loss: 2.488947868347168\n",
      "Sample 2878 - loss: 7.12968635559082\n",
      "Sample 2879 - loss: 8.901647567749023\n",
      "Sample 2880 - loss: 0.9649975299835205\n",
      "Sample 2881 - loss: 8.137212753295898\n",
      "Sample 2882 - loss: 6.795165538787842\n",
      "Sample 2883 - loss: 2.3272805213928223\n",
      "Sample 2884 - loss: 0.8679468035697937\n",
      "Sample 2885 - loss: 2.3216071128845215\n",
      "Sample 2886 - loss: 1.2836642265319824\n",
      "Sample 2887 - loss: 2.4610068798065186\n",
      "Sample 2888 - loss: 11.00408935546875\n",
      "Sample 2889 - loss: 1.094120979309082\n",
      "Sample 2890 - loss: 0.1368899792432785\n",
      "Sample 2891 - loss: 7.4584808349609375\n",
      "Sample 2892 - loss: 0.4253707826137543\n",
      "Sample 2893 - loss: 0.5678020119667053\n",
      "Sample 2894 - loss: 6.093446254730225\n",
      "Sample 2895 - loss: 12.86374282836914\n",
      "Sample 2896 - loss: 0.5180694460868835\n",
      "Sample 2897 - loss: 0.13683021068572998\n",
      "Sample 2898 - loss: 0.9960046410560608\n",
      "Sample 2899 - loss: 5.136045455932617\n",
      "Sample 2900 - loss: 2.2778069972991943\n",
      "Sample 2901 - loss: 9.307053565979004\n",
      "Sample 2902 - loss: 0.10795220732688904\n",
      "Sample 2903 - loss: 5.8080878257751465\n",
      "Sample 2904 - loss: 5.98536491394043\n",
      "Sample 2905 - loss: 9.044595718383789\n",
      "Sample 2906 - loss: 7.317193984985352\n",
      "Sample 2907 - loss: 4.180459022521973\n",
      "Sample 2908 - loss: 4.923689365386963\n",
      "Sample 2909 - loss: 2.0670180320739746\n",
      "Sample 2910 - loss: 10.230691909790039\n",
      "Sample 2911 - loss: 0.39689013361930847\n",
      "Sample 2912 - loss: 4.340422630310059\n",
      "Sample 2913 - loss: 0.09759370982646942\n",
      "Sample 2914 - loss: 2.7283716201782227\n",
      "Sample 2915 - loss: 2.6523637771606445\n",
      "Sample 2916 - loss: 7.322484016418457\n",
      "Sample 2917 - loss: 1.1678086519241333\n",
      "Sample 2918 - loss: 0.007872991263866425\n",
      "Sample 2919 - loss: 8.219721794128418\n",
      "Sample 2920 - loss: 0.108633853495121\n",
      "Sample 2921 - loss: 1.6923232078552246\n",
      "Sample 2922 - loss: 10.106417655944824\n",
      "Sample 2923 - loss: 3.373845100402832\n",
      "Sample 2924 - loss: 2.4677228927612305\n",
      "Sample 2925 - loss: 4.540882587432861\n",
      "Sample 2926 - loss: 0.25459086894989014\n",
      "Sample 2927 - loss: 2.661076545715332\n",
      "Sample 2928 - loss: 5.422858238220215\n",
      "Sample 2929 - loss: 3.101391553878784\n",
      "Sample 2930 - loss: 0.134947270154953\n",
      "Sample 2931 - loss: 6.1750969886779785\n",
      "Sample 2932 - loss: 5.855405807495117\n",
      "Sample 2933 - loss: 3.140345811843872\n",
      "Sample 2934 - loss: 7.30836296081543\n",
      "Sample 2935 - loss: 10.766584396362305\n",
      "Sample 2936 - loss: 4.412338733673096\n",
      "Sample 2937 - loss: 5.02110481262207\n",
      "Sample 2938 - loss: 2.9597930908203125\n",
      "Sample 2939 - loss: 3.163318157196045\n",
      "Sample 2940 - loss: 5.894337177276611\n",
      "Sample 2941 - loss: 4.378690719604492\n",
      "Sample 2942 - loss: 0.027422336861491203\n",
      "Sample 2943 - loss: 2.054037094116211\n",
      "Sample 2944 - loss: 0.16143108904361725\n",
      "Sample 2945 - loss: 9.229610443115234\n",
      "Sample 2946 - loss: 0.5238006114959717\n",
      "Sample 2947 - loss: 7.424638271331787\n",
      "Sample 2948 - loss: 4.459454536437988\n",
      "Sample 2949 - loss: 3.6459009647369385\n",
      "Sample 2950 - loss: 2.825667142868042\n",
      "Sample 2951 - loss: 3.3611416816711426\n",
      "Sample 2952 - loss: 3.9076449871063232\n",
      "Sample 2953 - loss: 4.9300856590271\n",
      "Sample 2954 - loss: 1.2841994762420654\n",
      "Sample 2955 - loss: 7.079279899597168\n",
      "Sample 2956 - loss: 6.697921276092529\n",
      "Sample 2957 - loss: 2.7366466522216797\n",
      "Sample 2958 - loss: 13.99641227722168\n",
      "Sample 2959 - loss: 1.5103864669799805\n",
      "Sample 2960 - loss: 0.8175767660140991\n",
      "Sample 2961 - loss: 8.996288299560547\n",
      "Sample 2962 - loss: 4.506646156311035\n",
      "Sample 2963 - loss: 0.14140067994594574\n",
      "Sample 2964 - loss: 0.06618084013462067\n",
      "Sample 2965 - loss: 0.01331359427422285\n",
      "Sample 2966 - loss: 2.2033286094665527\n",
      "Sample 2967 - loss: 0.709506630897522\n",
      "Sample 2968 - loss: 0.7682232856750488\n",
      "Sample 2969 - loss: 2.294363021850586\n",
      "Sample 2970 - loss: 1.280950903892517\n",
      "Sample 2971 - loss: 8.089337348937988\n",
      "Sample 2972 - loss: 7.7915143966674805\n",
      "Sample 2973 - loss: 2.2105133533477783\n",
      "Sample 2974 - loss: 3.1479156017303467\n",
      "Sample 2975 - loss: 1.08341646194458\n",
      "Sample 2976 - loss: 0.03216542303562164\n",
      "Sample 2977 - loss: 2.3341641426086426\n",
      "Sample 2978 - loss: 1.1470216512680054\n",
      "Sample 2979 - loss: 0.5192042589187622\n",
      "Sample 2980 - loss: 6.941707611083984\n",
      "Sample 2981 - loss: 3.241750478744507\n",
      "Sample 2982 - loss: 5.199181079864502\n",
      "Sample 2983 - loss: 4.146974086761475\n",
      "Sample 2984 - loss: 7.222548007965088\n",
      "Sample 2985 - loss: 10.253653526306152\n",
      "Sample 2986 - loss: 1.8412964344024658\n",
      "Sample 2987 - loss: 9.46868896484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2988 - loss: 1.7791229486465454\n",
      "Sample 2989 - loss: 1.8483799695968628\n",
      "Sample 2990 - loss: 7.312802791595459\n",
      "Sample 2991 - loss: 4.315156936645508\n",
      "Sample 2992 - loss: 2.446122169494629\n",
      "Sample 2993 - loss: 0.45598679780960083\n",
      "Sample 2994 - loss: 0.11847937852144241\n",
      "Sample 2995 - loss: 3.515596866607666\n",
      "Sample 2996 - loss: 2.2415413856506348\n",
      "Sample 2997 - loss: 9.241704940795898\n",
      "Sample 2998 - loss: 7.215879440307617\n",
      "Sample 2999 - loss: 0.5006793737411499\n",
      "Sample 3000 - loss: 1.673161268234253\n",
      "Sample 3001 - loss: 1.656297206878662\n",
      "Sample 3002 - loss: 5.854301929473877\n",
      "Sample 3003 - loss: 0.8469058871269226\n",
      "Sample 3004 - loss: 3.94610595703125\n",
      "Sample 3005 - loss: 10.309545516967773\n",
      "Sample 3006 - loss: 0.17207159101963043\n",
      "Sample 3007 - loss: 4.312321662902832\n",
      "Sample 3008 - loss: 11.266554832458496\n",
      "Sample 3009 - loss: 1.6344192028045654\n",
      "Sample 3010 - loss: 0.2406032234430313\n",
      "Sample 3011 - loss: 8.679463386535645\n",
      "Sample 3012 - loss: 1.9073989391326904\n",
      "Sample 3013 - loss: 2.628737449645996\n",
      "Sample 3014 - loss: 0.01682153157889843\n",
      "Sample 3015 - loss: 1.808128833770752\n",
      "Sample 3016 - loss: 2.015746831893921\n",
      "Sample 3017 - loss: 1.7695826292037964\n",
      "Sample 3018 - loss: 0.9105030298233032\n",
      "Sample 3019 - loss: 1.3232916593551636\n",
      "Sample 3020 - loss: 0.5089989304542542\n",
      "Sample 3021 - loss: 4.856919765472412\n",
      "Sample 3022 - loss: 7.927341461181641\n",
      "Sample 3023 - loss: 0.009148688055574894\n",
      "Sample 3024 - loss: 0.6364352703094482\n",
      "Sample 3025 - loss: 7.296853542327881\n",
      "Sample 3026 - loss: 8.716370582580566\n",
      "Sample 3027 - loss: 1.485373854637146\n",
      "Sample 3028 - loss: 2.17061185836792\n",
      "Sample 3029 - loss: 1.63173508644104\n",
      "Sample 3030 - loss: 11.789977073669434\n",
      "Sample 3031 - loss: 0.09869766980409622\n",
      "Sample 3032 - loss: 0.08789355307817459\n",
      "Sample 3033 - loss: 4.297358989715576\n",
      "Sample 3034 - loss: 0.6520355939865112\n",
      "Sample 3035 - loss: 7.292652130126953\n",
      "Sample 3036 - loss: 8.039119720458984\n",
      "Sample 3037 - loss: 1.2323424816131592\n",
      "Sample 3038 - loss: 4.820161819458008\n",
      "Sample 3039 - loss: 13.70013427734375\n",
      "Sample 3040 - loss: 0.37217530608177185\n",
      "Sample 3041 - loss: 12.672821044921875\n",
      "Sample 3042 - loss: 0.5011618733406067\n",
      "Sample 3043 - loss: 0.04231681674718857\n",
      "Sample 3044 - loss: 0.010310476645827293\n",
      "Sample 3045 - loss: 0.14048130810260773\n",
      "Sample 3046 - loss: 5.171047210693359\n",
      "Sample 3047 - loss: 2.889585256576538\n",
      "Sample 3048 - loss: 8.289844512939453\n",
      "Sample 3049 - loss: 0.6669159531593323\n",
      "Sample 3050 - loss: 7.907850742340088\n",
      "Sample 3051 - loss: 8.162239074707031\n",
      "Sample 3052 - loss: 2.201580762863159\n",
      "Sample 3053 - loss: 4.665876865386963\n",
      "Sample 3054 - loss: 0.01881100982427597\n",
      "Sample 3055 - loss: 0.19502659142017365\n",
      "Sample 3056 - loss: 8.517054557800293\n",
      "Sample 3057 - loss: 6.532252788543701\n",
      "Sample 3058 - loss: 2.6742138862609863\n",
      "Sample 3059 - loss: 2.017366409301758\n",
      "Sample 3060 - loss: 3.5969901084899902\n",
      "Sample 3061 - loss: 1.8314595222473145\n",
      "Sample 3062 - loss: 12.874361991882324\n",
      "Sample 3063 - loss: 8.44922161102295\n",
      "Sample 3064 - loss: 0.5080419182777405\n",
      "Sample 3065 - loss: 11.009255409240723\n",
      "Sample 3066 - loss: 3.975409746170044\n",
      "Sample 3067 - loss: 1.9123176336288452\n",
      "Sample 3068 - loss: 1.2434996366500854\n",
      "Sample 3069 - loss: 3.8360238075256348\n",
      "Sample 3070 - loss: 1.8643940687179565\n",
      "Sample 3071 - loss: 2.220957040786743\n",
      "Sample 3072 - loss: 4.821990013122559\n",
      "Sample 3073 - loss: 1.139695644378662\n",
      "Sample 3074 - loss: 10.690533638000488\n",
      "Sample 3075 - loss: 0.8859929442405701\n",
      "Sample 3076 - loss: 7.675012588500977\n",
      "Sample 3077 - loss: 10.207592010498047\n",
      "Sample 3078 - loss: 6.559988975524902\n",
      "Sample 3079 - loss: 0.642140805721283\n",
      "Sample 3080 - loss: 1.3381248712539673\n",
      "Sample 3081 - loss: 0.7843554019927979\n",
      "Sample 3082 - loss: 9.785550117492676\n",
      "Sample 3083 - loss: 1.1861236095428467\n",
      "Sample 3084 - loss: 4.3618574142456055\n",
      "Sample 3085 - loss: 1.3040416240692139\n",
      "Sample 3086 - loss: 7.8866801261901855\n",
      "Sample 3087 - loss: 4.295069217681885\n",
      "Sample 3088 - loss: 4.007434368133545\n",
      "Sample 3089 - loss: 5.713115692138672\n",
      "Sample 3090 - loss: 0.906059980392456\n",
      "Sample 3091 - loss: 8.204763412475586\n",
      "Sample 3092 - loss: 4.498947620391846\n",
      "Sample 3093 - loss: 0.4239901304244995\n",
      "Sample 3094 - loss: 0.015016858465969563\n",
      "Sample 3095 - loss: 1.6343938112258911\n",
      "Sample 3096 - loss: 3.434974431991577\n",
      "Sample 3097 - loss: 0.45571354031562805\n",
      "Sample 3098 - loss: 0.18065260350704193\n",
      "Sample 3099 - loss: 2.627793550491333\n",
      "Sample 3100 - loss: 0.005027629900723696\n",
      "Sample 3101 - loss: 11.252174377441406\n",
      "Sample 3102 - loss: 2.8378689289093018\n",
      "Sample 3103 - loss: 1.6583077907562256\n",
      "Sample 3104 - loss: 2.3136589527130127\n",
      "Sample 3105 - loss: 4.623602867126465\n",
      "Sample 3106 - loss: 8.464751243591309\n",
      "Sample 3107 - loss: 4.681603908538818\n",
      "Sample 3108 - loss: 3.0572280883789062\n",
      "Sample 3109 - loss: 11.174241065979004\n",
      "Sample 3110 - loss: 5.8922247886657715\n",
      "Sample 3111 - loss: 3.5767641067504883\n",
      "Sample 3112 - loss: 2.2089242935180664\n",
      "Sample 3113 - loss: 0.7259880900382996\n",
      "Sample 3114 - loss: 6.775559902191162\n",
      "Sample 3115 - loss: 4.854175567626953\n",
      "Sample 3116 - loss: 11.674162864685059\n",
      "Sample 3117 - loss: 0.2238880693912506\n",
      "Sample 3118 - loss: 4.599270820617676\n",
      "Sample 3119 - loss: 5.9217424392700195\n",
      "Sample 3120 - loss: 1.9583172798156738\n",
      "Sample 3121 - loss: 6.3355021476745605\n",
      "Sample 3122 - loss: 8.037339210510254\n",
      "Sample 3123 - loss: 2.4220786094665527\n",
      "Sample 3124 - loss: 3.744464635848999\n",
      "Sample 3125 - loss: 3.688649892807007\n",
      "Sample 3126 - loss: 4.059030055999756\n",
      "Sample 3127 - loss: 0.10005137324333191\n",
      "Sample 3128 - loss: 0.16950057446956635\n",
      "Sample 3129 - loss: 0.011185580864548683\n",
      "Sample 3130 - loss: 5.516689300537109\n",
      "Sample 3131 - loss: 7.078157424926758\n",
      "Sample 3132 - loss: 4.520614147186279\n",
      "Sample 3133 - loss: 1.0878376960754395\n",
      "Sample 3134 - loss: 4.191418647766113\n",
      "Sample 3135 - loss: 10.670831680297852\n",
      "Sample 3136 - loss: 9.754007339477539\n",
      "Sample 3137 - loss: 5.132594585418701\n",
      "Sample 3138 - loss: 1.4582692384719849\n",
      "Sample 3139 - loss: 0.29523202776908875\n",
      "Sample 3140 - loss: 0.2713692784309387\n",
      "Sample 3141 - loss: 1.0816882848739624\n",
      "Sample 3142 - loss: 7.64986515045166\n",
      "Sample 3143 - loss: 4.29354190826416\n",
      "Sample 3144 - loss: 0.4120379686355591\n",
      "Sample 3145 - loss: 0.30183032155036926\n",
      "Sample 3146 - loss: 1.9441850185394287\n",
      "Sample 3147 - loss: 6.273259162902832\n",
      "Sample 3148 - loss: 0.2126603126525879\n",
      "Sample 3149 - loss: 0.042638398706912994\n",
      "Sample 3150 - loss: 0.3859994411468506\n",
      "Sample 3151 - loss: 0.2850051820278168\n",
      "Sample 3152 - loss: 8.904114723205566\n",
      "Sample 3153 - loss: 6.161249160766602\n",
      "Sample 3154 - loss: 5.49545955657959\n",
      "Sample 3155 - loss: 8.077664375305176\n",
      "Sample 3156 - loss: 0.07842415571212769\n",
      "Sample 3157 - loss: 1.7343710660934448\n",
      "Sample 3158 - loss: 4.918230056762695\n",
      "Sample 3159 - loss: 0.0416930690407753\n",
      "Sample 3160 - loss: 1.367637038230896\n",
      "Sample 3161 - loss: 0.05580613762140274\n",
      "Sample 3162 - loss: 1.3517111539840698\n",
      "Sample 3163 - loss: 3.3831958770751953\n",
      "Sample 3164 - loss: 3.068455219268799\n",
      "Sample 3165 - loss: 7.084348678588867\n",
      "Sample 3166 - loss: 3.887799024581909\n",
      "Sample 3167 - loss: 2.679116725921631\n",
      "Sample 3168 - loss: 2.870939254760742\n",
      "Sample 3169 - loss: 2.5716769695281982\n",
      "Sample 3170 - loss: 5.898744583129883\n",
      "Sample 3171 - loss: 1.3318815231323242\n",
      "Sample 3172 - loss: 6.445073127746582\n",
      "Sample 3173 - loss: 2.0420823097229004\n",
      "Sample 3174 - loss: 7.3973388671875\n",
      "Sample 3175 - loss: 0.851869523525238\n",
      "Sample 3176 - loss: 2.1121890544891357\n",
      "Sample 3177 - loss: 0.3111076354980469\n",
      "Sample 3178 - loss: 4.534170150756836\n",
      "Sample 3179 - loss: 1.5947870016098022\n",
      "Sample 3180 - loss: 3.5296692848205566\n",
      "Sample 3181 - loss: 3.751039981842041\n",
      "Sample 3182 - loss: 3.099590539932251\n",
      "Sample 3183 - loss: 1.7406854629516602\n",
      "Sample 3184 - loss: 6.418241024017334\n",
      "Sample 3185 - loss: 6.850354194641113\n",
      "Sample 3186 - loss: 7.734689235687256\n",
      "Sample 3187 - loss: 0.9288468956947327\n",
      "Sample 3188 - loss: 0.015021576546132565\n",
      "Sample 3189 - loss: 8.168838500976562\n",
      "Sample 3190 - loss: 2.3450491428375244\n",
      "Sample 3191 - loss: 0.145619198679924\n",
      "Sample 3192 - loss: 0.044226303696632385\n",
      "Sample 3193 - loss: 3.698190689086914\n",
      "Sample 3194 - loss: 2.086904525756836\n",
      "Sample 3195 - loss: 0.507085919380188\n",
      "Sample 3196 - loss: 6.450633525848389\n",
      "Sample 3197 - loss: 1.1490932703018188\n",
      "Sample 3198 - loss: 5.00692892074585\n",
      "Sample 3199 - loss: 1.7308058738708496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3200 - loss: 8.432062149047852\n",
      "Sample 3201 - loss: 0.20589803159236908\n",
      "Sample 3202 - loss: 1.8426474332809448\n",
      "Sample 3203 - loss: 1.4412509202957153\n",
      "Sample 3204 - loss: 8.646929740905762\n",
      "Sample 3205 - loss: 4.616246700286865\n",
      "Sample 3206 - loss: 4.333710193634033\n",
      "Sample 3207 - loss: 1.0663855075836182\n",
      "Sample 3208 - loss: 4.207803726196289\n",
      "Sample 3209 - loss: 2.136035680770874\n",
      "Sample 3210 - loss: 8.519187927246094\n",
      "Sample 3211 - loss: 3.144345760345459\n",
      "Sample 3212 - loss: 2.7862942218780518\n",
      "Sample 3213 - loss: 9.050345420837402\n",
      "Sample 3214 - loss: 1.549069881439209\n",
      "Sample 3215 - loss: 0.00570777477696538\n",
      "Sample 3216 - loss: 5.173387050628662\n",
      "Sample 3217 - loss: 3.377110004425049\n",
      "Sample 3218 - loss: 6.058750152587891\n",
      "Sample 3219 - loss: 7.4409260749816895\n",
      "Sample 3220 - loss: 3.3525989055633545\n",
      "Sample 3221 - loss: 9.497699737548828\n",
      "Sample 3222 - loss: 9.424042701721191\n",
      "Sample 3223 - loss: 0.007267504930496216\n",
      "Sample 3224 - loss: 0.646348237991333\n",
      "Sample 3225 - loss: 1.1736891269683838\n",
      "Sample 3226 - loss: 1.6872247457504272\n",
      "Sample 3227 - loss: 7.724116802215576\n",
      "Sample 3228 - loss: 8.173908233642578\n",
      "Sample 3229 - loss: 7.624435901641846\n",
      "Sample 3230 - loss: 3.7782785892486572\n",
      "Sample 3231 - loss: 9.410602569580078\n",
      "Sample 3232 - loss: 6.905546188354492\n",
      "Sample 3233 - loss: 2.250669479370117\n",
      "Sample 3234 - loss: 5.130932807922363\n",
      "Sample 3235 - loss: 5.19431209564209\n",
      "Sample 3236 - loss: 4.6436896324157715\n",
      "Sample 3237 - loss: 2.0622611045837402\n",
      "Sample 3238 - loss: 0.10757453739643097\n",
      "Sample 3239 - loss: 0.04092968627810478\n",
      "Sample 3240 - loss: 4.672723770141602\n",
      "Sample 3241 - loss: 6.489480972290039\n",
      "Sample 3242 - loss: 7.679282188415527\n",
      "Sample 3243 - loss: 0.024772711098194122\n",
      "Sample 3244 - loss: 7.376153469085693\n",
      "Sample 3245 - loss: 13.284660339355469\n",
      "Sample 3246 - loss: 8.929447174072266\n",
      "Sample 3247 - loss: 7.432857513427734\n",
      "Sample 3248 - loss: 7.22808837890625\n",
      "Sample 3249 - loss: 0.07966909557580948\n",
      "Sample 3250 - loss: 7.491083145141602\n",
      "Sample 3251 - loss: 2.661468744277954\n",
      "Sample 3252 - loss: 6.881350517272949\n",
      "Sample 3253 - loss: 0.19496959447860718\n",
      "Sample 3254 - loss: 4.053246021270752\n",
      "Sample 3255 - loss: 0.8383756279945374\n",
      "Sample 3256 - loss: 0.6775807738304138\n",
      "Sample 3257 - loss: 0.8315607309341431\n",
      "Sample 3258 - loss: 9.236080169677734\n",
      "Sample 3259 - loss: 0.8566410541534424\n",
      "Sample 3260 - loss: 3.716622829437256\n",
      "Sample 3261 - loss: 0.3456351161003113\n",
      "Sample 3262 - loss: 8.707759857177734\n",
      "Sample 3263 - loss: 4.209907054901123\n",
      "Sample 3264 - loss: 0.41582679748535156\n",
      "Sample 3265 - loss: 2.335859537124634\n",
      "Sample 3266 - loss: 11.13543701171875\n",
      "Sample 3267 - loss: 0.3244369924068451\n",
      "Sample 3268 - loss: 0.048783864825963974\n",
      "Sample 3269 - loss: 0.5036436915397644\n",
      "Sample 3270 - loss: 3.9972028732299805\n",
      "Sample 3271 - loss: 0.018678152933716774\n",
      "Sample 3272 - loss: 2.2897391319274902\n",
      "Sample 3273 - loss: 0.4966731369495392\n",
      "Sample 3274 - loss: 0.014505845494568348\n",
      "Sample 3275 - loss: 0.34850212931632996\n",
      "Sample 3276 - loss: 2.197439670562744\n",
      "Sample 3277 - loss: 0.06533481180667877\n",
      "Sample 3278 - loss: 0.15345709025859833\n",
      "Sample 3279 - loss: 8.540266990661621\n",
      "Sample 3280 - loss: 0.45755845308303833\n",
      "Sample 3281 - loss: 13.00992202758789\n",
      "Sample 3282 - loss: 4.712486743927002\n",
      "Sample 3283 - loss: 0.9900640249252319\n",
      "Sample 3284 - loss: 7.297238349914551\n",
      "Sample 3285 - loss: 10.114401817321777\n",
      "Sample 3286 - loss: 0.09272022545337677\n",
      "Sample 3287 - loss: 0.8149044513702393\n",
      "Sample 3288 - loss: 0.5233107209205627\n",
      "Sample 3289 - loss: 8.086776733398438\n",
      "Sample 3290 - loss: 2.079960823059082\n",
      "Sample 3291 - loss: 1.9826159477233887\n",
      "Sample 3292 - loss: 1.6769392490386963\n",
      "Sample 3293 - loss: 9.457645416259766\n",
      "Sample 3294 - loss: 3.1759872436523438\n",
      "Sample 3295 - loss: 2.378005027770996\n",
      "Sample 3296 - loss: 3.276998996734619\n",
      "Sample 3297 - loss: 0.17421402037143707\n",
      "Sample 3298 - loss: 0.0707395076751709\n",
      "Sample 3299 - loss: 5.649473190307617\n",
      "Sample 3300 - loss: 7.5297064781188965\n",
      "Sample 3301 - loss: 1.031486988067627\n",
      "Sample 3302 - loss: 2.858355760574341\n",
      "Sample 3303 - loss: 0.1835981160402298\n",
      "Sample 3304 - loss: 0.050156548619270325\n",
      "Sample 3305 - loss: 5.6278862953186035\n",
      "Sample 3306 - loss: 4.065067291259766\n",
      "Sample 3307 - loss: 0.2961934208869934\n",
      "Sample 3308 - loss: 3.173929452896118\n",
      "Sample 3309 - loss: 3.7454640865325928\n",
      "Sample 3310 - loss: 8.363253593444824\n",
      "Sample 3311 - loss: 1.5685086250305176\n",
      "Sample 3312 - loss: 0.956807017326355\n",
      "Sample 3313 - loss: 0.03443736582994461\n",
      "Sample 3314 - loss: 0.08533583581447601\n",
      "Sample 3315 - loss: 6.181143760681152\n",
      "Sample 3316 - loss: 1.1265037059783936\n",
      "Sample 3317 - loss: 4.397918224334717\n",
      "Sample 3318 - loss: 4.378722667694092\n",
      "Sample 3319 - loss: 10.01171588897705\n",
      "Sample 3320 - loss: 0.013613604009151459\n",
      "Sample 3321 - loss: 4.150763988494873\n",
      "Sample 3322 - loss: 4.109951972961426\n",
      "Sample 3323 - loss: 1.625360131263733\n",
      "Sample 3324 - loss: 0.5005807280540466\n",
      "Sample 3325 - loss: 5.5383734703063965\n",
      "Sample 3326 - loss: 3.1753296852111816\n",
      "Sample 3327 - loss: 0.011995104141533375\n",
      "Sample 3328 - loss: 2.704227924346924\n",
      "Sample 3329 - loss: 7.012963771820068\n",
      "Sample 3330 - loss: 2.195014238357544\n",
      "Sample 3331 - loss: 12.751587867736816\n",
      "Sample 3332 - loss: 0.014829354360699654\n",
      "Sample 3333 - loss: 4.853201389312744\n",
      "Sample 3334 - loss: 3.1654741764068604\n",
      "Sample 3335 - loss: 0.1028328612446785\n",
      "Sample 3336 - loss: 0.211082324385643\n",
      "Sample 3337 - loss: 1.6137380599975586\n",
      "Sample 3338 - loss: 2.7866082191467285\n",
      "Sample 3339 - loss: 1.628849983215332\n",
      "Sample 3340 - loss: 2.780355215072632\n",
      "Sample 3341 - loss: 3.700225830078125\n",
      "Sample 3342 - loss: 11.597063064575195\n",
      "Sample 3343 - loss: 9.598899841308594\n",
      "Sample 3344 - loss: 4.586797714233398\n",
      "Sample 3345 - loss: 0.6416343450546265\n",
      "Sample 3346 - loss: 10.238917350769043\n",
      "Sample 3347 - loss: 5.44600772857666\n",
      "Sample 3348 - loss: 8.772966384887695\n",
      "Sample 3349 - loss: 0.9818813800811768\n",
      "Sample 3350 - loss: 0.09171703457832336\n",
      "Sample 3351 - loss: 8.309988975524902\n",
      "Sample 3352 - loss: 0.9232141375541687\n",
      "Sample 3353 - loss: 0.044193290174007416\n",
      "Sample 3354 - loss: 4.645327568054199\n",
      "Sample 3355 - loss: 0.3822631537914276\n",
      "Sample 3356 - loss: 10.942608833312988\n",
      "Sample 3357 - loss: 6.135980129241943\n",
      "Sample 3358 - loss: 2.8348217010498047\n",
      "Sample 3359 - loss: 0.3971283435821533\n",
      "Sample 3360 - loss: 7.791285514831543\n",
      "Sample 3361 - loss: 2.132821559906006\n",
      "Sample 3362 - loss: 0.5044506192207336\n",
      "Sample 3363 - loss: 8.89797592163086\n",
      "Sample 3364 - loss: 1.4441088438034058\n",
      "Sample 3365 - loss: 9.893414497375488\n",
      "Sample 3366 - loss: 10.596278190612793\n",
      "Sample 3367 - loss: 0.025572707876563072\n",
      "Sample 3368 - loss: 2.3767316341400146\n",
      "Sample 3369 - loss: 0.042897891253232956\n",
      "Sample 3370 - loss: 0.7464563846588135\n",
      "Sample 3371 - loss: 4.24127721786499\n",
      "Sample 3372 - loss: 6.904314041137695\n",
      "Sample 3373 - loss: 0.6606731414794922\n",
      "Sample 3374 - loss: 5.776666641235352\n",
      "Sample 3375 - loss: 4.601935863494873\n",
      "Sample 3376 - loss: 8.112099647521973\n",
      "Sample 3377 - loss: 1.9604122638702393\n",
      "Sample 3378 - loss: 0.03419899567961693\n",
      "Sample 3379 - loss: 5.816959857940674\n",
      "Sample 3380 - loss: 11.030945777893066\n",
      "Sample 3381 - loss: 0.8999481797218323\n",
      "Sample 3382 - loss: 7.747194766998291\n",
      "Sample 3383 - loss: 0.8046407103538513\n",
      "Sample 3384 - loss: 6.835899829864502\n",
      "Sample 3385 - loss: 0.28888121247291565\n",
      "Sample 3386 - loss: 3.6568338871002197\n",
      "Sample 3387 - loss: 0.7244880199432373\n",
      "Sample 3388 - loss: 0.6591275930404663\n",
      "Sample 3389 - loss: 7.9295196533203125\n",
      "Sample 3390 - loss: 6.069582939147949\n",
      "Sample 3391 - loss: 0.0508989542722702\n",
      "Sample 3392 - loss: 4.495838165283203\n",
      "Sample 3393 - loss: 10.51333999633789\n",
      "Sample 3394 - loss: 3.920705556869507\n",
      "Sample 3395 - loss: 4.565442085266113\n",
      "Sample 3396 - loss: 9.007369995117188\n",
      "Sample 3397 - loss: 1.5956076383590698\n",
      "Sample 3398 - loss: 5.296300888061523\n",
      "Sample 3399 - loss: 0.1331295520067215\n",
      "Sample 3400 - loss: 0.12295892834663391\n",
      "Sample 3401 - loss: 6.277611255645752\n",
      "Sample 3402 - loss: 2.1801037788391113\n",
      "Sample 3403 - loss: 2.012333631515503\n",
      "Sample 3404 - loss: 0.12928734719753265\n",
      "Sample 3405 - loss: 4.129331111907959\n",
      "Sample 3406 - loss: 2.1461403369903564\n",
      "Sample 3407 - loss: 7.97471809387207\n",
      "Sample 3408 - loss: 1.796289324760437\n",
      "Sample 3409 - loss: 5.768660068511963\n",
      "Sample 3410 - loss: 3.2978098392486572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3411 - loss: 0.11382681131362915\n",
      "Sample 3412 - loss: 0.7112985253334045\n",
      "Sample 3413 - loss: 10.953455924987793\n",
      "Sample 3414 - loss: 3.9564919471740723\n",
      "Sample 3415 - loss: 8.030448913574219\n",
      "Sample 3416 - loss: 5.584470272064209\n",
      "Sample 3417 - loss: 1.211750864982605\n",
      "Sample 3418 - loss: 0.6026954054832458\n",
      "Sample 3419 - loss: 0.9535388350486755\n",
      "Sample 3420 - loss: 2.9049882888793945\n",
      "Sample 3421 - loss: 3.2991690635681152\n",
      "Sample 3422 - loss: 0.34674397110939026\n",
      "Sample 3423 - loss: 5.204678535461426\n",
      "Sample 3424 - loss: 8.794408798217773\n",
      "Sample 3425 - loss: 0.47983863949775696\n",
      "Sample 3426 - loss: 2.581202983856201\n",
      "Sample 3427 - loss: 1.6955894231796265\n",
      "Sample 3428 - loss: 3.219452142715454\n",
      "Sample 3429 - loss: 0.2542212903499603\n",
      "Sample 3430 - loss: 7.60023307800293\n",
      "Sample 3431 - loss: 8.996635437011719\n",
      "Sample 3432 - loss: 7.294495105743408\n",
      "Sample 3433 - loss: 9.943129539489746\n",
      "Sample 3434 - loss: 1.3922518491744995\n",
      "Sample 3435 - loss: 0.4538339376449585\n",
      "Sample 3436 - loss: 6.9208984375\n",
      "Sample 3437 - loss: 5.2070183753967285\n",
      "Sample 3438 - loss: 0.7236549258232117\n",
      "Sample 3439 - loss: 4.212355136871338\n",
      "Sample 3440 - loss: 1.251875400543213\n",
      "Sample 3441 - loss: 3.4360435009002686\n",
      "Sample 3442 - loss: 0.16286878287792206\n",
      "Sample 3443 - loss: 7.694831371307373\n",
      "Sample 3444 - loss: 3.2912964820861816\n",
      "Sample 3445 - loss: 3.6191530227661133\n",
      "Sample 3446 - loss: 4.2067670822143555\n",
      "Sample 3447 - loss: 4.635080814361572\n",
      "Sample 3448 - loss: 8.753539085388184\n",
      "Sample 3449 - loss: 0.42073050141334534\n",
      "Sample 3450 - loss: 10.268919944763184\n",
      "Sample 3451 - loss: 1.5914274454116821\n",
      "Sample 3452 - loss: 0.3688443899154663\n",
      "Sample 3453 - loss: 5.781411170959473\n",
      "Sample 3454 - loss: 8.24853515625\n",
      "Sample 3455 - loss: 1.9059538841247559\n",
      "Sample 3456 - loss: 2.3534443378448486\n",
      "Sample 3457 - loss: 0.8680348992347717\n",
      "Sample 3458 - loss: 0.5385197997093201\n",
      "Sample 3459 - loss: 7.482824802398682\n",
      "Sample 3460 - loss: 0.40023693442344666\n",
      "Sample 3461 - loss: 9.391898155212402\n",
      "Sample 3462 - loss: 0.9600503444671631\n",
      "Sample 3463 - loss: 1.5321807861328125\n",
      "Sample 3464 - loss: 4.291709899902344\n",
      "Sample 3465 - loss: 0.1752377301454544\n",
      "Sample 3466 - loss: 8.763065338134766\n",
      "Sample 3467 - loss: 1.0420490503311157\n",
      "Sample 3468 - loss: 1.9217323064804077\n",
      "Sample 3469 - loss: 0.0682215690612793\n",
      "Sample 3470 - loss: 0.16106368601322174\n",
      "Sample 3471 - loss: 5.055907726287842\n",
      "Sample 3472 - loss: 2.583399772644043\n",
      "Sample 3473 - loss: 7.628922939300537\n",
      "Sample 3474 - loss: 6.7628889083862305\n",
      "Sample 3475 - loss: 6.029979228973389\n",
      "Sample 3476 - loss: 5.5205278396606445\n",
      "Sample 3477 - loss: 8.376506805419922\n",
      "Sample 3478 - loss: 0.2988259494304657\n",
      "Sample 3479 - loss: 13.622304916381836\n",
      "Sample 3480 - loss: 6.135672569274902\n",
      "Sample 3481 - loss: 11.163442611694336\n",
      "Sample 3482 - loss: 9.124249458312988\n",
      "Sample 3483 - loss: 2.381619930267334\n",
      "Sample 3484 - loss: 3.873196601867676\n",
      "Sample 3485 - loss: 0.2975424528121948\n",
      "Sample 3486 - loss: 8.801469802856445\n",
      "Sample 3487 - loss: 11.299599647521973\n",
      "Sample 3488 - loss: 0.13051480054855347\n",
      "Sample 3489 - loss: 0.5766971111297607\n",
      "Sample 3490 - loss: 4.380602836608887\n",
      "Sample 3491 - loss: 1.6729159355163574\n",
      "Sample 3492 - loss: 7.2177205085754395\n",
      "Sample 3493 - loss: 0.6331812143325806\n",
      "Sample 3494 - loss: 0.05255099758505821\n",
      "Sample 3495 - loss: 8.232351303100586\n",
      "Sample 3496 - loss: 8.456439018249512\n",
      "Sample 3497 - loss: 4.3818769454956055\n",
      "Sample 3498 - loss: 3.0580263137817383\n",
      "Sample 3499 - loss: 7.013758659362793\n",
      "Sample 3500 - loss: 1.5219027996063232\n",
      "Sample 3501 - loss: 0.35135313868522644\n",
      "Sample 3502 - loss: 0.21236249804496765\n",
      "Sample 3503 - loss: 2.4518017768859863\n",
      "Sample 3504 - loss: 5.269478797912598\n",
      "Sample 3505 - loss: 3.1602132320404053\n",
      "Sample 3506 - loss: 4.422589302062988\n",
      "Sample 3507 - loss: 3.7656078338623047\n",
      "Sample 3508 - loss: 0.6358916759490967\n",
      "Sample 3509 - loss: 7.230961799621582\n",
      "Sample 3510 - loss: 0.41880276799201965\n",
      "Sample 3511 - loss: 7.897079944610596\n",
      "Sample 3512 - loss: 12.034821510314941\n",
      "Sample 3513 - loss: 3.8602592945098877\n",
      "Sample 3514 - loss: 5.699941635131836\n",
      "Sample 3515 - loss: 8.908612251281738\n",
      "Sample 3516 - loss: 0.16130954027175903\n",
      "Sample 3517 - loss: 1.7914199829101562\n",
      "Sample 3518 - loss: 1.1264206171035767\n",
      "Sample 3519 - loss: 3.2702372074127197\n",
      "Sample 3520 - loss: 1.339789867401123\n",
      "Sample 3521 - loss: 2.1588852405548096\n",
      "Sample 3522 - loss: 5.344560623168945\n",
      "Sample 3523 - loss: 3.070188522338867\n",
      "Sample 3524 - loss: 5.926236152648926\n",
      "Sample 3525 - loss: 0.16014815866947174\n",
      "Sample 3526 - loss: 9.7583589553833\n",
      "Sample 3527 - loss: 2.2223448753356934\n",
      "Sample 3528 - loss: 3.1954774856567383\n",
      "Sample 3529 - loss: 3.699852705001831\n",
      "Sample 3530 - loss: 2.656039237976074\n",
      "Sample 3531 - loss: 2.428354501724243\n",
      "Sample 3532 - loss: 3.6456191539764404\n",
      "Sample 3533 - loss: 12.931840896606445\n",
      "Sample 3534 - loss: 1.8441194295883179\n",
      "Sample 3535 - loss: 4.741404056549072\n",
      "Sample 3536 - loss: 4.941992282867432\n",
      "Sample 3537 - loss: 4.694232940673828\n",
      "Sample 3538 - loss: 5.484168529510498\n",
      "Sample 3539 - loss: 9.731760025024414\n",
      "Sample 3540 - loss: 0.5317011475563049\n",
      "Sample 3541 - loss: 0.08189699053764343\n",
      "Sample 3542 - loss: 0.33114320039749146\n",
      "Sample 3543 - loss: 10.873795509338379\n",
      "Sample 3544 - loss: 2.621187210083008\n",
      "Sample 3545 - loss: 4.111985206604004\n",
      "Sample 3546 - loss: 3.045938014984131\n",
      "Sample 3547 - loss: 1.200609803199768\n",
      "Sample 3548 - loss: 2.032755136489868\n",
      "Sample 3549 - loss: 6.887287139892578\n",
      "Sample 3550 - loss: 1.3155971765518188\n",
      "Sample 3551 - loss: 1.3026233911514282\n",
      "Sample 3552 - loss: 0.8716766834259033\n",
      "Sample 3553 - loss: 5.465540885925293\n",
      "Sample 3554 - loss: 0.01779785379767418\n",
      "Sample 3555 - loss: 8.666491508483887\n",
      "Sample 3556 - loss: 8.809244155883789\n",
      "Sample 3557 - loss: 9.055394172668457\n",
      "Sample 3558 - loss: 11.54719352722168\n",
      "Sample 3559 - loss: 0.04831746593117714\n",
      "Sample 3560 - loss: 3.1891555786132812\n",
      "Sample 3561 - loss: 4.305952548980713\n",
      "Sample 3562 - loss: 2.3769826889038086\n",
      "Sample 3563 - loss: 6.429553985595703\n",
      "Sample 3564 - loss: 2.299231767654419\n",
      "Sample 3565 - loss: 7.353787422180176\n",
      "Sample 3566 - loss: 9.251932144165039\n",
      "Sample 3567 - loss: 4.279799938201904\n",
      "Sample 3568 - loss: 6.4092793464660645\n",
      "Sample 3569 - loss: 1.355422854423523\n",
      "Sample 3570 - loss: 0.6088415384292603\n",
      "Sample 3571 - loss: 1.261894941329956\n",
      "Sample 3572 - loss: 0.8745725750923157\n",
      "Sample 3573 - loss: 2.5225141048431396\n",
      "Sample 3574 - loss: 3.072735548019409\n",
      "Sample 3575 - loss: 7.224725723266602\n",
      "Sample 3576 - loss: 1.379973292350769\n",
      "Sample 3577 - loss: 12.132699012756348\n",
      "Sample 3578 - loss: 3.75752329826355\n",
      "Sample 3579 - loss: 11.8169584274292\n",
      "Sample 3580 - loss: 6.355532169342041\n",
      "Sample 3581 - loss: 3.689023494720459\n",
      "Sample 3582 - loss: 4.514136791229248\n",
      "Sample 3583 - loss: 0.31092655658721924\n",
      "Sample 3584 - loss: 3.780447483062744\n",
      "Sample 3585 - loss: 0.11462006717920303\n",
      "Sample 3586 - loss: 11.9833984375\n",
      "Sample 3587 - loss: 13.892922401428223\n",
      "Sample 3588 - loss: 3.0527219772338867\n",
      "Sample 3589 - loss: 0.7967453598976135\n",
      "Sample 3590 - loss: 8.279108047485352\n",
      "Sample 3591 - loss: 6.6312127113342285\n",
      "Sample 3592 - loss: 6.844467639923096\n",
      "Sample 3593 - loss: 9.838444709777832\n",
      "Sample 3594 - loss: 0.4306796193122864\n",
      "Sample 3595 - loss: 1.6291284561157227\n",
      "Sample 3596 - loss: 0.6968404650688171\n",
      "Sample 3597 - loss: 0.08168570697307587\n",
      "Sample 3598 - loss: 5.659943103790283\n",
      "Sample 3599 - loss: 2.192328691482544\n",
      "Sample 3600 - loss: 8.65654182434082\n",
      "Sample 3601 - loss: 0.4232071340084076\n",
      "Sample 3602 - loss: 12.920079231262207\n",
      "Sample 3603 - loss: 1.1230053901672363\n",
      "Sample 3604 - loss: 1.6276071071624756\n",
      "Sample 3605 - loss: 2.4344260692596436\n",
      "Sample 3606 - loss: 1.7133160829544067\n",
      "Sample 3607 - loss: 0.6552798748016357\n",
      "Sample 3608 - loss: 3.046956777572632\n",
      "Sample 3609 - loss: 7.977133274078369\n",
      "Sample 3610 - loss: 8.933399200439453\n",
      "Sample 3611 - loss: 6.823866367340088\n",
      "Sample 3612 - loss: 8.641341209411621\n",
      "Sample 3613 - loss: 8.742888450622559\n",
      "Sample 3614 - loss: 1.7757922410964966\n",
      "Sample 3615 - loss: 3.4497992992401123\n",
      "Sample 3616 - loss: 8.003152847290039\n",
      "Sample 3617 - loss: 6.741094589233398\n",
      "Sample 3618 - loss: 8.590808868408203\n",
      "Sample 3619 - loss: 0.3664360046386719\n",
      "Sample 3620 - loss: 0.6559040546417236\n",
      "Sample 3621 - loss: 0.8166341185569763\n",
      "Sample 3622 - loss: 0.6603268384933472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3623 - loss: 1.4311249256134033\n",
      "Sample 3624 - loss: 6.319538116455078\n",
      "Sample 3625 - loss: 2.4812116622924805\n",
      "Sample 3626 - loss: 5.951370716094971\n",
      "Sample 3627 - loss: 4.537091255187988\n",
      "Sample 3628 - loss: 4.725359916687012\n",
      "Sample 3629 - loss: 3.1406409740448\n",
      "Sample 3630 - loss: 2.817072868347168\n",
      "Sample 3631 - loss: 11.810173034667969\n",
      "Sample 3632 - loss: 0.333598792552948\n",
      "Sample 3633 - loss: 5.789766788482666\n",
      "Sample 3634 - loss: 2.9727730751037598\n",
      "Sample 3635 - loss: 0.022854939103126526\n",
      "Sample 3636 - loss: 0.08088592439889908\n",
      "Sample 3637 - loss: 10.08651065826416\n",
      "Sample 3638 - loss: 9.874399185180664\n",
      "Sample 3639 - loss: 12.816479682922363\n",
      "Sample 3640 - loss: 7.303825855255127\n",
      "Sample 3641 - loss: 1.2003618478775024\n",
      "Sample 3642 - loss: 8.72810173034668\n",
      "Sample 3643 - loss: 10.626258850097656\n",
      "Sample 3644 - loss: 0.06929139792919159\n",
      "Sample 3645 - loss: 4.818211555480957\n",
      "Sample 3646 - loss: 2.3088197708129883\n",
      "Sample 3647 - loss: 5.7409772872924805\n",
      "Sample 3648 - loss: 4.624357223510742\n",
      "Sample 3649 - loss: 7.671298980712891\n",
      "Sample 3650 - loss: 1.2859883308410645\n",
      "Sample 3651 - loss: 3.286710500717163\n",
      "Sample 3652 - loss: 2.1944613456726074\n",
      "Sample 3653 - loss: 2.5631513595581055\n",
      "Sample 3654 - loss: 7.899359226226807\n",
      "Sample 3655 - loss: 9.851162910461426\n",
      "Sample 3656 - loss: 0.10126087814569473\n",
      "Sample 3657 - loss: 0.017480485141277313\n",
      "Sample 3658 - loss: 0.1552550345659256\n",
      "Sample 3659 - loss: 2.8466010093688965\n",
      "Sample 3660 - loss: 12.486181259155273\n",
      "Sample 3661 - loss: 0.07293827831745148\n",
      "Sample 3662 - loss: 0.8297563195228577\n",
      "Sample 3663 - loss: 1.134793996810913\n",
      "Sample 3664 - loss: 2.681136131286621\n",
      "Sample 3665 - loss: 1.9550126791000366\n",
      "Sample 3666 - loss: 4.147677421569824\n",
      "Sample 3667 - loss: 2.741342067718506\n",
      "Sample 3668 - loss: 1.102892279624939\n",
      "Sample 3669 - loss: 6.527406215667725\n",
      "Sample 3670 - loss: 5.5249481201171875\n",
      "Sample 3671 - loss: 4.968181610107422\n",
      "Sample 3672 - loss: 11.69355583190918\n",
      "Sample 3673 - loss: 8.247486114501953\n",
      "Sample 3674 - loss: 0.9094853401184082\n",
      "Sample 3675 - loss: 4.626360893249512\n",
      "Sample 3676 - loss: 4.648777961730957\n",
      "Sample 3677 - loss: 5.67121696472168\n",
      "Sample 3678 - loss: 3.401752233505249\n",
      "Sample 3679 - loss: 0.36511707305908203\n",
      "Sample 3680 - loss: 4.692996978759766\n",
      "Sample 3681 - loss: 6.868238925933838\n",
      "Sample 3682 - loss: 7.342226028442383\n",
      "Sample 3683 - loss: 0.11887896806001663\n",
      "Sample 3684 - loss: 0.81444251537323\n",
      "Sample 3685 - loss: 3.824117660522461\n",
      "Sample 3686 - loss: 0.19004939496517181\n",
      "Sample 3687 - loss: 4.299543857574463\n",
      "Sample 3688 - loss: 4.366644382476807\n",
      "Sample 3689 - loss: 5.989685535430908\n",
      "Sample 3690 - loss: 5.6640448570251465\n",
      "Sample 3691 - loss: 3.4967823028564453\n",
      "Sample 3692 - loss: 7.231834888458252\n",
      "Sample 3693 - loss: 0.13268622756004333\n",
      "Sample 3694 - loss: 0.8847772479057312\n",
      "Sample 3695 - loss: 7.570645809173584\n",
      "Sample 3696 - loss: 5.534184455871582\n",
      "Sample 3697 - loss: 1.1948322057724\n",
      "Sample 3698 - loss: 9.189373016357422\n",
      "Sample 3699 - loss: 0.24464435875415802\n",
      "Sample 3700 - loss: 5.818741321563721\n",
      "Sample 3701 - loss: 9.460241317749023\n",
      "Sample 3702 - loss: 7.05727481842041\n",
      "Sample 3703 - loss: 1.4320873022079468\n",
      "Sample 3704 - loss: 1.4342845678329468\n",
      "Sample 3705 - loss: 0.3336244821548462\n",
      "Sample 3706 - loss: 0.7377472519874573\n",
      "Sample 3707 - loss: 8.109103202819824\n",
      "Sample 3708 - loss: 3.4731860160827637\n",
      "Sample 3709 - loss: 6.742120742797852\n",
      "Sample 3710 - loss: 2.2212257385253906\n",
      "Sample 3711 - loss: 3.0972912311553955\n",
      "Sample 3712 - loss: 0.006003509741276503\n",
      "Sample 3713 - loss: 4.892054557800293\n",
      "Sample 3714 - loss: 1.5257872343063354\n",
      "Sample 3715 - loss: 3.323650598526001\n",
      "Sample 3716 - loss: 2.2190985679626465\n",
      "Sample 3717 - loss: 0.4060676693916321\n",
      "Sample 3718 - loss: 4.752131462097168\n",
      "Sample 3719 - loss: 0.25767385959625244\n",
      "Sample 3720 - loss: 3.1350927352905273\n",
      "Sample 3721 - loss: 8.186420440673828\n",
      "Sample 3722 - loss: 4.722864151000977\n",
      "Sample 3723 - loss: 8.551431655883789\n",
      "Sample 3724 - loss: 1.3408176898956299\n",
      "Sample 3725 - loss: 1.4791381359100342\n",
      "Sample 3726 - loss: 2.7654244899749756\n",
      "Sample 3727 - loss: 0.12528349459171295\n",
      "Sample 3728 - loss: 2.8608200550079346\n",
      "Sample 3729 - loss: 0.029225094243884087\n",
      "Sample 3730 - loss: 0.14536739885807037\n",
      "Sample 3731 - loss: 4.666454792022705\n",
      "Sample 3732 - loss: 7.411866664886475\n",
      "Sample 3733 - loss: 0.9258564710617065\n",
      "Sample 3734 - loss: 5.077103137969971\n",
      "Sample 3735 - loss: 5.5095624923706055\n",
      "Sample 3736 - loss: 0.6673400402069092\n",
      "Sample 3737 - loss: 7.748902797698975\n",
      "Sample 3738 - loss: 4.063908576965332\n",
      "Sample 3739 - loss: 0.5116078853607178\n",
      "Sample 3740 - loss: 0.9409708976745605\n",
      "Sample 3741 - loss: 0.004131705965846777\n",
      "Sample 3742 - loss: 7.565035820007324\n",
      "Sample 3743 - loss: 1.2484205961227417\n",
      "Sample 3744 - loss: 5.739991664886475\n",
      "Sample 3745 - loss: 0.15165254473686218\n",
      "Sample 3746 - loss: 3.8824362754821777\n",
      "Sample 3747 - loss: 6.359592914581299\n",
      "Sample 3748 - loss: 0.16114097833633423\n",
      "Sample 3749 - loss: 0.09423650801181793\n",
      "Sample 3750 - loss: 3.3384029865264893\n",
      "Sample 3751 - loss: 2.602093458175659\n",
      "Sample 3752 - loss: 4.582966327667236\n",
      "Sample 3753 - loss: 0.19123393297195435\n",
      "Sample 3754 - loss: 1.3053103685379028\n",
      "Sample 3755 - loss: 5.65308952331543\n",
      "Sample 3756 - loss: 0.41551467776298523\n",
      "Sample 3757 - loss: 6.058087348937988\n",
      "Sample 3758 - loss: 1.4110877513885498\n",
      "Sample 3759 - loss: 1.4720427989959717\n",
      "Sample 3760 - loss: 0.8651822805404663\n",
      "Sample 3761 - loss: 0.7339112758636475\n",
      "Sample 3762 - loss: 1.7706767320632935\n",
      "Sample 3763 - loss: 7.084300994873047\n",
      "Sample 3764 - loss: 0.17855535447597504\n",
      "Sample 3765 - loss: 3.0237789154052734\n",
      "Sample 3766 - loss: 0.12309235334396362\n",
      "Sample 3767 - loss: 11.146000862121582\n",
      "Sample 3768 - loss: 2.6931095123291016\n",
      "Sample 3769 - loss: 2.801720380783081\n",
      "Sample 3770 - loss: 0.2650485336780548\n",
      "Sample 3771 - loss: 1.5121537446975708\n",
      "Sample 3772 - loss: 0.2804467976093292\n",
      "Sample 3773 - loss: 8.402480125427246\n",
      "Sample 3774 - loss: 0.04143282771110535\n",
      "Sample 3775 - loss: 6.862033843994141\n",
      "Sample 3776 - loss: 0.5302466154098511\n",
      "Sample 3777 - loss: 2.7173855304718018\n",
      "Sample 3778 - loss: 5.454653739929199\n",
      "Sample 3779 - loss: 12.109723091125488\n",
      "Sample 3780 - loss: 6.178140163421631\n",
      "Sample 3781 - loss: 10.776126861572266\n",
      "Sample 3782 - loss: 3.2701632976531982\n",
      "Sample 3783 - loss: 1.7507927417755127\n",
      "Sample 3784 - loss: 0.0350540392100811\n",
      "Sample 3785 - loss: 0.4865168631076813\n",
      "Sample 3786 - loss: 9.358573913574219\n",
      "Sample 3787 - loss: 1.7731181383132935\n",
      "Sample 3788 - loss: 0.6056103706359863\n",
      "Sample 3789 - loss: 0.2948857247829437\n",
      "Sample 3790 - loss: 3.6797549724578857\n",
      "Sample 3791 - loss: 0.16223248839378357\n",
      "Sample 3792 - loss: 0.5106406211853027\n",
      "Sample 3793 - loss: 1.7426048517227173\n",
      "Sample 3794 - loss: 0.11017151921987534\n",
      "Sample 3795 - loss: 4.835883140563965\n",
      "Sample 3796 - loss: 7.248178005218506\n",
      "Sample 3797 - loss: 11.535981178283691\n",
      "Sample 3798 - loss: 1.3577167987823486\n",
      "Sample 3799 - loss: 4.764565944671631\n",
      "Sample 3800 - loss: 2.1796774864196777\n",
      "Sample 3801 - loss: 11.646788597106934\n",
      "Sample 3802 - loss: 2.6975743770599365\n",
      "Sample 3803 - loss: 7.510749340057373\n",
      "Sample 3804 - loss: 0.9699887633323669\n",
      "Sample 3805 - loss: 0.04922785237431526\n",
      "Sample 3806 - loss: 0.04572610557079315\n",
      "Sample 3807 - loss: 0.0557134672999382\n",
      "Sample 3808 - loss: 0.19172897934913635\n",
      "Sample 3809 - loss: 10.58985710144043\n",
      "Sample 3810 - loss: 1.4796044826507568\n",
      "Sample 3811 - loss: 5.145695209503174\n",
      "Sample 3812 - loss: 0.191649928689003\n",
      "Sample 3813 - loss: 8.07099723815918\n",
      "Sample 3814 - loss: 0.3642232418060303\n",
      "Sample 3815 - loss: 6.204717636108398\n",
      "Sample 3816 - loss: 4.313522815704346\n",
      "Sample 3817 - loss: 3.0083978176116943\n",
      "Sample 3818 - loss: 1.7339571714401245\n",
      "Sample 3819 - loss: 0.011731010861694813\n",
      "Sample 3820 - loss: 3.3729846477508545\n",
      "Sample 3821 - loss: 1.4762513637542725\n",
      "Sample 3822 - loss: 10.398248672485352\n",
      "Sample 3823 - loss: 4.750610828399658\n",
      "Sample 3824 - loss: 3.307920455932617\n",
      "Sample 3825 - loss: 4.052928924560547\n",
      "Sample 3826 - loss: 0.04447232559323311\n",
      "Sample 3827 - loss: 1.9442453384399414\n",
      "Sample 3828 - loss: 0.00921690370887518\n",
      "Sample 3829 - loss: 6.995502471923828\n",
      "Sample 3830 - loss: 2.098069667816162\n",
      "Sample 3831 - loss: 10.15621566772461\n",
      "Sample 3832 - loss: 6.305949687957764\n",
      "Sample 3833 - loss: 3.844763994216919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3834 - loss: 7.153131008148193\n",
      "Sample 3835 - loss: 6.535870552062988\n",
      "Sample 3836 - loss: 4.146636486053467\n",
      "Sample 3837 - loss: 3.353799343109131\n",
      "Sample 3838 - loss: 7.413211822509766\n",
      "Sample 3839 - loss: 6.216334819793701\n",
      "Sample 3840 - loss: 0.5284578204154968\n",
      "Sample 3841 - loss: 10.160179138183594\n",
      "Sample 3842 - loss: 5.785253524780273\n",
      "Sample 3843 - loss: 1.2062947750091553\n",
      "Sample 3844 - loss: 0.32505160570144653\n",
      "Sample 3845 - loss: 0.4541217088699341\n",
      "Sample 3846 - loss: 0.8187351822853088\n",
      "Sample 3847 - loss: 1.3752719163894653\n",
      "Sample 3848 - loss: 2.0726795196533203\n",
      "Sample 3849 - loss: 10.20010757446289\n",
      "Sample 3850 - loss: 0.05434080585837364\n",
      "Sample 3851 - loss: 7.303867340087891\n",
      "Sample 3852 - loss: 3.8859283924102783\n",
      "Sample 3853 - loss: 0.011275810189545155\n",
      "Sample 3854 - loss: 5.416107654571533\n",
      "Sample 3855 - loss: 2.737711191177368\n",
      "Sample 3856 - loss: 3.8250656127929688\n",
      "Sample 3857 - loss: 0.16035732626914978\n",
      "Sample 3858 - loss: 7.692571640014648\n",
      "Sample 3859 - loss: 6.659778594970703\n",
      "Sample 3860 - loss: 2.5607662200927734\n",
      "Sample 3861 - loss: 2.2026784420013428\n",
      "Sample 3862 - loss: 1.177584171295166\n",
      "Sample 3863 - loss: 4.073739528656006\n",
      "Sample 3864 - loss: 9.10908317565918\n",
      "Sample 3865 - loss: 6.884988307952881\n",
      "Sample 3866 - loss: 6.254580497741699\n",
      "Sample 3867 - loss: 8.571598052978516\n",
      "Sample 3868 - loss: 1.6137588024139404\n",
      "Sample 3869 - loss: 4.755509376525879\n",
      "Sample 3870 - loss: 2.1248726844787598\n",
      "Sample 3871 - loss: 5.051807403564453\n",
      "Sample 3872 - loss: 0.028737729415297508\n",
      "Sample 3873 - loss: 0.04235753044486046\n",
      "Sample 3874 - loss: 2.3808422088623047\n",
      "Sample 3875 - loss: 7.695148944854736\n",
      "Sample 3876 - loss: 0.3688902258872986\n",
      "Sample 3877 - loss: 0.10787983983755112\n",
      "Sample 3878 - loss: 2.4413106441497803\n",
      "Sample 3879 - loss: 0.5950602889060974\n",
      "Sample 3880 - loss: 0.4860765039920807\n",
      "Sample 3881 - loss: 1.523898720741272\n",
      "Sample 3882 - loss: 2.592411994934082\n",
      "Sample 3883 - loss: 2.08266019821167\n",
      "Sample 3884 - loss: 1.680250644683838\n",
      "Sample 3885 - loss: 2.8113045692443848\n",
      "Sample 3886 - loss: 3.195582389831543\n",
      "Sample 3887 - loss: 0.5972849130630493\n",
      "Sample 3888 - loss: 2.564377546310425\n",
      "Sample 3889 - loss: 9.935683250427246\n",
      "Sample 3890 - loss: 8.082582473754883\n",
      "Sample 3891 - loss: 6.829790115356445\n",
      "Sample 3892 - loss: 6.2845869064331055\n",
      "Sample 3893 - loss: 7.762732982635498\n",
      "Sample 3894 - loss: 0.07467272877693176\n",
      "Sample 3895 - loss: 7.680487632751465\n",
      "Sample 3896 - loss: 0.0793088972568512\n",
      "Sample 3897 - loss: 0.10126955062150955\n",
      "Sample 3898 - loss: 6.1198530197143555\n",
      "Sample 3899 - loss: 1.9055778980255127\n",
      "Sample 3900 - loss: 11.278458595275879\n",
      "Sample 3901 - loss: 11.467840194702148\n",
      "Sample 3902 - loss: 0.3382473289966583\n",
      "Sample 3903 - loss: 0.1850954294204712\n",
      "Sample 3904 - loss: 0.43354281783103943\n",
      "Sample 3905 - loss: 0.17773857712745667\n",
      "Sample 3906 - loss: 3.486847162246704\n",
      "Sample 3907 - loss: 5.565147876739502\n",
      "Sample 3908 - loss: 0.9782161712646484\n",
      "Sample 3909 - loss: 1.248814344406128\n",
      "Sample 3910 - loss: 3.252810478210449\n",
      "Sample 3911 - loss: 6.495706558227539\n",
      "Sample 3912 - loss: 0.03152879327535629\n",
      "Sample 3913 - loss: 12.828064918518066\n",
      "Sample 3914 - loss: 0.006998813711106777\n",
      "Sample 3915 - loss: 5.479276657104492\n",
      "Sample 3916 - loss: 8.79552936553955\n",
      "Sample 3917 - loss: 6.074661731719971\n",
      "Sample 3918 - loss: 3.4587161540985107\n",
      "Sample 3919 - loss: 5.63157844543457\n",
      "Sample 3920 - loss: 1.6398587226867676\n",
      "Sample 3921 - loss: 9.931341171264648\n",
      "Sample 3922 - loss: 0.5150622129440308\n",
      "Sample 3923 - loss: 1.122512936592102\n",
      "Sample 3924 - loss: 1.4561423063278198\n",
      "Sample 3925 - loss: 1.6744108200073242\n",
      "Sample 3926 - loss: 8.133537292480469\n",
      "Sample 3927 - loss: 0.2709089517593384\n",
      "Sample 3928 - loss: 0.440735399723053\n",
      "Sample 3929 - loss: 1.9877841472625732\n",
      "Sample 3930 - loss: 10.05490493774414\n",
      "Sample 3931 - loss: 8.205224990844727\n",
      "Sample 3932 - loss: 0.06657671183347702\n",
      "Sample 3933 - loss: 12.285552978515625\n",
      "Sample 3934 - loss: 3.8283517360687256\n",
      "Sample 3935 - loss: 3.180361032485962\n",
      "Sample 3936 - loss: 8.673489570617676\n",
      "Sample 3937 - loss: 5.5004167556762695\n",
      "Sample 3938 - loss: 0.14810416102409363\n",
      "Sample 3939 - loss: 6.205542087554932\n",
      "Sample 3940 - loss: 6.920444488525391\n",
      "Sample 3941 - loss: 7.828500747680664\n",
      "Sample 3942 - loss: 3.8867275714874268\n",
      "Sample 3943 - loss: 6.0349016189575195\n",
      "Sample 3944 - loss: 1.8708261251449585\n",
      "Sample 3945 - loss: 2.422863006591797\n",
      "Sample 3946 - loss: 0.6476484537124634\n",
      "Sample 3947 - loss: 2.5631465911865234\n",
      "Sample 3948 - loss: 0.18919946253299713\n",
      "Sample 3949 - loss: 7.226245880126953\n",
      "Sample 3950 - loss: 5.329664707183838\n",
      "Sample 3951 - loss: 0.0062535409815609455\n",
      "Sample 3952 - loss: 3.288776159286499\n",
      "Sample 3953 - loss: 0.5394281148910522\n",
      "Sample 3954 - loss: 8.67686653137207\n",
      "Sample 3955 - loss: 0.16049081087112427\n",
      "Sample 3956 - loss: 7.73106575012207\n",
      "Sample 3957 - loss: 7.445205211639404\n",
      "Sample 3958 - loss: 5.703253269195557\n",
      "Sample 3959 - loss: 9.964629173278809\n",
      "Sample 3960 - loss: 0.556452214717865\n",
      "Sample 3961 - loss: 11.980518341064453\n",
      "Sample 3962 - loss: 0.6652930974960327\n",
      "Sample 3963 - loss: 11.099157333374023\n",
      "Sample 3964 - loss: 10.893197059631348\n",
      "Sample 3965 - loss: 1.4784413576126099\n",
      "Sample 3966 - loss: 4.648763179779053\n",
      "Sample 3967 - loss: 0.6170770525932312\n",
      "Sample 3968 - loss: 1.7305793762207031\n",
      "Sample 3969 - loss: 0.16939082741737366\n",
      "Sample 3970 - loss: 3.0946264266967773\n",
      "Sample 3971 - loss: 12.384037017822266\n",
      "Sample 3972 - loss: 1.9934873580932617\n",
      "Sample 3973 - loss: 3.4850943088531494\n",
      "Sample 3974 - loss: 3.7300634384155273\n",
      "Sample 3975 - loss: 6.179599761962891\n",
      "Sample 3976 - loss: 0.26227322220802307\n",
      "Sample 3977 - loss: 0.6662409901618958\n",
      "Sample 3978 - loss: 1.0973769426345825\n",
      "Sample 3979 - loss: 0.6840403079986572\n",
      "Sample 3980 - loss: 8.267848014831543\n",
      "Sample 3981 - loss: 6.962081432342529\n",
      "Sample 3982 - loss: 4.870779037475586\n",
      "Sample 3983 - loss: 7.761112689971924\n",
      "Sample 3984 - loss: 0.10413443297147751\n",
      "Sample 3985 - loss: 1.3072917461395264\n",
      "Sample 3986 - loss: 7.575158596038818\n",
      "Sample 3987 - loss: 0.6869865655899048\n",
      "Sample 3988 - loss: 3.721674919128418\n",
      "Sample 3989 - loss: 5.4439849853515625\n",
      "Sample 3990 - loss: 3.818246841430664\n",
      "Sample 3991 - loss: 3.11099910736084\n",
      "Sample 3992 - loss: 0.0589190237224102\n",
      "Sample 3993 - loss: 0.25771865248680115\n",
      "Sample 3994 - loss: 3.328657627105713\n",
      "Sample 3995 - loss: 11.878514289855957\n",
      "Sample 3996 - loss: 0.05552724748849869\n",
      "Sample 3997 - loss: 2.4514472484588623\n",
      "Sample 3998 - loss: 0.18440507352352142\n",
      "Sample 3999 - loss: 1.0083106756210327\n",
      "Sample 4000 - loss: 2.6071512699127197\n",
      "Sample 4001 - loss: 7.740210056304932\n",
      "Sample 4002 - loss: 2.68327260017395\n",
      "Sample 4003 - loss: 4.160964012145996\n",
      "Sample 4004 - loss: 3.5420331954956055\n",
      "Sample 4005 - loss: 0.06808006018400192\n",
      "Sample 4006 - loss: 0.7351528406143188\n",
      "Sample 4007 - loss: 1.2768157720565796\n",
      "Sample 4008 - loss: 1.3637655973434448\n",
      "Sample 4009 - loss: 3.547128915786743\n",
      "Sample 4010 - loss: 5.5851335525512695\n",
      "Sample 4011 - loss: 1.3083884716033936\n",
      "Sample 4012 - loss: 5.439666748046875\n",
      "Sample 4013 - loss: 6.623594760894775\n",
      "Sample 4014 - loss: 4.490900039672852\n",
      "Sample 4015 - loss: 1.426224946975708\n",
      "Sample 4016 - loss: 0.8268961310386658\n",
      "Sample 4017 - loss: 4.244112968444824\n",
      "Sample 4018 - loss: 6.734464645385742\n",
      "Sample 4019 - loss: 5.918109893798828\n",
      "Sample 4020 - loss: 7.990728378295898\n",
      "Sample 4021 - loss: 0.25001201033592224\n",
      "Sample 4022 - loss: 3.4885103702545166\n",
      "Sample 4023 - loss: 0.16324712336063385\n",
      "Sample 4024 - loss: 7.46000862121582\n",
      "Sample 4025 - loss: 7.981168270111084\n",
      "Sample 4026 - loss: 1.4598069190979004\n",
      "Sample 4027 - loss: 1.6469844579696655\n",
      "Sample 4028 - loss: 6.480932712554932\n",
      "Sample 4029 - loss: 8.442874908447266\n",
      "Sample 4030 - loss: 4.0186662673950195\n",
      "Sample 4031 - loss: 8.812731742858887\n",
      "Sample 4032 - loss: 5.326551914215088\n",
      "Sample 4033 - loss: 5.431825637817383\n",
      "Sample 4034 - loss: 1.086591362953186\n",
      "Sample 4035 - loss: 0.029500456526875496\n",
      "Sample 4036 - loss: 2.0118322372436523\n",
      "Sample 4037 - loss: 7.058065414428711\n",
      "Sample 4038 - loss: 0.07814604043960571\n",
      "Sample 4039 - loss: 0.6930400729179382\n",
      "Sample 4040 - loss: 8.250062942504883\n",
      "Sample 4041 - loss: 1.7558457851409912\n",
      "Sample 4042 - loss: 5.328629970550537\n",
      "Sample 4043 - loss: 1.141310453414917\n",
      "Sample 4044 - loss: 0.26140233874320984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4045 - loss: 1.0687036514282227\n",
      "Sample 4046 - loss: 2.3035295009613037\n",
      "Sample 4047 - loss: 6.2545952796936035\n",
      "Sample 4048 - loss: 8.908413887023926\n",
      "Sample 4049 - loss: 5.166697978973389\n",
      "Sample 4050 - loss: 0.051007285714149475\n",
      "Sample 4051 - loss: 8.180925369262695\n",
      "Sample 4052 - loss: 10.111732482910156\n",
      "Sample 4053 - loss: 3.4163637161254883\n",
      "Sample 4054 - loss: 9.332098960876465\n",
      "Sample 4055 - loss: 0.27916252613067627\n",
      "Sample 4056 - loss: 1.8431525230407715\n",
      "Sample 4057 - loss: 7.812733173370361\n",
      "Sample 4058 - loss: 0.6230649948120117\n",
      "Sample 4059 - loss: 1.4117393493652344\n",
      "Sample 4060 - loss: 2.575976610183716\n",
      "Sample 4061 - loss: 3.5316171646118164\n",
      "Sample 4062 - loss: 0.004214094486087561\n",
      "Sample 4063 - loss: 6.002302169799805\n",
      "Sample 4064 - loss: 1.6506630182266235\n",
      "Sample 4065 - loss: 3.3012783527374268\n",
      "Sample 4066 - loss: 4.2468037605285645\n",
      "Sample 4067 - loss: 1.0208579301834106\n",
      "Sample 4068 - loss: 10.738338470458984\n",
      "Sample 4069 - loss: 2.312020778656006\n",
      "Sample 4070 - loss: 4.647039890289307\n",
      "Sample 4071 - loss: 3.084871530532837\n",
      "Sample 4072 - loss: 4.762487888336182\n",
      "Sample 4073 - loss: 7.452289581298828\n",
      "Sample 4074 - loss: 1.8553483486175537\n",
      "Sample 4075 - loss: 6.880704879760742\n",
      "Sample 4076 - loss: 1.1089775562286377\n",
      "Sample 4077 - loss: 2.3507721424102783\n",
      "Sample 4078 - loss: 5.930202007293701\n",
      "Sample 4079 - loss: 5.465887069702148\n",
      "Sample 4080 - loss: 2.3413033485412598\n",
      "Sample 4081 - loss: 2.4328420162200928\n",
      "Sample 4082 - loss: 0.059872373938560486\n",
      "Sample 4083 - loss: 1.7641617059707642\n",
      "Sample 4084 - loss: 4.819768905639648\n",
      "Sample 4085 - loss: 0.8969275951385498\n",
      "Sample 4086 - loss: 5.6932291984558105\n",
      "Sample 4087 - loss: 1.6568706035614014\n",
      "Sample 4088 - loss: 0.11636783927679062\n",
      "Sample 4089 - loss: 1.154923677444458\n",
      "Sample 4090 - loss: 2.0296084880828857\n",
      "Sample 4091 - loss: 1.6262412071228027\n",
      "Sample 4092 - loss: 0.12331642955541611\n",
      "Sample 4093 - loss: 4.602696895599365\n",
      "Sample 4094 - loss: 0.1806715726852417\n",
      "Sample 4095 - loss: 7.517526149749756\n",
      "Sample 4096 - loss: 0.4902992248535156\n",
      "Sample 4097 - loss: 7.728672027587891\n",
      "Sample 4098 - loss: 0.7943179607391357\n",
      "Sample 4099 - loss: 9.002348899841309\n",
      "Sample 4100 - loss: 1.3622938394546509\n",
      "Sample 4101 - loss: 8.169612884521484\n",
      "Sample 4102 - loss: 0.1309305727481842\n",
      "Sample 4103 - loss: 7.354792594909668\n",
      "Sample 4104 - loss: 10.515350341796875\n",
      "Sample 4105 - loss: 3.408085584640503\n",
      "Sample 4106 - loss: 6.757557392120361\n",
      "Sample 4107 - loss: 1.930415391921997\n",
      "Sample 4108 - loss: 8.053756713867188\n",
      "Sample 4109 - loss: 2.1044888496398926\n",
      "Sample 4110 - loss: 7.001246929168701\n",
      "Sample 4111 - loss: 0.9029366374015808\n",
      "Sample 4112 - loss: 9.208194732666016\n",
      "Sample 4113 - loss: 2.5401651859283447\n",
      "Sample 4114 - loss: 1.3188209533691406\n",
      "Sample 4115 - loss: 4.570489883422852\n",
      "Sample 4116 - loss: 0.6770790219306946\n",
      "Sample 4117 - loss: 6.628811836242676\n",
      "Sample 4118 - loss: 4.975123405456543\n",
      "Sample 4119 - loss: 4.591461658477783\n",
      "Sample 4120 - loss: 2.525925874710083\n",
      "Sample 4121 - loss: 0.03284413367509842\n",
      "Sample 4122 - loss: 0.7574070692062378\n",
      "Sample 4123 - loss: 4.165153980255127\n",
      "Sample 4124 - loss: 0.25945863127708435\n",
      "Sample 4125 - loss: 8.095887184143066\n",
      "Sample 4126 - loss: 0.7692931890487671\n",
      "Sample 4127 - loss: 2.3344216346740723\n",
      "Sample 4128 - loss: 0.18301372230052948\n",
      "Sample 4129 - loss: 6.964954376220703\n",
      "Sample 4130 - loss: 0.3269168734550476\n",
      "Sample 4131 - loss: 1.0916831493377686\n",
      "Sample 4132 - loss: 7.97465705871582\n",
      "Sample 4133 - loss: 5.654949188232422\n",
      "Sample 4134 - loss: 9.900280952453613\n",
      "Sample 4135 - loss: 8.44330883026123\n",
      "Sample 4136 - loss: 5.120987415313721\n",
      "Sample 4137 - loss: 1.758579969406128\n",
      "Sample 4138 - loss: 8.410131454467773\n",
      "Sample 4139 - loss: 0.04776061698794365\n",
      "Sample 4140 - loss: 2.187130928039551\n",
      "Sample 4141 - loss: 6.041985034942627\n",
      "Sample 4142 - loss: 1.3873745203018188\n",
      "Sample 4143 - loss: 0.5885570049285889\n",
      "Sample 4144 - loss: 10.012434959411621\n",
      "Sample 4145 - loss: 4.493646621704102\n",
      "Sample 4146 - loss: 3.390723466873169\n",
      "Sample 4147 - loss: 5.8613786697387695\n",
      "Sample 4148 - loss: 3.2229061126708984\n",
      "Sample 4149 - loss: 4.492071628570557\n",
      "Sample 4150 - loss: 7.130360126495361\n",
      "Sample 4151 - loss: 1.722273588180542\n",
      "Sample 4152 - loss: 9.674073219299316\n",
      "Sample 4153 - loss: 1.2068049907684326\n",
      "Sample 4154 - loss: 7.5646538734436035\n",
      "Sample 4155 - loss: 0.8612156510353088\n",
      "Sample 4156 - loss: 9.759553909301758\n",
      "Sample 4157 - loss: 1.6075413227081299\n",
      "Sample 4158 - loss: 0.29112496972084045\n",
      "Sample 4159 - loss: 3.739928960800171\n",
      "Sample 4160 - loss: 4.107833385467529\n",
      "Sample 4161 - loss: 1.8084722757339478\n",
      "Sample 4162 - loss: 6.8735761642456055\n",
      "Sample 4163 - loss: 0.07492124289274216\n",
      "Sample 4164 - loss: 4.998073577880859\n",
      "Sample 4165 - loss: 6.90615177154541\n",
      "Sample 4166 - loss: 0.9635342955589294\n",
      "Sample 4167 - loss: 8.379648208618164\n",
      "Sample 4168 - loss: 7.102758407592773\n",
      "Sample 4169 - loss: 0.33299171924591064\n",
      "Sample 4170 - loss: 3.8718008995056152\n",
      "Sample 4171 - loss: 1.6045559644699097\n",
      "Sample 4172 - loss: 3.066336154937744\n",
      "Sample 4173 - loss: 9.994551658630371\n",
      "Sample 4174 - loss: 1.3333631753921509\n",
      "Sample 4175 - loss: 1.9703019857406616\n",
      "Sample 4176 - loss: 0.9723085165023804\n",
      "Sample 4177 - loss: 0.4097679555416107\n",
      "Sample 4178 - loss: 3.0375478267669678\n",
      "Sample 4179 - loss: 8.828426361083984\n",
      "Sample 4180 - loss: 0.9970197081565857\n",
      "Sample 4181 - loss: 0.16454562544822693\n",
      "Sample 4182 - loss: 4.607675552368164\n",
      "Sample 4183 - loss: 0.256114661693573\n",
      "Sample 4184 - loss: 0.08259744942188263\n",
      "Sample 4185 - loss: 0.04626152664422989\n",
      "Sample 4186 - loss: 0.4140147864818573\n",
      "Sample 4187 - loss: 6.5477166175842285\n",
      "Sample 4188 - loss: 5.4008965492248535\n",
      "Sample 4189 - loss: 1.8015971183776855\n",
      "Sample 4190 - loss: 9.183233261108398\n",
      "Sample 4191 - loss: 3.94758677482605\n",
      "Sample 4192 - loss: 6.625235080718994\n",
      "Sample 4193 - loss: 9.446547508239746\n",
      "Sample 4194 - loss: 0.8143600225448608\n",
      "Sample 4195 - loss: 0.06660594046115875\n",
      "Sample 4196 - loss: 0.03139634057879448\n",
      "Sample 4197 - loss: 9.74215316772461\n",
      "Sample 4198 - loss: 6.7605977058410645\n",
      "Sample 4199 - loss: 6.9172563552856445\n",
      "Sample 4200 - loss: 8.665822982788086\n",
      "Sample 4201 - loss: 0.692718505859375\n",
      "Sample 4202 - loss: 5.1058268547058105\n",
      "Sample 4203 - loss: 3.108227252960205\n",
      "Sample 4204 - loss: 0.43375611305236816\n",
      "Sample 4205 - loss: 0.9700341820716858\n",
      "Sample 4206 - loss: 0.05606449767947197\n",
      "Sample 4207 - loss: 1.7407350540161133\n",
      "Sample 4208 - loss: 2.9740614891052246\n",
      "Sample 4209 - loss: 9.5230073928833\n",
      "Sample 4210 - loss: 0.6740664839744568\n",
      "Sample 4211 - loss: 4.830036163330078\n",
      "Sample 4212 - loss: 5.564587593078613\n",
      "Sample 4213 - loss: 9.34280776977539\n",
      "Sample 4214 - loss: 3.7993927001953125\n",
      "Sample 4215 - loss: 2.3949670791625977\n",
      "Sample 4216 - loss: 5.1889543533325195\n",
      "Sample 4217 - loss: 5.703184604644775\n",
      "Sample 4218 - loss: 2.8335297107696533\n",
      "Sample 4219 - loss: 1.427980661392212\n",
      "Sample 4220 - loss: 5.7603044509887695\n",
      "Sample 4221 - loss: 0.20302556455135345\n",
      "Sample 4222 - loss: 0.594572901725769\n",
      "Sample 4223 - loss: 3.4372875690460205\n",
      "Sample 4224 - loss: 0.45468249917030334\n",
      "Sample 4225 - loss: 1.397999882698059\n",
      "Sample 4226 - loss: 6.760034561157227\n",
      "Sample 4227 - loss: 9.478414535522461\n",
      "Sample 4228 - loss: 0.12032096832990646\n",
      "Sample 4229 - loss: 3.6828322410583496\n",
      "Sample 4230 - loss: 2.286825656890869\n",
      "Sample 4231 - loss: 1.4171797037124634\n",
      "Sample 4232 - loss: 12.04247760772705\n",
      "Sample 4233 - loss: 0.9193825721740723\n",
      "Sample 4234 - loss: 3.158404588699341\n",
      "Sample 4235 - loss: 0.8568964600563049\n",
      "Sample 4236 - loss: 1.007454752922058\n",
      "Sample 4237 - loss: 1.1764200925827026\n",
      "Sample 4238 - loss: 0.8032793402671814\n",
      "Sample 4239 - loss: 7.476938247680664\n",
      "Sample 4240 - loss: 10.052026748657227\n",
      "Sample 4241 - loss: 5.332083225250244\n",
      "Sample 4242 - loss: 4.185396194458008\n",
      "Sample 4243 - loss: 2.1640970706939697\n",
      "Sample 4244 - loss: 6.794858455657959\n",
      "Sample 4245 - loss: 6.787262439727783\n",
      "Sample 4246 - loss: 7.797908782958984\n",
      "Sample 4247 - loss: 1.5755854845046997\n",
      "Sample 4248 - loss: 8.136183738708496\n",
      "Sample 4249 - loss: 0.016317401081323624\n",
      "Sample 4250 - loss: 11.307331085205078\n",
      "Sample 4251 - loss: 0.5999588966369629\n",
      "Sample 4252 - loss: 0.5481290817260742\n",
      "Sample 4253 - loss: 2.3254456520080566\n",
      "Sample 4254 - loss: 0.9217780828475952\n",
      "Sample 4255 - loss: 6.656156063079834\n",
      "Sample 4256 - loss: 4.265712261199951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4257 - loss: 6.7459588050842285\n",
      "Sample 4258 - loss: 0.1206272542476654\n",
      "Sample 4259 - loss: 2.7022805213928223\n",
      "Sample 4260 - loss: 0.5254570245742798\n",
      "Sample 4261 - loss: 1.4586354494094849\n",
      "Sample 4262 - loss: 1.5905463695526123\n",
      "Sample 4263 - loss: 2.4355368614196777\n",
      "Sample 4264 - loss: 12.190150260925293\n",
      "Sample 4265 - loss: 8.787059783935547\n",
      "Sample 4266 - loss: 3.856740951538086\n",
      "Sample 4267 - loss: 4.7934160232543945\n",
      "Sample 4268 - loss: 0.1358686089515686\n",
      "Sample 4269 - loss: 7.879392623901367\n",
      "Sample 4270 - loss: 4.837490558624268\n",
      "Sample 4271 - loss: 6.985787391662598\n",
      "Sample 4272 - loss: 0.3430827260017395\n",
      "Sample 4273 - loss: 7.112232208251953\n",
      "Sample 4274 - loss: 6.755774021148682\n",
      "Sample 4275 - loss: 9.304899215698242\n",
      "Sample 4276 - loss: 8.200469017028809\n",
      "Sample 4277 - loss: 2.4986438751220703\n",
      "Sample 4278 - loss: 3.1388604640960693\n",
      "Sample 4279 - loss: 4.804966926574707\n",
      "Sample 4280 - loss: 10.428911209106445\n",
      "Sample 4281 - loss: 2.516693353652954\n",
      "Sample 4282 - loss: 3.448930263519287\n",
      "Sample 4283 - loss: 0.5421745777130127\n",
      "Sample 4284 - loss: 1.9981786012649536\n",
      "Sample 4285 - loss: 2.414095878601074\n",
      "Sample 4286 - loss: 1.910556435585022\n",
      "Sample 4287 - loss: 0.36795443296432495\n",
      "Sample 4288 - loss: 1.1460928916931152\n",
      "Sample 4289 - loss: 5.1932573318481445\n",
      "Sample 4290 - loss: 6.752636909484863\n",
      "Sample 4291 - loss: 0.20658157765865326\n",
      "Sample 4292 - loss: 3.041987895965576\n",
      "Sample 4293 - loss: 4.337335586547852\n",
      "Sample 4294 - loss: 2.046811819076538\n",
      "Sample 4295 - loss: 9.132356643676758\n",
      "Sample 4296 - loss: 3.128363847732544\n",
      "Sample 4297 - loss: 1.4031256437301636\n",
      "Sample 4298 - loss: 3.0013227462768555\n",
      "Sample 4299 - loss: 1.4172569513320923\n",
      "Sample 4300 - loss: 0.3428799510002136\n",
      "Sample 4301 - loss: 2.5319809913635254\n",
      "Sample 4302 - loss: 8.915268898010254\n",
      "Sample 4303 - loss: 1.8452110290527344\n",
      "Sample 4304 - loss: 0.4854184687137604\n",
      "Sample 4305 - loss: 8.679793357849121\n",
      "Sample 4306 - loss: 2.299309730529785\n",
      "Sample 4307 - loss: 0.13535138964653015\n",
      "Sample 4308 - loss: 5.202810287475586\n",
      "Sample 4309 - loss: 6.354884624481201\n",
      "Sample 4310 - loss: 8.090483665466309\n",
      "Sample 4311 - loss: 4.05333137512207\n",
      "Sample 4312 - loss: 4.318857192993164\n",
      "Sample 4313 - loss: 8.694778442382812\n",
      "Sample 4314 - loss: 2.5591840744018555\n",
      "Sample 4315 - loss: 4.96089506149292\n",
      "Sample 4316 - loss: 4.314460277557373\n",
      "Sample 4317 - loss: 1.1135506629943848\n",
      "Sample 4318 - loss: 9.428267478942871\n",
      "Sample 4319 - loss: 0.08900678902864456\n",
      "Sample 4320 - loss: 3.847620964050293\n",
      "Sample 4321 - loss: 7.063216686248779\n",
      "Sample 4322 - loss: 8.519274711608887\n",
      "Sample 4323 - loss: 0.44595420360565186\n",
      "Sample 4324 - loss: 0.07434223592281342\n",
      "Sample 4325 - loss: 5.935239315032959\n",
      "Sample 4326 - loss: 8.728141784667969\n",
      "Sample 4327 - loss: 1.166335105895996\n",
      "Sample 4328 - loss: 1.095252275466919\n",
      "Sample 4329 - loss: 10.134100914001465\n",
      "Sample 4330 - loss: 1.5553797483444214\n",
      "Sample 4331 - loss: 9.727169036865234\n",
      "Sample 4332 - loss: 3.4871129989624023\n",
      "Sample 4333 - loss: 0.6753697991371155\n",
      "Sample 4334 - loss: 9.553567886352539\n",
      "Sample 4335 - loss: 0.20090541243553162\n",
      "Sample 4336 - loss: 0.5444859862327576\n",
      "Sample 4337 - loss: 3.4601171016693115\n",
      "Sample 4338 - loss: 8.075899124145508\n",
      "Sample 4339 - loss: 6.6477813720703125\n",
      "Sample 4340 - loss: 0.0415620431303978\n",
      "Sample 4341 - loss: 1.910280466079712\n",
      "Sample 4342 - loss: 3.265432357788086\n",
      "Sample 4343 - loss: 7.416600227355957\n",
      "Sample 4344 - loss: 0.14168572425842285\n",
      "Sample 4345 - loss: 6.508971691131592\n",
      "Sample 4346 - loss: 1.4144482612609863\n",
      "Sample 4347 - loss: 3.3615493774414062\n",
      "Sample 4348 - loss: 1.7279996871948242\n",
      "Sample 4349 - loss: 9.54031753540039\n",
      "Sample 4350 - loss: 2.4469730854034424\n",
      "Sample 4351 - loss: 4.715939044952393\n",
      "Sample 4352 - loss: 0.10546690970659256\n",
      "Sample 4353 - loss: 2.617401123046875\n",
      "Sample 4354 - loss: 0.07968230545520782\n",
      "Sample 4355 - loss: 1.3087129592895508\n",
      "Sample 4356 - loss: 6.2388014793396\n",
      "Sample 4357 - loss: 4.320492744445801\n",
      "Sample 4358 - loss: 6.5931925773620605\n",
      "Sample 4359 - loss: 2.6621925830841064\n",
      "Sample 4360 - loss: 0.7254616618156433\n",
      "Sample 4361 - loss: 4.114506721496582\n",
      "Sample 4362 - loss: 0.020827023312449455\n",
      "Sample 4363 - loss: 6.851728439331055\n",
      "Sample 4364 - loss: 3.7700302600860596\n",
      "Sample 4365 - loss: 0.08915714174509048\n",
      "Sample 4366 - loss: 0.09056861698627472\n",
      "Sample 4367 - loss: 0.06166433170437813\n",
      "Sample 4368 - loss: 9.073816299438477\n",
      "Sample 4369 - loss: 1.0928359031677246\n",
      "Sample 4370 - loss: 0.2071584314107895\n",
      "Sample 4371 - loss: 4.422407627105713\n",
      "Sample 4372 - loss: 3.196429967880249\n",
      "Sample 4373 - loss: 0.5983057618141174\n",
      "Sample 4374 - loss: 3.8442249298095703\n",
      "Sample 4375 - loss: 8.524264335632324\n",
      "Sample 4376 - loss: 3.9106345176696777\n",
      "Sample 4377 - loss: 7.66800594329834\n",
      "Sample 4378 - loss: 0.41384637355804443\n",
      "Sample 4379 - loss: 0.24870260059833527\n",
      "Sample 4380 - loss: 3.666801691055298\n",
      "Sample 4381 - loss: 6.784055233001709\n",
      "Sample 4382 - loss: 1.7915743589401245\n",
      "Sample 4383 - loss: 0.6715330481529236\n",
      "Sample 4384 - loss: 0.9601119756698608\n",
      "Sample 4385 - loss: 1.0038957595825195\n",
      "Sample 4386 - loss: 0.01416579820215702\n",
      "Sample 4387 - loss: 7.704644680023193\n",
      "Sample 4388 - loss: 6.909787178039551\n",
      "Sample 4389 - loss: 7.135970592498779\n",
      "Sample 4390 - loss: 0.4052727222442627\n",
      "Sample 4391 - loss: 0.7975502014160156\n",
      "Sample 4392 - loss: 6.713998794555664\n",
      "Sample 4393 - loss: 0.326875239610672\n",
      "Sample 4394 - loss: 0.2560022175312042\n",
      "Sample 4395 - loss: 0.09540354460477829\n",
      "Sample 4396 - loss: 0.1642404943704605\n",
      "Sample 4397 - loss: 0.026585347950458527\n",
      "Sample 4398 - loss: 5.8692145347595215\n",
      "Sample 4399 - loss: 0.8494927883148193\n",
      "Sample 4400 - loss: 0.2574501931667328\n",
      "Sample 4401 - loss: 6.1980061531066895\n",
      "Sample 4402 - loss: 0.03456898778676987\n",
      "Sample 4403 - loss: 5.358548164367676\n",
      "Sample 4404 - loss: 4.966904163360596\n",
      "Sample 4405 - loss: 4.899111747741699\n",
      "Sample 4406 - loss: 6.121945858001709\n",
      "Sample 4407 - loss: 6.908143997192383\n",
      "Sample 4408 - loss: 3.4538228511810303\n",
      "Sample 4409 - loss: 7.502382755279541\n",
      "Sample 4410 - loss: 0.7647010087966919\n",
      "Sample 4411 - loss: 0.015978075563907623\n",
      "Sample 4412 - loss: 0.4500047266483307\n",
      "Sample 4413 - loss: 6.122217178344727\n",
      "Sample 4414 - loss: 9.043539047241211\n",
      "Sample 4415 - loss: 1.5820956230163574\n",
      "Sample 4416 - loss: 2.9181504249572754\n",
      "Sample 4417 - loss: 1.0338801145553589\n",
      "Sample 4418 - loss: 1.3278671503067017\n",
      "Sample 4419 - loss: 0.5757319331169128\n",
      "Sample 4420 - loss: 1.966609239578247\n",
      "Sample 4421 - loss: 7.818151950836182\n",
      "Sample 4422 - loss: 1.4558645486831665\n",
      "Sample 4423 - loss: 6.6923933029174805\n",
      "Sample 4424 - loss: 1.7547944784164429\n",
      "Sample 4425 - loss: 8.47038745880127\n",
      "Sample 4426 - loss: 0.2366020828485489\n",
      "Sample 4427 - loss: 3.120143413543701\n",
      "Sample 4428 - loss: 3.097792863845825\n",
      "Sample 4429 - loss: 9.312629699707031\n",
      "Sample 4430 - loss: 2.223597764968872\n",
      "Sample 4431 - loss: 0.0746394470334053\n",
      "Sample 4432 - loss: 1.4167572259902954\n",
      "Sample 4433 - loss: 3.1940033435821533\n",
      "Sample 4434 - loss: 3.2101833820343018\n",
      "Sample 4435 - loss: 1.109806776046753\n",
      "Sample 4436 - loss: 0.32795006036758423\n",
      "Sample 4437 - loss: 9.601358413696289\n",
      "Sample 4438 - loss: 1.916285753250122\n",
      "Sample 4439 - loss: 0.7126858234405518\n",
      "Sample 4440 - loss: 9.07844352722168\n",
      "Sample 4441 - loss: 8.682890892028809\n",
      "Sample 4442 - loss: 4.675649642944336\n",
      "Sample 4443 - loss: 1.1619151830673218\n",
      "Sample 4444 - loss: 7.2021894454956055\n",
      "Sample 4445 - loss: 2.754929304122925\n",
      "Sample 4446 - loss: 3.901965856552124\n",
      "Sample 4447 - loss: 0.039654411375522614\n",
      "Sample 4448 - loss: 5.2521491050720215\n",
      "Sample 4449 - loss: 0.43503886461257935\n",
      "Sample 4450 - loss: 1.600527048110962\n",
      "Sample 4451 - loss: 4.334970474243164\n",
      "Sample 4452 - loss: 11.732976913452148\n",
      "Sample 4453 - loss: 2.626277208328247\n",
      "Sample 4454 - loss: 1.7027500867843628\n",
      "Sample 4455 - loss: 1.8157538175582886\n",
      "Sample 4456 - loss: 6.43714714050293\n",
      "Sample 4457 - loss: 4.946539402008057\n",
      "Sample 4458 - loss: 2.31898832321167\n",
      "Sample 4459 - loss: 3.4546074867248535\n",
      "Sample 4460 - loss: 6.384293079376221\n",
      "Sample 4461 - loss: 6.819086074829102\n",
      "Sample 4462 - loss: 2.009589195251465\n",
      "Sample 4463 - loss: 5.667823314666748\n",
      "Sample 4464 - loss: 0.12197314202785492\n",
      "Sample 4465 - loss: 7.810697078704834\n",
      "Sample 4466 - loss: 11.597390174865723\n",
      "Sample 4467 - loss: 3.0642473697662354\n",
      "Sample 4468 - loss: 8.260383605957031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4469 - loss: 8.591131210327148\n",
      "Sample 4470 - loss: 3.1733603477478027\n",
      "Sample 4471 - loss: 1.9705047607421875\n",
      "Sample 4472 - loss: 1.805019497871399\n",
      "Sample 4473 - loss: 3.0387766361236572\n",
      "Sample 4474 - loss: 3.6187212467193604\n",
      "Sample 4475 - loss: 5.472872734069824\n",
      "Sample 4476 - loss: 1.3364681005477905\n",
      "Sample 4477 - loss: 5.124298095703125\n",
      "Sample 4478 - loss: 3.9620308876037598\n",
      "Sample 4479 - loss: 6.970833778381348\n",
      "Sample 4480 - loss: 6.897891998291016\n",
      "Sample 4481 - loss: 10.954527854919434\n",
      "Sample 4482 - loss: 0.20973622798919678\n",
      "Sample 4483 - loss: 3.9302971363067627\n",
      "Sample 4484 - loss: 0.33638301491737366\n",
      "Sample 4485 - loss: 4.084356307983398\n",
      "Sample 4486 - loss: 1.5752676725387573\n",
      "Sample 4487 - loss: 1.2354702949523926\n",
      "Sample 4488 - loss: 7.284114837646484\n",
      "Sample 4489 - loss: 1.9619698524475098\n",
      "Sample 4490 - loss: 6.573225498199463\n",
      "Sample 4491 - loss: 0.07977414131164551\n",
      "Sample 4492 - loss: 9.391361236572266\n",
      "Sample 4493 - loss: 1.8608012199401855\n",
      "Sample 4494 - loss: 0.6255764961242676\n",
      "Sample 4495 - loss: 3.079080104827881\n",
      "Sample 4496 - loss: 0.04127015545964241\n",
      "Sample 4497 - loss: 5.3484368324279785\n",
      "Sample 4498 - loss: 5.2418107986450195\n",
      "Sample 4499 - loss: 0.02113323286175728\n",
      "Sample 4500 - loss: 6.284627914428711\n",
      "Sample 4501 - loss: 3.6309587955474854\n",
      "Sample 4502 - loss: 1.0645884275436401\n",
      "Sample 4503 - loss: 2.868112802505493\n",
      "Sample 4504 - loss: 1.1771236658096313\n",
      "Sample 4505 - loss: 1.1271624565124512\n",
      "Sample 4506 - loss: 6.185743808746338\n",
      "Sample 4507 - loss: 0.8980998396873474\n",
      "Sample 4508 - loss: 4.406694412231445\n",
      "Sample 4509 - loss: 1.9612065553665161\n",
      "Sample 4510 - loss: 5.433739185333252\n",
      "Sample 4511 - loss: 0.10888522863388062\n",
      "Sample 4512 - loss: 4.919097423553467\n",
      "Sample 4513 - loss: 3.2691237926483154\n",
      "Sample 4514 - loss: 5.717459678649902\n",
      "Sample 4515 - loss: 0.6622804403305054\n",
      "Sample 4516 - loss: 7.300447940826416\n",
      "Sample 4517 - loss: 1.7695635557174683\n",
      "Sample 4518 - loss: 0.35003048181533813\n",
      "Sample 4519 - loss: 10.000089645385742\n",
      "Sample 4520 - loss: 2.6360366344451904\n",
      "Sample 4521 - loss: 7.439640522003174\n",
      "Sample 4522 - loss: 0.09236279129981995\n",
      "Sample 4523 - loss: 5.081449508666992\n",
      "Sample 4524 - loss: 1.9917137622833252\n",
      "Sample 4525 - loss: 0.07459813356399536\n",
      "Sample 4526 - loss: 1.1523289680480957\n",
      "Sample 4527 - loss: 4.175579071044922\n",
      "Sample 4528 - loss: 0.25082290172576904\n",
      "Sample 4529 - loss: 3.284377336502075\n",
      "Sample 4530 - loss: 3.687446355819702\n",
      "Sample 4531 - loss: 9.864583969116211\n",
      "Sample 4532 - loss: 10.939631462097168\n",
      "Sample 4533 - loss: 7.710702896118164\n",
      "Sample 4534 - loss: 8.737335205078125\n",
      "Sample 4535 - loss: 0.966594398021698\n",
      "Sample 4536 - loss: 9.878096580505371\n",
      "Sample 4537 - loss: 1.2812634706497192\n",
      "Sample 4538 - loss: 2.1383891105651855\n",
      "Sample 4539 - loss: 4.310161590576172\n",
      "Sample 4540 - loss: 4.636472702026367\n",
      "Sample 4541 - loss: 7.44607400894165\n",
      "Sample 4542 - loss: 1.2400941848754883\n",
      "Sample 4543 - loss: 4.403459548950195\n",
      "Sample 4544 - loss: 2.379244327545166\n",
      "Sample 4545 - loss: 4.617610454559326\n",
      "Sample 4546 - loss: 5.4202985763549805\n",
      "Sample 4547 - loss: 3.001598834991455\n",
      "Sample 4548 - loss: 0.5453729033470154\n",
      "Sample 4549 - loss: 0.23744139075279236\n",
      "Sample 4550 - loss: 0.6909677982330322\n",
      "Sample 4551 - loss: 10.837201118469238\n",
      "Sample 4552 - loss: 5.268576145172119\n",
      "Sample 4553 - loss: 2.7620813846588135\n",
      "Sample 4554 - loss: 9.984634399414062\n",
      "Sample 4555 - loss: 0.17443722486495972\n",
      "Sample 4556 - loss: 0.12547844648361206\n",
      "Sample 4557 - loss: 0.10595563054084778\n",
      "Sample 4558 - loss: 2.155149459838867\n",
      "Sample 4559 - loss: 5.963897705078125\n",
      "Sample 4560 - loss: 3.317213535308838\n",
      "Sample 4561 - loss: 1.2489556074142456\n",
      "Sample 4562 - loss: 4.11808967590332\n",
      "Sample 4563 - loss: 5.135397434234619\n",
      "Sample 4564 - loss: 0.10449975728988647\n",
      "Sample 4565 - loss: 3.561199903488159\n",
      "Sample 4566 - loss: 4.242417812347412\n",
      "Sample 4567 - loss: 4.892104625701904\n",
      "Sample 4568 - loss: 5.215826511383057\n",
      "Sample 4569 - loss: 2.9651782512664795\n",
      "Sample 4570 - loss: 5.7024993896484375\n",
      "Sample 4571 - loss: 5.228962421417236\n",
      "Sample 4572 - loss: 1.155722975730896\n",
      "Sample 4573 - loss: 7.393336772918701\n",
      "Sample 4574 - loss: 2.380554437637329\n",
      "Sample 4575 - loss: 5.414394378662109\n",
      "Sample 4576 - loss: 8.719657897949219\n",
      "Sample 4577 - loss: 1.6088618040084839\n",
      "Sample 4578 - loss: 1.9189740419387817\n",
      "Sample 4579 - loss: 5.659852981567383\n",
      "Sample 4580 - loss: 1.7218165397644043\n",
      "Sample 4581 - loss: 3.791593313217163\n",
      "Sample 4582 - loss: 0.23179036378860474\n",
      "Sample 4583 - loss: 0.0956980288028717\n",
      "Sample 4584 - loss: 4.9503374099731445\n",
      "Sample 4585 - loss: 3.5458450317382812\n",
      "Sample 4586 - loss: 1.21840500831604\n",
      "Sample 4587 - loss: 3.3145525455474854\n",
      "Sample 4588 - loss: 3.236544132232666\n",
      "Sample 4589 - loss: 10.16591739654541\n",
      "Sample 4590 - loss: 0.591498851776123\n",
      "Sample 4591 - loss: 5.633871555328369\n",
      "Sample 4592 - loss: 1.1942944526672363\n",
      "Sample 4593 - loss: 2.4361140727996826\n",
      "Sample 4594 - loss: 1.0313899517059326\n",
      "Sample 4595 - loss: 7.182616710662842\n",
      "Sample 4596 - loss: 0.040960680693387985\n",
      "Sample 4597 - loss: 8.573945045471191\n",
      "Sample 4598 - loss: 6.954046249389648\n",
      "Sample 4599 - loss: 1.4145865440368652\n",
      "Sample 4600 - loss: 7.43171501159668\n",
      "Sample 4601 - loss: 4.132059097290039\n",
      "Sample 4602 - loss: 6.416922092437744\n",
      "Sample 4603 - loss: 0.17580190300941467\n",
      "Sample 4604 - loss: 0.1816844344139099\n",
      "Sample 4605 - loss: 3.597963333129883\n",
      "Sample 4606 - loss: 4.948923110961914\n",
      "Sample 4607 - loss: 8.704513549804688\n",
      "Sample 4608 - loss: 6.4115986824035645\n",
      "Sample 4609 - loss: 0.6636642217636108\n",
      "Sample 4610 - loss: 5.5404205322265625\n",
      "Sample 4611 - loss: 7.4188432693481445\n",
      "Sample 4612 - loss: 11.108925819396973\n",
      "Sample 4613 - loss: 9.878853797912598\n",
      "Sample 4614 - loss: 0.05532775819301605\n",
      "Sample 4615 - loss: 2.4793038368225098\n",
      "Sample 4616 - loss: 0.10285058617591858\n",
      "Sample 4617 - loss: 2.7445547580718994\n",
      "Sample 4618 - loss: 2.4062659740448\n",
      "Sample 4619 - loss: 2.2855896949768066\n",
      "Sample 4620 - loss: 0.003427340416237712\n",
      "Sample 4621 - loss: 4.599499702453613\n",
      "Sample 4622 - loss: 2.6839821338653564\n",
      "Sample 4623 - loss: 0.1445574164390564\n",
      "Sample 4624 - loss: 0.32609015703201294\n",
      "Sample 4625 - loss: 0.0344916433095932\n",
      "Sample 4626 - loss: 8.382049560546875\n",
      "Sample 4627 - loss: 1.7954298257827759\n",
      "Sample 4628 - loss: 0.17920750379562378\n",
      "Sample 4629 - loss: 2.348068952560425\n",
      "Sample 4630 - loss: 4.706035137176514\n",
      "Sample 4631 - loss: 6.623219013214111\n",
      "Sample 4632 - loss: 1.358054518699646\n",
      "Sample 4633 - loss: 3.115285634994507\n",
      "Sample 4634 - loss: 0.05469297990202904\n",
      "Sample 4635 - loss: 0.17249184846878052\n",
      "Sample 4636 - loss: 6.005471706390381\n",
      "Sample 4637 - loss: 6.7938551902771\n",
      "Sample 4638 - loss: 1.6533032655715942\n",
      "Sample 4639 - loss: 3.5729055404663086\n",
      "Sample 4640 - loss: 0.5877464413642883\n",
      "Sample 4641 - loss: 5.319464683532715\n",
      "Sample 4642 - loss: 2.416151285171509\n",
      "Sample 4643 - loss: 0.9541170597076416\n",
      "Sample 4644 - loss: 0.9850354194641113\n",
      "Sample 4645 - loss: 8.391119003295898\n",
      "Sample 4646 - loss: 2.7018258571624756\n",
      "Sample 4647 - loss: 7.750092029571533\n",
      "Sample 4648 - loss: 6.852229595184326\n",
      "Sample 4649 - loss: 0.11857139319181442\n",
      "Sample 4650 - loss: 0.0457112081348896\n",
      "Sample 4651 - loss: 3.34237003326416\n",
      "Sample 4652 - loss: 1.1749380826950073\n",
      "Sample 4653 - loss: 1.8415156602859497\n",
      "Sample 4654 - loss: 2.8358588218688965\n",
      "Sample 4655 - loss: 5.924383640289307\n",
      "Sample 4656 - loss: 8.333000183105469\n",
      "Sample 4657 - loss: 0.23653976619243622\n",
      "Sample 4658 - loss: 0.15157632529735565\n",
      "Sample 4659 - loss: 0.3549237549304962\n",
      "Sample 4660 - loss: 5.854520320892334\n",
      "Sample 4661 - loss: 3.506634473800659\n",
      "Sample 4662 - loss: 6.518496513366699\n",
      "Sample 4663 - loss: 0.6229590177536011\n",
      "Sample 4664 - loss: 6.65786600112915\n",
      "Sample 4665 - loss: 0.3647063076496124\n",
      "Sample 4666 - loss: 11.978750228881836\n",
      "Sample 4667 - loss: 0.041176687926054\n",
      "Sample 4668 - loss: 5.648311138153076\n",
      "Sample 4669 - loss: 9.440187454223633\n",
      "Sample 4670 - loss: 11.24991226196289\n",
      "Sample 4671 - loss: 0.2097497433423996\n",
      "Sample 4672 - loss: 6.6113786697387695\n",
      "Sample 4673 - loss: 6.413568496704102\n",
      "Sample 4674 - loss: 6.745506763458252\n",
      "Sample 4675 - loss: 12.975298881530762\n",
      "Sample 4676 - loss: 1.0520633459091187\n",
      "Sample 4677 - loss: 1.299412727355957\n",
      "Sample 4678 - loss: 0.050320059061050415\n",
      "Sample 4679 - loss: 7.444677352905273\n",
      "Sample 4680 - loss: 11.487238883972168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4681 - loss: 1.0324751138687134\n",
      "Sample 4682 - loss: 11.994906425476074\n",
      "Sample 4683 - loss: 5.603574275970459\n",
      "Sample 4684 - loss: 2.6805810928344727\n",
      "Sample 4685 - loss: 4.386209011077881\n",
      "Sample 4686 - loss: 6.880972385406494\n",
      "Sample 4687 - loss: 1.9247384071350098\n",
      "Sample 4688 - loss: 0.27281367778778076\n",
      "Sample 4689 - loss: 3.7550971508026123\n",
      "Sample 4690 - loss: 0.3070908188819885\n",
      "Sample 4691 - loss: 3.741748094558716\n",
      "Sample 4692 - loss: 0.02123847045004368\n",
      "Sample 4693 - loss: 5.604673862457275\n",
      "Sample 4694 - loss: 9.716096878051758\n",
      "Sample 4695 - loss: 8.028404235839844\n",
      "Sample 4696 - loss: 0.24718298017978668\n",
      "Sample 4697 - loss: 0.09837773442268372\n",
      "Sample 4698 - loss: 3.7818443775177\n",
      "Sample 4699 - loss: 3.2760848999023438\n",
      "Sample 4700 - loss: 6.407706260681152\n",
      "Sample 4701 - loss: 0.540244460105896\n",
      "Sample 4702 - loss: 9.935452461242676\n",
      "Sample 4703 - loss: 9.126382827758789\n",
      "Sample 4704 - loss: 0.25993624329566956\n",
      "Sample 4705 - loss: 0.159904345870018\n",
      "Sample 4706 - loss: 8.064703941345215\n",
      "Sample 4707 - loss: 5.367337226867676\n",
      "Sample 4708 - loss: 2.64797306060791\n",
      "Sample 4709 - loss: 6.90322732925415\n",
      "Sample 4710 - loss: 0.016279704868793488\n",
      "Sample 4711 - loss: 11.356049537658691\n",
      "Sample 4712 - loss: 0.8090465068817139\n",
      "Sample 4713 - loss: 2.619826555252075\n",
      "Sample 4714 - loss: 5.988085746765137\n",
      "Sample 4715 - loss: 4.246672630310059\n",
      "Sample 4716 - loss: 1.4114410877227783\n",
      "Sample 4717 - loss: 5.056753158569336\n",
      "Sample 4718 - loss: 2.094573736190796\n",
      "Sample 4719 - loss: 3.3517301082611084\n",
      "Sample 4720 - loss: 0.04802402853965759\n",
      "Sample 4721 - loss: 0.3797522485256195\n",
      "Sample 4722 - loss: 1.4142735004425049\n",
      "Sample 4723 - loss: 1.9175159931182861\n",
      "Sample 4724 - loss: 2.569350481033325\n",
      "Sample 4725 - loss: 2.565305709838867\n",
      "Sample 4726 - loss: 6.4891252517700195\n",
      "Sample 4727 - loss: 9.491271018981934\n",
      "Sample 4728 - loss: 1.8282638788223267\n",
      "Sample 4729 - loss: 8.693160057067871\n",
      "Sample 4730 - loss: 1.6356916427612305\n",
      "Sample 4731 - loss: 3.1361215114593506\n",
      "Sample 4732 - loss: 2.507775068283081\n",
      "Sample 4733 - loss: 2.3634655475616455\n",
      "Sample 4734 - loss: 1.6258702278137207\n",
      "Sample 4735 - loss: 2.320028305053711\n",
      "Sample 4736 - loss: 2.8823609352111816\n",
      "Sample 4737 - loss: 7.8826727867126465\n",
      "Sample 4738 - loss: 4.647048473358154\n",
      "Sample 4739 - loss: 0.11765048652887344\n",
      "Sample 4740 - loss: 0.0410800464451313\n",
      "Sample 4741 - loss: 0.38840922713279724\n",
      "Sample 4742 - loss: 10.302559852600098\n",
      "Sample 4743 - loss: 3.9459402561187744\n",
      "Sample 4744 - loss: 4.543994426727295\n",
      "Sample 4745 - loss: 1.6902663707733154\n",
      "Sample 4746 - loss: 10.999847412109375\n",
      "Sample 4747 - loss: 1.9637527465820312\n",
      "Sample 4748 - loss: 12.828544616699219\n",
      "Sample 4749 - loss: 0.0424581877887249\n",
      "Sample 4750 - loss: 0.8935328125953674\n",
      "Sample 4751 - loss: 3.70218563079834\n",
      "Sample 4752 - loss: 5.053918838500977\n",
      "Sample 4753 - loss: 2.434032678604126\n",
      "Sample 4754 - loss: 0.06521839648485184\n",
      "Sample 4755 - loss: 0.6661682724952698\n",
      "Sample 4756 - loss: 8.854846000671387\n",
      "Sample 4757 - loss: 0.6049640774726868\n",
      "Sample 4758 - loss: 0.07351647317409515\n",
      "Sample 4759 - loss: 5.6291069984436035\n",
      "Sample 4760 - loss: 1.885284423828125\n",
      "Sample 4761 - loss: 10.369462013244629\n",
      "Sample 4762 - loss: 2.078429698944092\n",
      "Sample 4763 - loss: 2.173830509185791\n",
      "Sample 4764 - loss: 0.7283720970153809\n",
      "Sample 4765 - loss: 8.038284301757812\n",
      "Sample 4766 - loss: 4.999447822570801\n",
      "Sample 4767 - loss: 3.4470369815826416\n",
      "Sample 4768 - loss: 7.204049587249756\n",
      "Sample 4769 - loss: 0.5198037028312683\n",
      "Sample 4770 - loss: 0.6079545617103577\n",
      "Sample 4771 - loss: 8.167444229125977\n",
      "Sample 4772 - loss: 0.5564540028572083\n",
      "Sample 4773 - loss: 7.183990955352783\n",
      "Sample 4774 - loss: 7.218695640563965\n",
      "Sample 4775 - loss: 1.2228164672851562\n",
      "Sample 4776 - loss: 3.1765809059143066\n",
      "Sample 4777 - loss: 3.525275945663452\n",
      "Sample 4778 - loss: 11.142735481262207\n",
      "Sample 4779 - loss: 1.363158106803894\n",
      "Sample 4780 - loss: 7.7667999267578125\n",
      "Sample 4781 - loss: 1.1821186542510986\n",
      "Sample 4782 - loss: 0.4039779603481293\n",
      "Sample 4783 - loss: 8.240091323852539\n",
      "Sample 4784 - loss: 5.529874801635742\n",
      "Sample 4785 - loss: 5.186249256134033\n",
      "Sample 4786 - loss: 1.4571822881698608\n",
      "Sample 4787 - loss: 0.3627406060695648\n",
      "Sample 4788 - loss: 0.24090078473091125\n",
      "Sample 4789 - loss: 4.67356014251709\n",
      "Sample 4790 - loss: 3.4682843685150146\n",
      "Sample 4791 - loss: 4.207902431488037\n",
      "Sample 4792 - loss: 1.793578028678894\n",
      "Sample 4793 - loss: 0.3343094289302826\n",
      "Sample 4794 - loss: 1.720729947090149\n",
      "Sample 4795 - loss: 0.9591050744056702\n",
      "Sample 4796 - loss: 2.9952285289764404\n",
      "Sample 4797 - loss: 6.2916154861450195\n",
      "Sample 4798 - loss: 6.798738479614258\n",
      "Sample 4799 - loss: 1.9286165237426758\n",
      "Sample 4800 - loss: 7.140156269073486\n",
      "Sample 4801 - loss: 6.270901679992676\n",
      "Sample 4802 - loss: 4.1852874755859375\n",
      "Sample 4803 - loss: 0.03828386962413788\n",
      "Sample 4804 - loss: 6.354640960693359\n",
      "Sample 4805 - loss: 8.253402709960938\n",
      "Sample 4806 - loss: 3.8804104328155518\n",
      "Sample 4807 - loss: 2.4938650131225586\n",
      "Sample 4808 - loss: 4.946048259735107\n",
      "Sample 4809 - loss: 0.017142631113529205\n",
      "Sample 4810 - loss: 1.04010808467865\n",
      "Sample 4811 - loss: 6.938919544219971\n",
      "Sample 4812 - loss: 2.6061859130859375\n",
      "Sample 4813 - loss: 1.2049809694290161\n",
      "Sample 4814 - loss: 3.299031972885132\n",
      "Sample 4815 - loss: 0.6115540862083435\n",
      "Sample 4816 - loss: 1.178206443786621\n",
      "Sample 4817 - loss: 5.334080696105957\n",
      "Sample 4818 - loss: 0.1763894259929657\n",
      "Sample 4819 - loss: 0.0626046434044838\n",
      "Sample 4820 - loss: 3.1564505100250244\n",
      "Sample 4821 - loss: 0.04586520791053772\n",
      "Sample 4822 - loss: 2.71939754486084\n",
      "Sample 4823 - loss: 0.05942187458276749\n",
      "Sample 4824 - loss: 1.844997525215149\n",
      "Sample 4825 - loss: 5.812070846557617\n",
      "Sample 4826 - loss: 7.451076507568359\n",
      "Sample 4827 - loss: 1.0765708684921265\n",
      "Sample 4828 - loss: 1.4852547645568848\n",
      "Sample 4829 - loss: 5.964388847351074\n",
      "Sample 4830 - loss: 9.833221435546875\n",
      "Sample 4831 - loss: 0.20695215463638306\n",
      "Sample 4832 - loss: 2.6308205127716064\n",
      "Sample 4833 - loss: 6.530266761779785\n",
      "Sample 4834 - loss: 8.910717964172363\n",
      "Sample 4835 - loss: 3.571585178375244\n",
      "Sample 4836 - loss: 7.545856475830078\n",
      "Sample 4837 - loss: 7.531901836395264\n",
      "Sample 4838 - loss: 0.15035265684127808\n",
      "Sample 4839 - loss: 0.07729876786470413\n",
      "Sample 4840 - loss: 2.8708314895629883\n",
      "Sample 4841 - loss: 4.540180206298828\n",
      "Sample 4842 - loss: 1.0347458124160767\n",
      "Sample 4843 - loss: 3.5474929809570312\n",
      "Sample 4844 - loss: 7.060689926147461\n",
      "Sample 4845 - loss: 6.675689697265625\n",
      "Sample 4846 - loss: 8.117966651916504\n",
      "Sample 4847 - loss: 8.751953125\n",
      "Sample 4848 - loss: 0.14605121314525604\n",
      "Sample 4849 - loss: 7.293793201446533\n",
      "Sample 4850 - loss: 5.1233720779418945\n",
      "Sample 4851 - loss: 4.361886501312256\n",
      "Sample 4852 - loss: 6.179778575897217\n",
      "Sample 4853 - loss: 0.4043896198272705\n",
      "Sample 4854 - loss: 1.3464497327804565\n",
      "Sample 4855 - loss: 0.2791966497898102\n",
      "Sample 4856 - loss: 7.722986221313477\n",
      "Sample 4857 - loss: 3.6172738075256348\n",
      "Sample 4858 - loss: 4.174278259277344\n",
      "Sample 4859 - loss: 0.8825290203094482\n",
      "Sample 4860 - loss: 0.8351193070411682\n",
      "Sample 4861 - loss: 1.729285717010498\n",
      "Sample 4862 - loss: 1.3735231161117554\n",
      "Sample 4863 - loss: 0.08080171793699265\n",
      "Sample 4864 - loss: 0.08570561558008194\n",
      "Sample 4865 - loss: 0.08788875490427017\n",
      "Sample 4866 - loss: 3.280322790145874\n",
      "Sample 4867 - loss: 8.89266586303711\n",
      "Sample 4868 - loss: 0.12859585881233215\n",
      "Sample 4869 - loss: 1.6567829847335815\n",
      "Sample 4870 - loss: 2.657320499420166\n",
      "Sample 4871 - loss: 6.204426288604736\n",
      "Sample 4872 - loss: 4.8399338722229\n",
      "Sample 4873 - loss: 0.04389181733131409\n",
      "Sample 4874 - loss: 0.38640299439430237\n",
      "Sample 4875 - loss: 2.9002695083618164\n",
      "Sample 4876 - loss: 3.1955630779266357\n",
      "Sample 4877 - loss: 2.3923532962799072\n",
      "Sample 4878 - loss: 2.645277738571167\n",
      "Sample 4879 - loss: 0.19315677881240845\n",
      "Sample 4880 - loss: 2.06492018699646\n",
      "Sample 4881 - loss: 0.9353840351104736\n",
      "Sample 4882 - loss: 6.478024482727051\n",
      "Sample 4883 - loss: 5.675222873687744\n",
      "Sample 4884 - loss: 0.142104372382164\n",
      "Sample 4885 - loss: 5.66358757019043\n",
      "Sample 4886 - loss: 2.6436095237731934\n",
      "Sample 4887 - loss: 0.6000831723213196\n",
      "Sample 4888 - loss: 3.089402437210083\n",
      "Sample 4889 - loss: 1.918587327003479\n",
      "Sample 4890 - loss: 6.004951000213623\n",
      "Sample 4891 - loss: 6.771990776062012\n",
      "Sample 4892 - loss: 3.0513710975646973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 4893 - loss: 10.466452598571777\n",
      "Sample 4894 - loss: 4.8518595695495605\n",
      "Sample 4895 - loss: 0.00663940841332078\n",
      "Sample 4896 - loss: 0.3595995306968689\n",
      "Sample 4897 - loss: 1.8875802755355835\n",
      "Sample 4898 - loss: 9.502470970153809\n",
      "Sample 4899 - loss: 6.642879486083984\n",
      "Sample 4900 - loss: 8.258591651916504\n",
      "Sample 4901 - loss: 4.4063310623168945\n",
      "Sample 4902 - loss: 3.0123283863067627\n",
      "Sample 4903 - loss: 0.5805777907371521\n",
      "Sample 4904 - loss: 1.0715360641479492\n",
      "Sample 4905 - loss: 0.9255664944648743\n",
      "Sample 4906 - loss: 1.9122772216796875\n",
      "Sample 4907 - loss: 1.4724208116531372\n",
      "Sample 4908 - loss: 2.2300870418548584\n",
      "Sample 4909 - loss: 1.6163992881774902\n",
      "Sample 4910 - loss: 0.9911460876464844\n",
      "Sample 4911 - loss: 4.368727207183838\n",
      "Sample 4912 - loss: 3.615736484527588\n",
      "Sample 4913 - loss: 1.6412221193313599\n",
      "Sample 4914 - loss: 2.3103837966918945\n",
      "Sample 4915 - loss: 7.203245162963867\n",
      "Sample 4916 - loss: 7.88437557220459\n",
      "Sample 4917 - loss: 9.605520248413086\n",
      "Sample 4918 - loss: 6.175388336181641\n",
      "Sample 4919 - loss: 0.9710537195205688\n",
      "Sample 4920 - loss: 5.8896074295043945\n",
      "Sample 4921 - loss: 8.014015197753906\n",
      "Sample 4922 - loss: 2.2644107341766357\n",
      "Sample 4923 - loss: 0.049933940172195435\n",
      "Sample 4924 - loss: 1.878484845161438\n",
      "Sample 4925 - loss: 3.955637216567993\n",
      "Sample 4926 - loss: 2.2181191444396973\n",
      "Sample 4927 - loss: 2.3143908977508545\n",
      "Sample 4928 - loss: 5.024054527282715\n",
      "Sample 4929 - loss: 0.482328861951828\n",
      "Sample 4930 - loss: 3.1866912841796875\n",
      "Sample 4931 - loss: 1.5105661153793335\n",
      "Sample 4932 - loss: 0.01983734779059887\n",
      "Sample 4933 - loss: 1.3107600212097168\n",
      "Sample 4934 - loss: 5.860308647155762\n",
      "Sample 4935 - loss: 1.7468851804733276\n",
      "Sample 4936 - loss: 0.22154106199741364\n",
      "Sample 4937 - loss: 2.5798022747039795\n",
      "Sample 4938 - loss: 1.6459875106811523\n",
      "Sample 4939 - loss: 7.349654674530029\n",
      "Sample 4940 - loss: 7.027348041534424\n",
      "Sample 4941 - loss: 2.563030481338501\n",
      "Sample 4942 - loss: 6.066047191619873\n",
      "Sample 4943 - loss: 4.781963348388672\n",
      "Sample 4944 - loss: 0.14863291382789612\n",
      "Sample 4945 - loss: 0.022913146764039993\n",
      "Sample 4946 - loss: 2.6982622146606445\n",
      "Sample 4947 - loss: 7.338911056518555\n",
      "Sample 4948 - loss: 0.7929938435554504\n",
      "Sample 4949 - loss: 3.7590856552124023\n",
      "Sample 4950 - loss: 3.2701919078826904\n",
      "Sample 4951 - loss: 1.4669888019561768\n",
      "Sample 4952 - loss: 1.8624894618988037\n",
      "Sample 4953 - loss: 8.892175674438477\n",
      "Sample 4954 - loss: 1.5085591077804565\n",
      "Sample 4955 - loss: 0.2598947584629059\n",
      "Sample 4956 - loss: 1.6265151500701904\n",
      "Sample 4957 - loss: 7.8249359130859375\n",
      "Sample 4958 - loss: 0.012767872773110867\n",
      "Sample 4959 - loss: 2.5455703735351562\n",
      "Sample 4960 - loss: 5.8431901931762695\n",
      "Sample 4961 - loss: 0.8885023593902588\n",
      "Sample 4962 - loss: 0.8040473461151123\n",
      "Sample 4963 - loss: 8.83681869506836\n",
      "Sample 4964 - loss: 1.1668342351913452\n",
      "Sample 4965 - loss: 7.119292736053467\n",
      "Sample 4966 - loss: 4.759982109069824\n",
      "Sample 4967 - loss: 1.2808752059936523\n",
      "Sample 4968 - loss: 1.749778151512146\n",
      "Sample 4969 - loss: 0.162033811211586\n",
      "Sample 4970 - loss: 0.15064924955368042\n",
      "Sample 4971 - loss: 2.417941093444824\n",
      "Sample 4972 - loss: 0.3142423927783966\n",
      "Sample 4973 - loss: 3.9495668411254883\n",
      "Sample 4974 - loss: 7.590299129486084\n",
      "Sample 4975 - loss: 0.9570022821426392\n",
      "Sample 4976 - loss: 8.03111457824707\n",
      "Sample 4977 - loss: 1.5124415159225464\n",
      "Sample 4978 - loss: 3.7093329429626465\n",
      "Sample 4979 - loss: 0.13554859161376953\n",
      "Sample 4980 - loss: 1.5473333597183228\n",
      "Sample 4981 - loss: 1.7193427085876465\n",
      "Sample 4982 - loss: 0.2133283019065857\n",
      "Sample 4983 - loss: 5.057178020477295\n",
      "Sample 4984 - loss: 0.5505428910255432\n",
      "Sample 4985 - loss: 9.057473182678223\n",
      "Sample 4986 - loss: 2.085433006286621\n",
      "Sample 4987 - loss: 10.42573356628418\n",
      "Sample 4988 - loss: 0.05970108509063721\n",
      "Sample 4989 - loss: 0.027495693415403366\n",
      "Sample 4990 - loss: 1.592897891998291\n",
      "Sample 4991 - loss: 2.2939682006835938\n",
      "Sample 4992 - loss: 0.5352024435997009\n",
      "Sample 4993 - loss: 0.07644820213317871\n",
      "Sample 4994 - loss: 0.01050272025167942\n",
      "Sample 4995 - loss: 4.908556938171387\n",
      "Sample 4996 - loss: 6.881532192230225\n",
      "Sample 4997 - loss: 0.5821250081062317\n",
      "Sample 4998 - loss: 2.4224157333374023\n",
      "Sample 4999 - loss: 5.416674613952637\n",
      "Sample 5000 - loss: 0.9212598204612732\n",
      "Sample 5001 - loss: 0.5347281694412231\n",
      "Sample 5002 - loss: 0.4626559019088745\n",
      "Sample 5003 - loss: 3.5901458263397217\n",
      "Sample 5004 - loss: 10.606823921203613\n",
      "Sample 5005 - loss: 3.504762887954712\n",
      "Sample 5006 - loss: 0.8637855648994446\n",
      "Sample 5007 - loss: 0.026616409420967102\n",
      "Sample 5008 - loss: 8.399128913879395\n",
      "Sample 5009 - loss: 0.5300444960594177\n",
      "Sample 5010 - loss: 2.767457962036133\n",
      "Sample 5011 - loss: 1.540921926498413\n",
      "Sample 5012 - loss: 5.4028730392456055\n",
      "Sample 5013 - loss: 6.085481643676758\n",
      "Sample 5014 - loss: 1.0937631130218506\n",
      "Sample 5015 - loss: 9.241565704345703\n",
      "Sample 5016 - loss: 3.8519110679626465\n",
      "Sample 5017 - loss: 0.8255098462104797\n",
      "Sample 5018 - loss: 1.8452749252319336\n",
      "Sample 5019 - loss: 0.05110854282975197\n",
      "Sample 5020 - loss: 0.3966276943683624\n",
      "Sample 5021 - loss: 2.954360246658325\n",
      "Sample 5022 - loss: 8.180180549621582\n",
      "Sample 5023 - loss: 3.791245698928833\n",
      "Sample 5024 - loss: 3.7974483966827393\n",
      "Sample 5025 - loss: 2.612539291381836\n",
      "Sample 5026 - loss: 8.1390962600708\n",
      "Sample 5027 - loss: 3.7757620811462402\n",
      "Sample 5028 - loss: 5.3171706199646\n",
      "Sample 5029 - loss: 2.332360029220581\n",
      "Sample 5030 - loss: 6.010410785675049\n",
      "Sample 5031 - loss: 0.8099493384361267\n",
      "Sample 5032 - loss: 3.749582290649414\n",
      "Sample 5033 - loss: 0.5297294855117798\n",
      "Sample 5034 - loss: 6.19450569152832\n",
      "Sample 5035 - loss: 2.8043017387390137\n",
      "Sample 5036 - loss: 0.009965470992028713\n",
      "Sample 5037 - loss: 2.388256311416626\n",
      "Sample 5038 - loss: 5.769758224487305\n",
      "Sample 5039 - loss: 1.9580559730529785\n",
      "Sample 5040 - loss: 0.8925939202308655\n",
      "Sample 5041 - loss: 5.093735694885254\n",
      "Sample 5042 - loss: 0.5041021704673767\n",
      "Sample 5043 - loss: 1.1986873149871826\n",
      "Sample 5044 - loss: 5.602368354797363\n",
      "Sample 5045 - loss: 3.7808926105499268\n",
      "Sample 5046 - loss: 0.9612605571746826\n",
      "Sample 5047 - loss: 4.709208965301514\n",
      "Sample 5048 - loss: 0.8889713883399963\n",
      "Sample 5049 - loss: 5.388910293579102\n",
      "Sample 5050 - loss: 6.828866004943848\n",
      "Sample 5051 - loss: 0.8049703240394592\n",
      "Sample 5052 - loss: 0.7427175045013428\n",
      "Sample 5053 - loss: 6.666051864624023\n",
      "Sample 5054 - loss: 3.5327303409576416\n",
      "Sample 5055 - loss: 2.6017141342163086\n",
      "Sample 5056 - loss: 3.4370131492614746\n",
      "Sample 5057 - loss: 0.7830150723457336\n",
      "Sample 5058 - loss: 3.942054510116577\n",
      "Sample 5059 - loss: 1.1545811891555786\n",
      "Sample 5060 - loss: 0.5006551146507263\n",
      "Sample 5061 - loss: 2.138435125350952\n",
      "Sample 5062 - loss: 1.4536004066467285\n",
      "Sample 5063 - loss: 8.640668869018555\n",
      "Sample 5064 - loss: 6.346384048461914\n",
      "Sample 5065 - loss: 4.0493669509887695\n",
      "Sample 5066 - loss: 0.33586356043815613\n",
      "Sample 5067 - loss: 0.9138556122779846\n",
      "Sample 5068 - loss: 0.4864256680011749\n",
      "Sample 5069 - loss: 5.085126876831055\n",
      "Sample 5070 - loss: 8.174884796142578\n",
      "Sample 5071 - loss: 10.290386199951172\n",
      "Sample 5072 - loss: 6.885443687438965\n",
      "Sample 5073 - loss: 0.6587115526199341\n",
      "Sample 5074 - loss: 2.3244800567626953\n",
      "Sample 5075 - loss: 5.8595194816589355\n",
      "Sample 5076 - loss: 0.1834898740053177\n",
      "Sample 5077 - loss: 6.828493595123291\n",
      "Sample 5078 - loss: 5.404299736022949\n",
      "Sample 5079 - loss: 0.12988099455833435\n",
      "Sample 5080 - loss: 4.730567455291748\n",
      "Sample 5081 - loss: 8.800989151000977\n",
      "Sample 5082 - loss: 4.386753082275391\n",
      "Sample 5083 - loss: 11.422143936157227\n",
      "Sample 5084 - loss: 4.432229995727539\n",
      "Sample 5085 - loss: 1.15175461769104\n",
      "Sample 5086 - loss: 8.999823570251465\n",
      "Sample 5087 - loss: 1.9062600135803223\n",
      "Sample 5088 - loss: 2.996577501296997\n",
      "Sample 5089 - loss: 5.538267135620117\n",
      "Sample 5090 - loss: 0.6286205649375916\n",
      "Sample 5091 - loss: 5.6245832443237305\n",
      "Sample 5092 - loss: 2.6316921710968018\n",
      "Sample 5093 - loss: 6.7241034507751465\n",
      "Sample 5094 - loss: 2.669381618499756\n",
      "Sample 5095 - loss: 0.05955679714679718\n",
      "Sample 5096 - loss: 3.9745583534240723\n",
      "Sample 5097 - loss: 0.6090977787971497\n",
      "Sample 5098 - loss: 3.768958806991577\n",
      "Sample 5099 - loss: 0.036178380250930786\n",
      "Sample 5100 - loss: 0.281890332698822\n",
      "Sample 5101 - loss: 1.251986026763916\n",
      "Sample 5102 - loss: 1.0494427680969238\n",
      "Sample 5103 - loss: 5.3154072761535645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5104 - loss: 6.572513580322266\n",
      "Sample 5105 - loss: 0.055528245866298676\n",
      "Sample 5106 - loss: 2.2783727645874023\n",
      "Sample 5107 - loss: 0.19379331171512604\n",
      "Sample 5108 - loss: 3.097846269607544\n",
      "Sample 5109 - loss: 8.601415634155273\n",
      "Sample 5110 - loss: 2.675567626953125\n",
      "Sample 5111 - loss: 4.185522079467773\n",
      "Sample 5112 - loss: 0.9262771606445312\n",
      "Sample 5113 - loss: 5.082454204559326\n",
      "Sample 5114 - loss: 0.014899704605340958\n",
      "Sample 5115 - loss: 1.39430832862854\n",
      "Sample 5116 - loss: 0.005892076063901186\n",
      "Sample 5117 - loss: 2.5189788341522217\n",
      "Sample 5118 - loss: 0.018742546439170837\n",
      "Sample 5119 - loss: 5.07783317565918\n",
      "Sample 5120 - loss: 4.5914716720581055\n",
      "Sample 5121 - loss: 2.0081818103790283\n",
      "Sample 5122 - loss: 4.406399726867676\n",
      "Sample 5123 - loss: 0.7784122228622437\n",
      "Sample 5124 - loss: 4.551477432250977\n",
      "Sample 5125 - loss: 3.210819959640503\n",
      "Sample 5126 - loss: 5.837759017944336\n",
      "Sample 5127 - loss: 3.0024094581604004\n",
      "Sample 5128 - loss: 7.888181686401367\n",
      "Sample 5129 - loss: 5.0777387619018555\n",
      "Sample 5130 - loss: 4.510675430297852\n",
      "Sample 5131 - loss: 0.6545212268829346\n",
      "Sample 5132 - loss: 2.0574772357940674\n",
      "Sample 5133 - loss: 3.5331122875213623\n",
      "Sample 5134 - loss: 0.3472977578639984\n",
      "Sample 5135 - loss: 1.982663869857788\n",
      "Sample 5136 - loss: 0.7430431842803955\n",
      "Sample 5137 - loss: 2.3608179092407227\n",
      "Sample 5138 - loss: 1.534871220588684\n",
      "Sample 5139 - loss: 2.9070382118225098\n",
      "Sample 5140 - loss: 11.30389404296875\n",
      "Sample 5141 - loss: 3.2959249019622803\n",
      "Sample 5142 - loss: 0.4449114501476288\n",
      "Sample 5143 - loss: 1.2924402952194214\n",
      "Sample 5144 - loss: 7.593032360076904\n",
      "Sample 5145 - loss: 1.6881884336471558\n",
      "Sample 5146 - loss: 5.188526153564453\n",
      "Sample 5147 - loss: 1.0245585441589355\n",
      "Sample 5148 - loss: 3.317882776260376\n",
      "Sample 5149 - loss: 6.891456127166748\n",
      "Sample 5150 - loss: 1.826184868812561\n",
      "Sample 5151 - loss: 3.937628746032715\n",
      "Sample 5152 - loss: 4.730020523071289\n",
      "Sample 5153 - loss: 1.02691650390625\n",
      "Sample 5154 - loss: 4.699120044708252\n",
      "Sample 5155 - loss: 0.019087372347712517\n",
      "Sample 5156 - loss: 1.2217624187469482\n",
      "Sample 5157 - loss: 3.644402265548706\n",
      "Sample 5158 - loss: 4.268780708312988\n",
      "Sample 5159 - loss: 2.4903690814971924\n",
      "Sample 5160 - loss: 3.879976511001587\n",
      "Sample 5161 - loss: 3.0727601051330566\n",
      "Sample 5162 - loss: 3.158797025680542\n",
      "Sample 5163 - loss: 7.608242988586426\n",
      "Sample 5164 - loss: 2.476653814315796\n",
      "Sample 5165 - loss: 3.702810049057007\n",
      "Sample 5166 - loss: 3.7129507064819336\n",
      "Sample 5167 - loss: 4.459144115447998\n",
      "Sample 5168 - loss: 2.8586864471435547\n",
      "Sample 5169 - loss: 2.845163583755493\n",
      "Sample 5170 - loss: 8.261394500732422\n",
      "Sample 5171 - loss: 0.07628633826971054\n",
      "Sample 5172 - loss: 7.408157825469971\n",
      "Sample 5173 - loss: 0.19970065355300903\n",
      "Sample 5174 - loss: 6.300041675567627\n",
      "Sample 5175 - loss: 7.2718281745910645\n",
      "Sample 5176 - loss: 2.11148738861084\n",
      "Sample 5177 - loss: 0.23005323112010956\n",
      "Sample 5178 - loss: 2.2334718704223633\n",
      "Sample 5179 - loss: 9.510847091674805\n",
      "Sample 5180 - loss: 2.311655044555664\n",
      "Sample 5181 - loss: 7.660643100738525\n",
      "Sample 5182 - loss: 4.835165500640869\n",
      "Sample 5183 - loss: 0.32659557461738586\n",
      "Sample 5184 - loss: 4.509428977966309\n",
      "Sample 5185 - loss: 1.0631375312805176\n",
      "Sample 5186 - loss: 0.09823587536811829\n",
      "Sample 5187 - loss: 0.7150912284851074\n",
      "Sample 5188 - loss: 0.9239799976348877\n",
      "Sample 5189 - loss: 3.3763198852539062\n",
      "Sample 5190 - loss: 3.1409854888916016\n",
      "Sample 5191 - loss: 1.4362342357635498\n",
      "Sample 5192 - loss: 4.825579643249512\n",
      "Sample 5193 - loss: 1.4170302152633667\n",
      "Sample 5194 - loss: 1.0152643918991089\n",
      "Sample 5195 - loss: 0.21979323029518127\n",
      "Sample 5196 - loss: 1.470468282699585\n",
      "Sample 5197 - loss: 1.768670916557312\n",
      "Sample 5198 - loss: 0.6619627475738525\n",
      "Sample 5199 - loss: 5.737743377685547\n",
      "Sample 5200 - loss: 3.2841684818267822\n",
      "Sample 5201 - loss: 0.4577813744544983\n",
      "Sample 5202 - loss: 4.410163879394531\n",
      "Sample 5203 - loss: 3.486387014389038\n",
      "Sample 5204 - loss: 2.5402467250823975\n",
      "Sample 5205 - loss: 1.315943956375122\n",
      "Sample 5206 - loss: 0.5406013131141663\n",
      "Sample 5207 - loss: 2.330584764480591\n",
      "Sample 5208 - loss: 0.14786340296268463\n",
      "Sample 5209 - loss: 0.7244243025779724\n",
      "Sample 5210 - loss: 7.1923112869262695\n",
      "Sample 5211 - loss: 0.3944908380508423\n",
      "Sample 5212 - loss: 2.79716157913208\n",
      "Sample 5213 - loss: 0.07051157206296921\n",
      "Sample 5214 - loss: 0.4358060359954834\n",
      "Sample 5215 - loss: 1.4910643100738525\n",
      "Sample 5216 - loss: 0.011843685992062092\n",
      "Sample 5217 - loss: 5.378925800323486\n",
      "Sample 5218 - loss: 0.015410269610583782\n",
      "Sample 5219 - loss: 0.6074742674827576\n",
      "Sample 5220 - loss: 3.1647491455078125\n",
      "Sample 5221 - loss: 4.464303493499756\n",
      "Sample 5222 - loss: 6.1389851570129395\n",
      "Sample 5223 - loss: 0.31388676166534424\n",
      "Sample 5224 - loss: 6.192818641662598\n",
      "Sample 5225 - loss: 0.2633322775363922\n",
      "Sample 5226 - loss: 0.08055764436721802\n",
      "Sample 5227 - loss: 2.2572076320648193\n",
      "Sample 5228 - loss: 0.011058214120566845\n",
      "Sample 5229 - loss: 0.11881691962480545\n",
      "Sample 5230 - loss: 6.320560932159424\n",
      "Sample 5231 - loss: 0.013005954213440418\n",
      "Sample 5232 - loss: 7.998483657836914\n",
      "Sample 5233 - loss: 6.379209041595459\n",
      "Sample 5234 - loss: 5.344674110412598\n",
      "Sample 5235 - loss: 0.194911390542984\n",
      "Sample 5236 - loss: 2.812105178833008\n",
      "Sample 5237 - loss: 1.1593163013458252\n",
      "Sample 5238 - loss: 8.848480224609375\n",
      "Sample 5239 - loss: 0.3355613946914673\n",
      "Sample 5240 - loss: 5.500088691711426\n",
      "Sample 5241 - loss: 6.663452625274658\n",
      "Sample 5242 - loss: 8.444480895996094\n",
      "Sample 5243 - loss: 0.42677536606788635\n",
      "Sample 5244 - loss: 5.061821460723877\n",
      "Sample 5245 - loss: 0.8061156272888184\n",
      "Sample 5246 - loss: 0.4229973554611206\n",
      "Sample 5247 - loss: 0.51446932554245\n",
      "Sample 5248 - loss: 5.45930290222168\n",
      "Sample 5249 - loss: 1.0652357339859009\n",
      "Sample 5250 - loss: 0.3615395426750183\n",
      "Sample 5251 - loss: 9.40688419342041\n",
      "Sample 5252 - loss: 6.538304328918457\n",
      "Sample 5253 - loss: 2.4487619400024414\n",
      "Sample 5254 - loss: 6.223555088043213\n",
      "Sample 5255 - loss: 4.972925662994385\n",
      "Sample 5256 - loss: 0.030308494344353676\n",
      "Sample 5257 - loss: 0.08999534696340561\n",
      "Sample 5258 - loss: 3.9392566680908203\n",
      "Sample 5259 - loss: 12.175765037536621\n",
      "Sample 5260 - loss: 1.4845939874649048\n",
      "Sample 5261 - loss: 3.021199941635132\n",
      "Sample 5262 - loss: 0.9544781446456909\n",
      "Sample 5263 - loss: 0.0076264264062047005\n",
      "Sample 5264 - loss: 0.1715652346611023\n",
      "Sample 5265 - loss: 6.7005510330200195\n",
      "Sample 5266 - loss: 3.941300868988037\n",
      "Sample 5267 - loss: 0.23752661049365997\n",
      "Sample 5268 - loss: 0.04786097630858421\n",
      "Sample 5269 - loss: 4.199102878570557\n",
      "Sample 5270 - loss: 0.5657444000244141\n",
      "Sample 5271 - loss: 8.717268943786621\n",
      "Sample 5272 - loss: 2.5576603412628174\n",
      "Sample 5273 - loss: 0.6544582843780518\n",
      "Sample 5274 - loss: 4.655401229858398\n",
      "Sample 5275 - loss: 0.9337109327316284\n",
      "Sample 5276 - loss: 2.285560369491577\n",
      "Sample 5277 - loss: 1.053221583366394\n",
      "Sample 5278 - loss: 7.379903793334961\n",
      "Sample 5279 - loss: 10.232721328735352\n",
      "Sample 5280 - loss: 2.6728458404541016\n",
      "Sample 5281 - loss: 0.43008530139923096\n",
      "Sample 5282 - loss: 3.3650002479553223\n",
      "Sample 5283 - loss: 3.359332799911499\n",
      "Sample 5284 - loss: 0.44701942801475525\n",
      "Sample 5285 - loss: 5.424660682678223\n",
      "Sample 5286 - loss: 0.038668397814035416\n",
      "Sample 5287 - loss: 3.4263412952423096\n",
      "Sample 5288 - loss: 4.7242631912231445\n",
      "Sample 5289 - loss: 2.167768955230713\n",
      "Sample 5290 - loss: 1.6405760049819946\n",
      "Sample 5291 - loss: 8.274688720703125\n",
      "Sample 5292 - loss: 4.435905456542969\n",
      "Sample 5293 - loss: 4.065204620361328\n",
      "Sample 5294 - loss: 0.4727776348590851\n",
      "Sample 5295 - loss: 1.1595733165740967\n",
      "Sample 5296 - loss: 0.8373337388038635\n",
      "Sample 5297 - loss: 5.310094833374023\n",
      "Sample 5298 - loss: 0.16756689548492432\n",
      "Sample 5299 - loss: 0.6597884893417358\n",
      "Sample 5300 - loss: 9.393566131591797\n",
      "Sample 5301 - loss: 0.23395150899887085\n",
      "Sample 5302 - loss: 1.2611850500106812\n",
      "Sample 5303 - loss: 0.7644937038421631\n",
      "Sample 5304 - loss: 0.025395382195711136\n",
      "Sample 5305 - loss: 3.172758102416992\n",
      "Sample 5306 - loss: 6.206589221954346\n",
      "Sample 5307 - loss: 9.920278549194336\n",
      "Sample 5308 - loss: 2.177233934402466\n",
      "Sample 5309 - loss: 0.6315370202064514\n",
      "Sample 5310 - loss: 0.35535740852355957\n",
      "Sample 5311 - loss: 0.20574870705604553\n",
      "Sample 5312 - loss: 0.6680241227149963\n",
      "Sample 5313 - loss: 4.849311828613281\n",
      "Sample 5314 - loss: 4.012532711029053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5315 - loss: 0.8345180749893188\n",
      "Sample 5316 - loss: 7.977790355682373\n",
      "Sample 5317 - loss: 2.0240509510040283\n",
      "Sample 5318 - loss: 2.8973233699798584\n",
      "Sample 5319 - loss: 2.573604106903076\n",
      "Sample 5320 - loss: 6.010766983032227\n",
      "Sample 5321 - loss: 9.218350410461426\n",
      "Sample 5322 - loss: 0.8353510499000549\n",
      "Sample 5323 - loss: 0.03726212680339813\n",
      "Sample 5324 - loss: 8.243829727172852\n",
      "Sample 5325 - loss: 7.123327732086182\n",
      "Sample 5326 - loss: 10.22097396850586\n",
      "Sample 5327 - loss: 8.113306045532227\n",
      "Sample 5328 - loss: 3.7648072242736816\n",
      "Sample 5329 - loss: 0.9714291095733643\n",
      "Sample 5330 - loss: 1.1021466255187988\n",
      "Sample 5331 - loss: 8.477795600891113\n",
      "Sample 5332 - loss: 3.033973455429077\n",
      "Sample 5333 - loss: 3.940758466720581\n",
      "Sample 5334 - loss: 7.135009765625\n",
      "Sample 5335 - loss: 4.540177822113037\n",
      "Sample 5336 - loss: 12.564627647399902\n",
      "Sample 5337 - loss: 1.0442326068878174\n",
      "Sample 5338 - loss: 5.0832438468933105\n",
      "Sample 5339 - loss: 8.776715278625488\n",
      "Sample 5340 - loss: 1.8930624723434448\n",
      "Sample 5341 - loss: 6.8719282150268555\n",
      "Sample 5342 - loss: 7.665229320526123\n",
      "Sample 5343 - loss: 1.0061851739883423\n",
      "Sample 5344 - loss: 1.6318966150283813\n",
      "Sample 5345 - loss: 1.9438563585281372\n",
      "Sample 5346 - loss: 0.60798180103302\n",
      "Sample 5347 - loss: 1.7742953300476074\n",
      "Sample 5348 - loss: 0.5479637980461121\n",
      "Sample 5349 - loss: 7.256667613983154\n",
      "Sample 5350 - loss: 10.80954360961914\n",
      "Sample 5351 - loss: 3.702035427093506\n",
      "Sample 5352 - loss: 1.5324040651321411\n",
      "Sample 5353 - loss: 0.7283955216407776\n",
      "Sample 5354 - loss: 0.6048932075500488\n",
      "Sample 5355 - loss: 0.1838947832584381\n",
      "Sample 5356 - loss: 0.5706993937492371\n",
      "Sample 5357 - loss: 0.058556221425533295\n",
      "Sample 5358 - loss: 4.609979629516602\n",
      "Sample 5359 - loss: 4.12437105178833\n",
      "Sample 5360 - loss: 4.976357936859131\n",
      "Sample 5361 - loss: 0.10128865391016006\n",
      "Sample 5362 - loss: 0.09196069091558456\n",
      "Sample 5363 - loss: 0.07861611247062683\n",
      "Sample 5364 - loss: 4.381204605102539\n",
      "Sample 5365 - loss: 0.2391437292098999\n",
      "Sample 5366 - loss: 2.329240322113037\n",
      "Sample 5367 - loss: 0.8942694067955017\n",
      "Sample 5368 - loss: 0.0545005165040493\n",
      "Sample 5369 - loss: 0.549811601638794\n",
      "Sample 5370 - loss: 0.9890130758285522\n",
      "Sample 5371 - loss: 4.283475399017334\n",
      "Sample 5372 - loss: 0.36275145411491394\n",
      "Sample 5373 - loss: 0.9254804849624634\n",
      "Sample 5374 - loss: 1.4968156814575195\n",
      "Sample 5375 - loss: 0.1695100963115692\n",
      "Sample 5376 - loss: 6.5728254318237305\n",
      "Sample 5377 - loss: 0.42184799909591675\n",
      "Sample 5378 - loss: 4.490437984466553\n",
      "Sample 5379 - loss: 6.116455554962158\n",
      "Sample 5380 - loss: 0.3032974302768707\n",
      "Sample 5381 - loss: 2.300719976425171\n",
      "Sample 5382 - loss: 0.4733390510082245\n",
      "Sample 5383 - loss: 3.6363630294799805\n",
      "Sample 5384 - loss: 8.3489351272583\n",
      "Sample 5385 - loss: 2.094604253768921\n",
      "Sample 5386 - loss: 2.0111663341522217\n",
      "Sample 5387 - loss: 0.40517669916152954\n",
      "Sample 5388 - loss: 0.14281192421913147\n",
      "Sample 5389 - loss: 0.1074308231472969\n",
      "Sample 5390 - loss: 1.249914526939392\n",
      "Sample 5391 - loss: 1.6214327812194824\n",
      "Sample 5392 - loss: 7.124319076538086\n",
      "Sample 5393 - loss: 0.659034788608551\n",
      "Sample 5394 - loss: 4.3402323722839355\n",
      "Sample 5395 - loss: 0.2683887183666229\n",
      "Sample 5396 - loss: 3.0044775009155273\n",
      "Sample 5397 - loss: 1.4646052122116089\n",
      "Sample 5398 - loss: 0.6542385220527649\n",
      "Sample 5399 - loss: 6.4685797691345215\n",
      "Sample 5400 - loss: 1.799320101737976\n",
      "Sample 5401 - loss: 2.2058281898498535\n",
      "Sample 5402 - loss: 4.570966720581055\n",
      "Sample 5403 - loss: 0.9680899977684021\n",
      "Sample 5404 - loss: 0.015011662617325783\n",
      "Sample 5405 - loss: 2.5795164108276367\n",
      "Sample 5406 - loss: 6.025772571563721\n",
      "Sample 5407 - loss: 1.4274609088897705\n",
      "Sample 5408 - loss: 5.9907636642456055\n",
      "Sample 5409 - loss: 0.6146200299263\n",
      "Sample 5410 - loss: 0.2005615234375\n",
      "Sample 5411 - loss: 0.2764774262905121\n",
      "Sample 5412 - loss: 0.9204877614974976\n",
      "Sample 5413 - loss: 0.400216281414032\n",
      "Sample 5414 - loss: 0.04096708819270134\n",
      "Sample 5415 - loss: 0.405558317899704\n",
      "Sample 5416 - loss: 1.5144073963165283\n",
      "Sample 5417 - loss: 3.1941139698028564\n",
      "Sample 5418 - loss: 4.731013298034668\n",
      "Sample 5419 - loss: 0.36392930150032043\n",
      "Sample 5420 - loss: 0.010182315483689308\n",
      "Sample 5421 - loss: 7.279769420623779\n",
      "Sample 5422 - loss: 4.243931770324707\n",
      "Sample 5423 - loss: 1.5040260553359985\n",
      "Sample 5424 - loss: 8.301167488098145\n",
      "Sample 5425 - loss: 1.4951651096343994\n",
      "Sample 5426 - loss: 5.771890640258789\n",
      "Sample 5427 - loss: 4.685664653778076\n",
      "Sample 5428 - loss: 3.002608299255371\n",
      "Sample 5429 - loss: 4.3032450675964355\n",
      "Sample 5430 - loss: 3.0471067428588867\n",
      "Sample 5431 - loss: 6.705844879150391\n",
      "Sample 5432 - loss: 2.9484899044036865\n",
      "Sample 5433 - loss: 2.302842140197754\n",
      "Sample 5434 - loss: 5.358524799346924\n",
      "Sample 5435 - loss: 7.036913871765137\n",
      "Sample 5436 - loss: 4.5919575691223145\n",
      "Sample 5437 - loss: 0.02036791294813156\n",
      "Sample 5438 - loss: 7.818886756896973\n",
      "Sample 5439 - loss: 0.0398014672100544\n",
      "Sample 5440 - loss: 9.333405494689941\n",
      "Sample 5441 - loss: 2.9681360721588135\n",
      "Sample 5442 - loss: 0.7671560645103455\n",
      "Sample 5443 - loss: 4.162110805511475\n",
      "Sample 5444 - loss: 2.430021286010742\n",
      "Sample 5445 - loss: 0.6050358414649963\n",
      "Sample 5446 - loss: 8.4973783493042\n",
      "Sample 5447 - loss: 5.931309700012207\n",
      "Sample 5448 - loss: 4.334714412689209\n",
      "Sample 5449 - loss: 0.14269383251667023\n",
      "Sample 5450 - loss: 0.5063576102256775\n",
      "Sample 5451 - loss: 6.309945106506348\n",
      "Sample 5452 - loss: 0.07447925955057144\n",
      "Sample 5453 - loss: 9.683704376220703\n",
      "Sample 5454 - loss: 2.9887993335723877\n",
      "Sample 5455 - loss: 4.678018569946289\n",
      "Sample 5456 - loss: 0.07057908177375793\n",
      "Sample 5457 - loss: 0.5358924269676208\n",
      "Sample 5458 - loss: 1.759056568145752\n",
      "Sample 5459 - loss: 3.9516165256500244\n",
      "Sample 5460 - loss: 9.453479766845703\n",
      "Sample 5461 - loss: 7.086707592010498\n",
      "Sample 5462 - loss: 3.4211575984954834\n",
      "Sample 5463 - loss: 0.08638345450162888\n",
      "Sample 5464 - loss: 1.0362060070037842\n",
      "Sample 5465 - loss: 0.824779748916626\n",
      "Sample 5466 - loss: 8.711359024047852\n",
      "Sample 5467 - loss: 5.502927780151367\n",
      "Sample 5468 - loss: 0.05223611369729042\n",
      "Sample 5469 - loss: 0.21243377029895782\n",
      "Sample 5470 - loss: 4.8618927001953125\n",
      "Sample 5471 - loss: 0.84051513671875\n",
      "Sample 5472 - loss: 1.4544240236282349\n",
      "Sample 5473 - loss: 4.083381175994873\n",
      "Sample 5474 - loss: 2.6227545738220215\n",
      "Sample 5475 - loss: 3.1771984100341797\n",
      "Sample 5476 - loss: 3.915656805038452\n",
      "Sample 5477 - loss: 0.5658087134361267\n",
      "Sample 5478 - loss: 4.400486469268799\n",
      "Sample 5479 - loss: 3.9733054637908936\n",
      "Sample 5480 - loss: 5.599783897399902\n",
      "Sample 5481 - loss: 2.244253635406494\n",
      "Sample 5482 - loss: 8.990447044372559\n",
      "Sample 5483 - loss: 5.4593095779418945\n",
      "Sample 5484 - loss: 3.0347678661346436\n",
      "Sample 5485 - loss: 1.116166353225708\n",
      "Sample 5486 - loss: 7.926778793334961\n",
      "Sample 5487 - loss: 6.028503894805908\n",
      "Sample 5488 - loss: 0.6922323107719421\n",
      "Sample 5489 - loss: 8.470917701721191\n",
      "Sample 5490 - loss: 7.365718841552734\n",
      "Sample 5491 - loss: 1.0284007787704468\n",
      "Sample 5492 - loss: 1.5800296068191528\n",
      "Sample 5493 - loss: 2.0920331478118896\n",
      "Sample 5494 - loss: 9.857643127441406\n",
      "Sample 5495 - loss: 0.709871232509613\n",
      "Sample 5496 - loss: 3.1010634899139404\n",
      "Sample 5497 - loss: 9.00540542602539\n",
      "Sample 5498 - loss: 0.8207389116287231\n",
      "Sample 5499 - loss: 6.45904541015625\n",
      "Sample 5500 - loss: 0.34232696890830994\n",
      "Sample 5501 - loss: 8.155219078063965\n",
      "Sample 5502 - loss: 9.817699432373047\n",
      "Sample 5503 - loss: 0.034443046897649765\n",
      "Sample 5504 - loss: 1.5350542068481445\n",
      "Sample 5505 - loss: 0.5033905506134033\n",
      "Sample 5506 - loss: 0.03586336597800255\n",
      "Sample 5507 - loss: 7.9930620193481445\n",
      "Sample 5508 - loss: 6.636669158935547\n",
      "Sample 5509 - loss: 0.33281242847442627\n",
      "Sample 5510 - loss: 0.07326097786426544\n",
      "Sample 5511 - loss: 0.2838260233402252\n",
      "Sample 5512 - loss: 1.42136812210083\n",
      "Sample 5513 - loss: 0.09510625898838043\n",
      "Sample 5514 - loss: 0.76737380027771\n",
      "Sample 5515 - loss: 3.3363149166107178\n",
      "Sample 5516 - loss: 4.804496765136719\n",
      "Sample 5517 - loss: 4.260000228881836\n",
      "Sample 5518 - loss: 6.533984184265137\n",
      "Sample 5519 - loss: 0.22268562018871307\n",
      "Sample 5520 - loss: 0.08314262330532074\n",
      "Sample 5521 - loss: 11.9005765914917\n",
      "Sample 5522 - loss: 0.04227609932422638\n",
      "Sample 5523 - loss: 1.581539511680603\n",
      "Sample 5524 - loss: 6.6657633781433105\n",
      "Sample 5525 - loss: 0.7543139457702637\n",
      "Sample 5526 - loss: 0.8941157460212708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5527 - loss: 2.870400905609131\n",
      "Sample 5528 - loss: 2.4637513160705566\n",
      "Sample 5529 - loss: 0.9164065718650818\n",
      "Sample 5530 - loss: 0.8993694186210632\n",
      "Sample 5531 - loss: 2.349175453186035\n",
      "Sample 5532 - loss: 0.45569390058517456\n",
      "Sample 5533 - loss: 1.303676962852478\n",
      "Sample 5534 - loss: 8.415765762329102\n",
      "Sample 5535 - loss: 1.2821182012557983\n",
      "Sample 5536 - loss: 9.233075141906738\n",
      "Sample 5537 - loss: 4.807704448699951\n",
      "Sample 5538 - loss: 0.7387658953666687\n",
      "Sample 5539 - loss: 0.7003464698791504\n",
      "Sample 5540 - loss: 0.0247283224016428\n",
      "Sample 5541 - loss: 8.901518821716309\n",
      "Sample 5542 - loss: 3.224133014678955\n",
      "Sample 5543 - loss: 6.1763834953308105\n",
      "Sample 5544 - loss: 4.426570892333984\n",
      "Sample 5545 - loss: 5.857046127319336\n",
      "Sample 5546 - loss: 2.395172595977783\n",
      "Sample 5547 - loss: 2.957939863204956\n",
      "Sample 5548 - loss: 4.583652019500732\n",
      "Sample 5549 - loss: 4.720492362976074\n",
      "Sample 5550 - loss: 7.076227188110352\n",
      "Sample 5551 - loss: 7.123837471008301\n",
      "Sample 5552 - loss: 4.764825344085693\n",
      "Sample 5553 - loss: 3.055612802505493\n",
      "Sample 5554 - loss: 1.015712857246399\n",
      "Sample 5555 - loss: 5.927301406860352\n",
      "Sample 5556 - loss: 2.9022579193115234\n",
      "Sample 5557 - loss: 4.643012523651123\n",
      "Sample 5558 - loss: 0.31842130422592163\n",
      "Sample 5559 - loss: 9.667696952819824\n",
      "Sample 5560 - loss: 0.01777927577495575\n",
      "Sample 5561 - loss: 1.4599711894989014\n",
      "Sample 5562 - loss: 1.9209625720977783\n",
      "Sample 5563 - loss: 10.028487205505371\n",
      "Sample 5564 - loss: 5.4603657722473145\n",
      "Sample 5565 - loss: 0.2898542582988739\n",
      "Sample 5566 - loss: 5.015964031219482\n",
      "Sample 5567 - loss: 0.7470498085021973\n",
      "Sample 5568 - loss: 1.4159148931503296\n",
      "Sample 5569 - loss: 5.676501274108887\n",
      "Sample 5570 - loss: 4.593462944030762\n",
      "Sample 5571 - loss: 0.26934337615966797\n",
      "Sample 5572 - loss: 0.1570529341697693\n",
      "Sample 5573 - loss: 0.9406887292861938\n",
      "Sample 5574 - loss: 0.3585966229438782\n",
      "Sample 5575 - loss: 4.2397847175598145\n",
      "Sample 5576 - loss: 2.6322455406188965\n",
      "Sample 5577 - loss: 0.48839935660362244\n",
      "Sample 5578 - loss: 2.4364571571350098\n",
      "Sample 5579 - loss: 7.026157379150391\n",
      "Sample 5580 - loss: 7.7429094314575195\n",
      "Sample 5581 - loss: 4.7900776863098145\n",
      "Sample 5582 - loss: 11.542119979858398\n",
      "Sample 5583 - loss: 8.287102699279785\n",
      "Sample 5584 - loss: 4.472143650054932\n",
      "Sample 5585 - loss: 1.3131921291351318\n",
      "Sample 5586 - loss: 0.9286161065101624\n",
      "Sample 5587 - loss: 1.7959765195846558\n",
      "Sample 5588 - loss: 1.8809139728546143\n",
      "Sample 5589 - loss: 4.965475082397461\n",
      "Sample 5590 - loss: 7.367115020751953\n",
      "Sample 5591 - loss: 0.19152988493442535\n",
      "Sample 5592 - loss: 2.9996557235717773\n",
      "Sample 5593 - loss: 0.060688119381666183\n",
      "Sample 5594 - loss: 0.2753673195838928\n",
      "Sample 5595 - loss: 1.1336919069290161\n",
      "Sample 5596 - loss: 6.452235698699951\n",
      "Sample 5597 - loss: 0.29247280955314636\n",
      "Sample 5598 - loss: 0.671252429485321\n",
      "Sample 5599 - loss: 6.820821762084961\n",
      "Sample 5600 - loss: 11.184370040893555\n",
      "Sample 5601 - loss: 1.0698554515838623\n",
      "Sample 5602 - loss: 1.469227910041809\n",
      "Sample 5603 - loss: 5.335233688354492\n",
      "Sample 5604 - loss: 0.05978691950440407\n",
      "Sample 5605 - loss: 3.450707197189331\n",
      "Sample 5606 - loss: 0.13003522157669067\n",
      "Sample 5607 - loss: 0.6294748187065125\n",
      "Sample 5608 - loss: 8.908342361450195\n",
      "Sample 5609 - loss: 0.21962910890579224\n",
      "Sample 5610 - loss: 4.788397312164307\n",
      "Sample 5611 - loss: 0.15143676102161407\n",
      "Sample 5612 - loss: 5.504924774169922\n",
      "Sample 5613 - loss: 0.6879186034202576\n",
      "Sample 5614 - loss: 0.027967162430286407\n",
      "Sample 5615 - loss: 2.6967153549194336\n",
      "Sample 5616 - loss: 1.4966408014297485\n",
      "Sample 5617 - loss: 3.6301400661468506\n",
      "Sample 5618 - loss: 0.04832480475306511\n",
      "Sample 5619 - loss: 3.118222236633301\n",
      "Sample 5620 - loss: 1.0237886905670166\n",
      "Sample 5621 - loss: 3.5182039737701416\n",
      "Sample 5622 - loss: 2.563411235809326\n",
      "Sample 5623 - loss: 5.340616226196289\n",
      "Sample 5624 - loss: 5.962334632873535\n",
      "Sample 5625 - loss: 0.14233717322349548\n",
      "Sample 5626 - loss: 0.31454646587371826\n",
      "Sample 5627 - loss: 6.305875778198242\n",
      "Sample 5628 - loss: 0.029265230521559715\n",
      "Sample 5629 - loss: 8.163045883178711\n",
      "Sample 5630 - loss: 0.08628080040216446\n",
      "Sample 5631 - loss: 3.932291030883789\n",
      "Sample 5632 - loss: 0.07704813033342361\n",
      "Sample 5633 - loss: 6.220395565032959\n",
      "Sample 5634 - loss: 8.280511856079102\n",
      "Sample 5635 - loss: 0.577308714389801\n",
      "Sample 5636 - loss: 0.08583042770624161\n",
      "Sample 5637 - loss: 6.521860122680664\n",
      "Sample 5638 - loss: 0.9640040397644043\n",
      "Sample 5639 - loss: 0.3029112219810486\n",
      "Sample 5640 - loss: 0.04590136185288429\n",
      "Sample 5641 - loss: 4.1172380447387695\n",
      "Sample 5642 - loss: 5.834610462188721\n",
      "Sample 5643 - loss: 1.5989556312561035\n",
      "Sample 5644 - loss: 1.026659607887268\n",
      "Sample 5645 - loss: 1.2472420930862427\n",
      "Sample 5646 - loss: 0.8594349026679993\n",
      "Sample 5647 - loss: 1.4535698890686035\n",
      "Sample 5648 - loss: 0.2860426604747772\n",
      "Sample 5649 - loss: 3.775092840194702\n",
      "Sample 5650 - loss: 5.326852321624756\n",
      "Sample 5651 - loss: 2.1940805912017822\n",
      "Sample 5652 - loss: 4.555209159851074\n",
      "Sample 5653 - loss: 2.7523245811462402\n",
      "Sample 5654 - loss: 1.7976971864700317\n",
      "Sample 5655 - loss: 0.031726520508527756\n",
      "Sample 5656 - loss: 1.3051425218582153\n",
      "Sample 5657 - loss: 0.9668861627578735\n",
      "Sample 5658 - loss: 0.6721569895744324\n",
      "Sample 5659 - loss: 1.9310411214828491\n",
      "Sample 5660 - loss: 4.519373893737793\n",
      "Sample 5661 - loss: 8.88111400604248\n",
      "Sample 5662 - loss: 1.904695749282837\n",
      "Sample 5663 - loss: 2.0757460594177246\n",
      "Sample 5664 - loss: 0.2906758189201355\n",
      "Sample 5665 - loss: 4.295621395111084\n",
      "Sample 5666 - loss: 8.64877700805664\n",
      "Sample 5667 - loss: 0.8481792211532593\n",
      "Sample 5668 - loss: 4.315536975860596\n",
      "Sample 5669 - loss: 1.137019157409668\n",
      "Sample 5670 - loss: 0.15461230278015137\n",
      "Sample 5671 - loss: 0.075215183198452\n",
      "Sample 5672 - loss: 0.02831658348441124\n",
      "Sample 5673 - loss: 0.0050164880231022835\n",
      "Sample 5674 - loss: 0.020238177850842476\n",
      "Sample 5675 - loss: 0.23497213423252106\n",
      "Sample 5676 - loss: 3.2553822994232178\n",
      "Sample 5677 - loss: 4.158548355102539\n",
      "Sample 5678 - loss: 3.828939199447632\n",
      "Sample 5679 - loss: 0.03993792459368706\n",
      "Sample 5680 - loss: 0.8452925682067871\n",
      "Sample 5681 - loss: 10.114654541015625\n",
      "Sample 5682 - loss: 5.680840969085693\n",
      "Sample 5683 - loss: 3.6064281463623047\n",
      "Sample 5684 - loss: 5.015558242797852\n",
      "Sample 5685 - loss: 0.7253134250640869\n",
      "Sample 5686 - loss: 8.623477935791016\n",
      "Sample 5687 - loss: 1.3954582214355469\n",
      "Sample 5688 - loss: 7.493009090423584\n",
      "Sample 5689 - loss: 0.09411811083555222\n",
      "Sample 5690 - loss: 8.63929271697998\n",
      "Sample 5691 - loss: 1.5181635618209839\n",
      "Sample 5692 - loss: 4.716099739074707\n",
      "Sample 5693 - loss: 7.46942138671875\n",
      "Sample 5694 - loss: 2.300985336303711\n",
      "Sample 5695 - loss: 0.14823587238788605\n",
      "Sample 5696 - loss: 2.9878995418548584\n",
      "Sample 5697 - loss: 10.555440902709961\n",
      "Sample 5698 - loss: 8.798213005065918\n",
      "Sample 5699 - loss: 0.5379987955093384\n",
      "Sample 5700 - loss: 1.5862780809402466\n",
      "Sample 5701 - loss: 4.358964920043945\n",
      "Sample 5702 - loss: 7.167783260345459\n",
      "Sample 5703 - loss: 5.834410190582275\n",
      "Sample 5704 - loss: 1.0474581718444824\n",
      "Sample 5705 - loss: 0.5953925848007202\n",
      "Sample 5706 - loss: 0.23348823189735413\n",
      "Sample 5707 - loss: 8.371091842651367\n",
      "Sample 5708 - loss: 0.8972543478012085\n",
      "Sample 5709 - loss: 5.52285099029541\n",
      "Sample 5710 - loss: 0.11133179813623428\n",
      "Sample 5711 - loss: 5.083292007446289\n",
      "Sample 5712 - loss: 0.664476752281189\n",
      "Sample 5713 - loss: 4.742330551147461\n",
      "Sample 5714 - loss: 0.18162517249584198\n",
      "Sample 5715 - loss: 0.8704721331596375\n",
      "Sample 5716 - loss: 1.7749279737472534\n",
      "Sample 5717 - loss: 4.988968849182129\n",
      "Sample 5718 - loss: 5.231035232543945\n",
      "Sample 5719 - loss: 6.707694053649902\n",
      "Sample 5720 - loss: 0.2972792685031891\n",
      "Sample 5721 - loss: 0.11344757676124573\n",
      "Sample 5722 - loss: 5.308248519897461\n",
      "Sample 5723 - loss: 3.388014793395996\n",
      "Sample 5724 - loss: 1.4071671962738037\n",
      "Sample 5725 - loss: 2.335068702697754\n",
      "Sample 5726 - loss: 0.2082109898328781\n",
      "Sample 5727 - loss: 7.756060600280762\n",
      "Sample 5728 - loss: 8.44954776763916\n",
      "Sample 5729 - loss: 0.8650283217430115\n",
      "Sample 5730 - loss: 1.0740693807601929\n",
      "Sample 5731 - loss: 0.6554663777351379\n",
      "Sample 5732 - loss: 0.8179551959037781\n",
      "Sample 5733 - loss: 0.8542293310165405\n",
      "Sample 5734 - loss: 4.700240612030029\n",
      "Sample 5735 - loss: 2.1943538188934326\n",
      "Sample 5736 - loss: 0.8364384174346924\n",
      "Sample 5737 - loss: 9.844130516052246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5738 - loss: 5.843545436859131\n",
      "Sample 5739 - loss: 0.03253998979926109\n",
      "Sample 5740 - loss: 4.169116497039795\n",
      "Sample 5741 - loss: 6.421796798706055\n",
      "Sample 5742 - loss: 5.938923358917236\n",
      "Sample 5743 - loss: 6.326956272125244\n",
      "Sample 5744 - loss: 0.2206084132194519\n",
      "Sample 5745 - loss: 2.783669948577881\n",
      "Sample 5746 - loss: 0.16407173871994019\n",
      "Sample 5747 - loss: 0.07314667105674744\n",
      "Sample 5748 - loss: 0.027557983994483948\n",
      "Sample 5749 - loss: 0.4871169626712799\n",
      "Sample 5750 - loss: 8.027320861816406\n",
      "Sample 5751 - loss: 4.027993679046631\n",
      "Sample 5752 - loss: 3.0316879749298096\n",
      "Sample 5753 - loss: 7.045910835266113\n",
      "Sample 5754 - loss: 6.168893814086914\n",
      "Sample 5755 - loss: 1.9206167459487915\n",
      "Sample 5756 - loss: 2.3618791103363037\n",
      "Sample 5757 - loss: 2.748175859451294\n",
      "Sample 5758 - loss: 0.6562262177467346\n",
      "Sample 5759 - loss: 1.561012625694275\n",
      "Sample 5760 - loss: 0.1508428454399109\n",
      "Sample 5761 - loss: 0.3396809697151184\n",
      "Sample 5762 - loss: 3.8949596881866455\n",
      "Sample 5763 - loss: 3.028531074523926\n",
      "Sample 5764 - loss: 4.548376560211182\n",
      "Sample 5765 - loss: 0.047728367149829865\n",
      "Sample 5766 - loss: 5.889444351196289\n",
      "Sample 5767 - loss: 5.587141036987305\n",
      "Sample 5768 - loss: 7.258148193359375\n",
      "Sample 5769 - loss: 0.28240901231765747\n",
      "Sample 5770 - loss: 0.019292190670967102\n",
      "Sample 5771 - loss: 5.210977077484131\n",
      "Sample 5772 - loss: 0.014002526178956032\n",
      "Sample 5773 - loss: 5.4033284187316895\n",
      "Sample 5774 - loss: 5.843051910400391\n",
      "Sample 5775 - loss: 0.44873565435409546\n",
      "Sample 5776 - loss: 3.074622392654419\n",
      "Sample 5777 - loss: 6.051482677459717\n",
      "Sample 5778 - loss: 1.0524897575378418\n",
      "Sample 5779 - loss: 0.38282597064971924\n",
      "Sample 5780 - loss: 0.00952689629048109\n",
      "Sample 5781 - loss: 3.439639091491699\n",
      "Sample 5782 - loss: 2.6051080226898193\n",
      "Sample 5783 - loss: 5.668923854827881\n",
      "Sample 5784 - loss: 9.61975383758545\n",
      "Sample 5785 - loss: 7.0065789222717285\n",
      "Sample 5786 - loss: 4.979804515838623\n",
      "Sample 5787 - loss: 6.7415385246276855\n",
      "Sample 5788 - loss: 0.3027406334877014\n",
      "Sample 5789 - loss: 0.4373382329940796\n",
      "Sample 5790 - loss: 6.987180233001709\n",
      "Sample 5791 - loss: 8.338461875915527\n",
      "Sample 5792 - loss: 7.279747486114502\n",
      "Sample 5793 - loss: 8.796280860900879\n",
      "Sample 5794 - loss: 4.864692211151123\n",
      "Sample 5795 - loss: 0.15794813632965088\n",
      "Sample 5796 - loss: 0.09697860479354858\n",
      "Sample 5797 - loss: 2.1747055053710938\n",
      "Sample 5798 - loss: 7.271294593811035\n",
      "Sample 5799 - loss: 9.558289527893066\n",
      "Sample 5800 - loss: 9.776481628417969\n",
      "Sample 5801 - loss: 0.046020183712244034\n",
      "Sample 5802 - loss: 3.0023386478424072\n",
      "Sample 5803 - loss: 3.081718683242798\n",
      "Sample 5804 - loss: 0.457404226064682\n",
      "Sample 5805 - loss: 2.794532537460327\n",
      "Sample 5806 - loss: 1.49979567527771\n",
      "Sample 5807 - loss: 8.182269096374512\n",
      "Sample 5808 - loss: 4.290124416351318\n",
      "Sample 5809 - loss: 2.9509682655334473\n",
      "Sample 5810 - loss: 0.5139328241348267\n",
      "Sample 5811 - loss: 1.3485256433486938\n",
      "Sample 5812 - loss: 3.9921000003814697\n",
      "Sample 5813 - loss: 5.389799118041992\n",
      "Sample 5814 - loss: 7.415277004241943\n",
      "Sample 5815 - loss: 0.17583805322647095\n",
      "Sample 5816 - loss: 3.007658004760742\n",
      "Sample 5817 - loss: 2.5683517456054688\n",
      "Sample 5818 - loss: 0.41196686029434204\n",
      "Sample 5819 - loss: 1.1716082096099854\n",
      "Sample 5820 - loss: 8.61228084564209\n",
      "Sample 5821 - loss: 3.951777935028076\n",
      "Sample 5822 - loss: 1.9430248737335205\n",
      "Sample 5823 - loss: 7.89284610748291\n",
      "Sample 5824 - loss: 6.735140800476074\n",
      "Sample 5825 - loss: 1.378962516784668\n",
      "Sample 5826 - loss: 1.0031635761260986\n",
      "Sample 5827 - loss: 6.552716255187988\n",
      "Sample 5828 - loss: 5.427008628845215\n",
      "Sample 5829 - loss: 6.612461566925049\n",
      "Sample 5830 - loss: 2.778378963470459\n",
      "Sample 5831 - loss: 9.256121635437012\n",
      "Sample 5832 - loss: 0.11291977018117905\n",
      "Sample 5833 - loss: 3.3129515647888184\n",
      "Sample 5834 - loss: 0.2019267976284027\n",
      "Sample 5835 - loss: 9.338358879089355\n",
      "Sample 5836 - loss: 1.7602348327636719\n",
      "Sample 5837 - loss: 3.535922050476074\n",
      "Sample 5838 - loss: 0.951312780380249\n",
      "Sample 5839 - loss: 0.06734897941350937\n",
      "Sample 5840 - loss: 4.127668857574463\n",
      "Sample 5841 - loss: 0.3315030038356781\n",
      "Sample 5842 - loss: 11.383256912231445\n",
      "Sample 5843 - loss: 5.121265411376953\n",
      "Sample 5844 - loss: 3.169335126876831\n",
      "Sample 5845 - loss: 8.952049255371094\n",
      "Sample 5846 - loss: 1.3204258680343628\n",
      "Sample 5847 - loss: 1.9220119714736938\n",
      "Sample 5848 - loss: 1.7244563102722168\n",
      "Sample 5849 - loss: 5.841873645782471\n",
      "Sample 5850 - loss: 1.1165939569473267\n",
      "Sample 5851 - loss: 1.52144193649292\n",
      "Sample 5852 - loss: 0.3914321959018707\n",
      "Sample 5853 - loss: 0.014314074069261551\n",
      "Sample 5854 - loss: 0.9808565378189087\n",
      "Sample 5855 - loss: 0.14303819835186005\n",
      "Sample 5856 - loss: 0.1894105076789856\n",
      "Sample 5857 - loss: 0.8037657141685486\n",
      "Sample 5858 - loss: 2.5065009593963623\n",
      "Sample 5859 - loss: 3.6968190670013428\n",
      "Sample 5860 - loss: 0.807573139667511\n",
      "Sample 5861 - loss: 2.3959834575653076\n",
      "Sample 5862 - loss: 0.08469633758068085\n",
      "Sample 5863 - loss: 0.9137513041496277\n",
      "Sample 5864 - loss: 1.784661889076233\n",
      "Sample 5865 - loss: 6.206020355224609\n",
      "Sample 5866 - loss: 0.49716728925704956\n",
      "Sample 5867 - loss: 2.775432825088501\n",
      "Sample 5868 - loss: 3.7451236248016357\n",
      "Sample 5869 - loss: 5.942403793334961\n",
      "Sample 5870 - loss: 1.2571184635162354\n",
      "Sample 5871 - loss: 5.621446132659912\n",
      "Sample 5872 - loss: 4.986456394195557\n",
      "Sample 5873 - loss: 0.16947127878665924\n",
      "Sample 5874 - loss: 1.5188758373260498\n",
      "Sample 5875 - loss: 1.0406417846679688\n",
      "Sample 5876 - loss: 5.752561092376709\n",
      "Sample 5877 - loss: 10.550707817077637\n",
      "Sample 5878 - loss: 3.6684279441833496\n",
      "Sample 5879 - loss: 3.1729021072387695\n",
      "Sample 5880 - loss: 2.500208854675293\n",
      "Sample 5881 - loss: 1.2543230056762695\n",
      "Sample 5882 - loss: 8.117504119873047\n",
      "Sample 5883 - loss: 3.105120897293091\n",
      "Sample 5884 - loss: 7.1881513595581055\n",
      "Sample 5885 - loss: 1.6924406290054321\n",
      "Sample 5886 - loss: 0.15541456639766693\n",
      "Sample 5887 - loss: 4.905325889587402\n",
      "Sample 5888 - loss: 7.879194736480713\n",
      "Sample 5889 - loss: 3.475707769393921\n",
      "Sample 5890 - loss: 2.5362648963928223\n",
      "Sample 5891 - loss: 2.775639057159424\n",
      "Sample 5892 - loss: 0.1546105444431305\n",
      "Sample 5893 - loss: 1.4626717567443848\n",
      "Sample 5894 - loss: 2.0964081287384033\n",
      "Sample 5895 - loss: 2.7291321754455566\n",
      "Sample 5896 - loss: 5.662837505340576\n",
      "Sample 5897 - loss: 1.4189141988754272\n",
      "Sample 5898 - loss: 0.5798439979553223\n",
      "Sample 5899 - loss: 0.44879409670829773\n",
      "Sample 5900 - loss: 12.389911651611328\n",
      "Sample 5901 - loss: 1.1726845502853394\n",
      "Sample 5902 - loss: 3.7551915645599365\n",
      "Sample 5903 - loss: 0.03897608071565628\n",
      "Sample 5904 - loss: 1.3729475736618042\n",
      "Sample 5905 - loss: 0.2388431578874588\n",
      "Sample 5906 - loss: 0.7113807201385498\n",
      "Sample 5907 - loss: 0.37554508447647095\n",
      "Sample 5908 - loss: 1.223758578300476\n",
      "Sample 5909 - loss: 2.11337947845459\n",
      "Sample 5910 - loss: 2.5633697509765625\n",
      "Sample 5911 - loss: 0.5506004095077515\n",
      "Sample 5912 - loss: 0.08990073949098587\n",
      "Sample 5913 - loss: 9.283517837524414\n",
      "Sample 5914 - loss: 11.646081924438477\n",
      "Sample 5915 - loss: 1.7702581882476807\n",
      "Sample 5916 - loss: 6.323650360107422\n",
      "Sample 5917 - loss: 5.326054573059082\n",
      "Sample 5918 - loss: 3.3639883995056152\n",
      "Sample 5919 - loss: 2.0970511436462402\n",
      "Sample 5920 - loss: 0.43940791487693787\n",
      "Sample 5921 - loss: 4.612731456756592\n",
      "Sample 5922 - loss: 7.745540618896484\n",
      "Sample 5923 - loss: 5.203907489776611\n",
      "Sample 5924 - loss: 0.2872542142868042\n",
      "Sample 5925 - loss: 8.061161994934082\n",
      "Sample 5926 - loss: 3.476076364517212\n",
      "Sample 5927 - loss: 3.64113712310791\n",
      "Sample 5928 - loss: 4.7513322830200195\n",
      "Sample 5929 - loss: 7.90443229675293\n",
      "Sample 5930 - loss: 1.1839094161987305\n",
      "Sample 5931 - loss: 8.273294448852539\n",
      "Sample 5932 - loss: 0.03383725881576538\n",
      "Sample 5933 - loss: 6.8223395347595215\n",
      "Sample 5934 - loss: 0.13409115374088287\n",
      "Sample 5935 - loss: 4.4563751220703125\n",
      "Sample 5936 - loss: 3.051142930984497\n",
      "Sample 5937 - loss: 3.4650347232818604\n",
      "Sample 5938 - loss: 1.08768892288208\n",
      "Sample 5939 - loss: 2.842535972595215\n",
      "Sample 5940 - loss: 6.880192279815674\n",
      "Sample 5941 - loss: 7.5304036140441895\n",
      "Sample 5942 - loss: 2.660264253616333\n",
      "Sample 5943 - loss: 4.7130632400512695\n",
      "Sample 5944 - loss: 0.24296413362026215\n",
      "Sample 5945 - loss: 3.297882080078125\n",
      "Sample 5946 - loss: 7.970980167388916\n",
      "Sample 5947 - loss: 7.13936710357666\n",
      "Sample 5948 - loss: 3.8854339122772217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5949 - loss: 0.8391338586807251\n",
      "Sample 5950 - loss: 4.818227291107178\n",
      "Sample 5951 - loss: 1.975576639175415\n",
      "Sample 5952 - loss: 1.7233381271362305\n",
      "Sample 5953 - loss: 0.934814453125\n",
      "Sample 5954 - loss: 4.505177974700928\n",
      "Sample 5955 - loss: 0.6101803183555603\n",
      "Sample 5956 - loss: 3.6364614963531494\n",
      "Sample 5957 - loss: 0.023012211546301842\n",
      "Sample 5958 - loss: 3.1864876747131348\n",
      "Sample 5959 - loss: 0.8737567067146301\n",
      "Sample 5960 - loss: 2.0507214069366455\n",
      "Sample 5961 - loss: 0.6573230624198914\n",
      "Sample 5962 - loss: 0.16941837966442108\n",
      "Sample 5963 - loss: 0.1344711184501648\n",
      "Sample 5964 - loss: 0.1421806365251541\n",
      "Sample 5965 - loss: 0.018760301172733307\n",
      "Sample 5966 - loss: 2.738372802734375\n",
      "Sample 5967 - loss: 0.11331071704626083\n",
      "Sample 5968 - loss: 0.22058242559432983\n",
      "Sample 5969 - loss: 0.2273339331150055\n",
      "Sample 5970 - loss: 0.39632147550582886\n",
      "Sample 5971 - loss: 6.38840389251709\n",
      "Sample 5972 - loss: 1.245241641998291\n",
      "Sample 5973 - loss: 6.994623184204102\n",
      "Sample 5974 - loss: 3.915492057800293\n",
      "Sample 5975 - loss: 0.025545340031385422\n",
      "Sample 5976 - loss: 2.1839418411254883\n",
      "Sample 5977 - loss: 0.04239363223314285\n",
      "Sample 5978 - loss: 0.08231448382139206\n",
      "Sample 5979 - loss: 8.448285102844238\n",
      "Sample 5980 - loss: 1.0250002145767212\n",
      "Sample 5981 - loss: 0.24314653873443604\n",
      "Sample 5982 - loss: 2.290565252304077\n",
      "Sample 5983 - loss: 2.683335542678833\n",
      "Sample 5984 - loss: 7.577732086181641\n",
      "Sample 5985 - loss: 7.84358024597168\n",
      "Sample 5986 - loss: 0.13955962657928467\n",
      "Sample 5987 - loss: 4.31353759765625\n",
      "Sample 5988 - loss: 3.8742072582244873\n",
      "Sample 5989 - loss: 2.3534348011016846\n",
      "Sample 5990 - loss: 0.1691417545080185\n",
      "Sample 5991 - loss: 4.837662220001221\n",
      "Sample 5992 - loss: 2.360288619995117\n",
      "Sample 5993 - loss: 6.612878322601318\n",
      "Sample 5994 - loss: 6.041207313537598\n",
      "Sample 5995 - loss: 0.23232336342334747\n",
      "Sample 5996 - loss: 8.814428329467773\n",
      "Sample 5997 - loss: 1.3434724807739258\n",
      "Sample 5998 - loss: 0.46442198753356934\n",
      "Sample 5999 - loss: 0.119488924741745\n",
      "Sample 6000 - loss: 3.4120166301727295\n",
      "Sample 6001 - loss: 1.686818242073059\n",
      "Sample 6002 - loss: 9.046235084533691\n",
      "Sample 6003 - loss: 5.2162299156188965\n",
      "Sample 6004 - loss: 0.04205317422747612\n",
      "Sample 6005 - loss: 0.6365009546279907\n",
      "Sample 6006 - loss: 3.2882239818573\n",
      "Sample 6007 - loss: 0.07752074301242828\n",
      "Sample 6008 - loss: 1.567502737045288\n",
      "Sample 6009 - loss: 0.49818259477615356\n",
      "Sample 6010 - loss: 3.4586715698242188\n",
      "Sample 6011 - loss: 0.26324108242988586\n",
      "Sample 6012 - loss: 1.8197153806686401\n",
      "Sample 6013 - loss: 2.4164938926696777\n",
      "Sample 6014 - loss: 7.783141613006592\n",
      "Sample 6015 - loss: 4.2017340660095215\n",
      "Sample 6016 - loss: 8.178862571716309\n",
      "Sample 6017 - loss: 0.4750194549560547\n",
      "Sample 6018 - loss: 3.290471076965332\n",
      "Sample 6019 - loss: 1.3949147462844849\n",
      "Sample 6020 - loss: 3.8156368732452393\n",
      "Sample 6021 - loss: 1.6545436382293701\n",
      "Sample 6022 - loss: 8.25202751159668\n",
      "Sample 6023 - loss: 5.638913154602051\n",
      "Sample 6024 - loss: 1.994870901107788\n",
      "Sample 6025 - loss: 9.976021766662598\n",
      "Sample 6026 - loss: 3.0370407104492188\n",
      "Sample 6027 - loss: 3.7815628051757812\n",
      "Sample 6028 - loss: 0.764014720916748\n",
      "Sample 6029 - loss: 5.359152793884277\n",
      "Sample 6030 - loss: 11.489104270935059\n",
      "Sample 6031 - loss: 0.6408532857894897\n",
      "Sample 6032 - loss: 2.8066184520721436\n",
      "Sample 6033 - loss: 7.404935359954834\n",
      "Sample 6034 - loss: 1.7809780836105347\n",
      "Sample 6035 - loss: 3.0155599117279053\n",
      "Sample 6036 - loss: 0.049051761627197266\n",
      "Sample 6037 - loss: 1.3128561973571777\n",
      "Sample 6038 - loss: 3.1365468502044678\n",
      "Sample 6039 - loss: 9.644526481628418\n",
      "Sample 6040 - loss: 0.9943742156028748\n",
      "Sample 6041 - loss: 2.4695143699645996\n",
      "Sample 6042 - loss: 8.846324920654297\n",
      "Sample 6043 - loss: 3.722207546234131\n",
      "Sample 6044 - loss: 0.578779399394989\n",
      "Sample 6045 - loss: 6.646807670593262\n",
      "Sample 6046 - loss: 2.0499541759490967\n",
      "Sample 6047 - loss: 3.590730667114258\n",
      "Sample 6048 - loss: 6.096445083618164\n",
      "Sample 6049 - loss: 7.9299421310424805\n",
      "Sample 6050 - loss: 4.6345906257629395\n",
      "Sample 6051 - loss: 11.975602149963379\n",
      "Sample 6052 - loss: 7.054434776306152\n",
      "Sample 6053 - loss: 0.7095067501068115\n",
      "Sample 6054 - loss: 0.5472785234451294\n",
      "Sample 6055 - loss: 2.51206374168396\n",
      "Sample 6056 - loss: 4.877584934234619\n",
      "Sample 6057 - loss: 3.5729727745056152\n",
      "Sample 6058 - loss: 3.8517203330993652\n",
      "Sample 6059 - loss: 1.5984419584274292\n",
      "Sample 6060 - loss: 9.606138229370117\n",
      "Sample 6061 - loss: 4.209970951080322\n",
      "Sample 6062 - loss: 7.432751655578613\n",
      "Sample 6063 - loss: 4.589971542358398\n",
      "Sample 6064 - loss: 0.034186601638793945\n",
      "Sample 6065 - loss: 4.649257659912109\n",
      "Sample 6066 - loss: 0.40656548738479614\n",
      "Sample 6067 - loss: 2.0169663429260254\n",
      "Sample 6068 - loss: 0.12862366437911987\n",
      "Sample 6069 - loss: 0.20903240144252777\n",
      "Sample 6070 - loss: 1.122128963470459\n",
      "Sample 6071 - loss: 5.193517684936523\n",
      "Sample 6072 - loss: 0.06859391927719116\n",
      "Sample 6073 - loss: 2.478510856628418\n",
      "Sample 6074 - loss: 2.063244342803955\n",
      "Sample 6075 - loss: 0.9383851885795593\n",
      "Sample 6076 - loss: 0.4140421152114868\n",
      "Sample 6077 - loss: 3.311368703842163\n",
      "Sample 6078 - loss: 8.731839179992676\n",
      "Sample 6079 - loss: 5.432100772857666\n",
      "Sample 6080 - loss: 7.60421895980835\n",
      "Sample 6081 - loss: 3.9506120681762695\n",
      "Sample 6082 - loss: 4.707269191741943\n",
      "Sample 6083 - loss: 1.554500699043274\n",
      "Sample 6084 - loss: 3.144937753677368\n",
      "Sample 6085 - loss: 2.848248243331909\n",
      "Sample 6086 - loss: 4.80494499206543\n",
      "Sample 6087 - loss: 0.17459775507450104\n",
      "Sample 6088 - loss: 0.8440796136856079\n",
      "Sample 6089 - loss: 1.2569077014923096\n",
      "Sample 6090 - loss: 1.4967296123504639\n",
      "Sample 6091 - loss: 8.602028846740723\n",
      "Sample 6092 - loss: 7.730810642242432\n",
      "Sample 6093 - loss: 6.6009063720703125\n",
      "Sample 6094 - loss: 8.792682647705078\n",
      "Sample 6095 - loss: 2.2195143699645996\n",
      "Sample 6096 - loss: 3.6111090183258057\n",
      "Sample 6097 - loss: 0.5685774683952332\n",
      "Sample 6098 - loss: 0.7883298397064209\n",
      "Sample 6099 - loss: 0.007320625241845846\n",
      "Sample 6100 - loss: 0.08666814863681793\n",
      "Sample 6101 - loss: 3.1134560108184814\n",
      "Sample 6102 - loss: 4.15238618850708\n",
      "Sample 6103 - loss: 4.926678657531738\n",
      "Sample 6104 - loss: 1.66280198097229\n",
      "Sample 6105 - loss: 8.07809066772461\n",
      "Sample 6106 - loss: 6.612969875335693\n",
      "Sample 6107 - loss: 2.591134548187256\n",
      "Sample 6108 - loss: 4.2806010246276855\n",
      "Sample 6109 - loss: 2.3965811729431152\n",
      "Sample 6110 - loss: 0.21885274350643158\n",
      "Sample 6111 - loss: 0.005190376657992601\n",
      "Sample 6112 - loss: 5.7633376121521\n",
      "Sample 6113 - loss: 5.623546123504639\n",
      "Sample 6114 - loss: 6.087182998657227\n",
      "Sample 6115 - loss: 3.8314058780670166\n",
      "Sample 6116 - loss: 2.2465035915374756\n",
      "Sample 6117 - loss: 6.108547210693359\n",
      "Sample 6118 - loss: 8.550762176513672\n",
      "Sample 6119 - loss: 5.352906703948975\n",
      "Sample 6120 - loss: 10.569594383239746\n",
      "Sample 6121 - loss: 0.9756630659103394\n",
      "Sample 6122 - loss: 7.282406806945801\n",
      "Sample 6123 - loss: 0.7887162566184998\n",
      "Sample 6124 - loss: 1.4043370485305786\n",
      "Sample 6125 - loss: 3.1469149589538574\n",
      "Sample 6126 - loss: 0.3625888526439667\n",
      "Sample 6127 - loss: 3.487381935119629\n",
      "Sample 6128 - loss: 1.596651315689087\n",
      "Sample 6129 - loss: 0.09575976431369781\n",
      "Sample 6130 - loss: 4.360607624053955\n",
      "Sample 6131 - loss: 3.6797964572906494\n",
      "Sample 6132 - loss: 0.1655634492635727\n",
      "Sample 6133 - loss: 9.114164352416992\n",
      "Sample 6134 - loss: 1.2962745428085327\n",
      "Sample 6135 - loss: 2.0121495723724365\n",
      "Sample 6136 - loss: 7.730342864990234\n",
      "Sample 6137 - loss: 2.695223093032837\n",
      "Sample 6138 - loss: 0.3988966643810272\n",
      "Sample 6139 - loss: 3.3839166164398193\n",
      "Sample 6140 - loss: 2.0747339725494385\n",
      "Sample 6141 - loss: 0.3267732262611389\n",
      "Sample 6142 - loss: 0.1387787014245987\n",
      "Sample 6143 - loss: 0.017694182693958282\n",
      "Sample 6144 - loss: 1.6243213415145874\n",
      "Sample 6145 - loss: 5.940591812133789\n",
      "Sample 6146 - loss: 0.5024896860122681\n",
      "Sample 6147 - loss: 7.962997913360596\n",
      "Sample 6148 - loss: 3.844907283782959\n",
      "Sample 6149 - loss: 0.13170988857746124\n",
      "Sample 6150 - loss: 2.4593753814697266\n",
      "Sample 6151 - loss: 3.358268976211548\n",
      "Sample 6152 - loss: 3.0671749114990234\n",
      "Sample 6153 - loss: 4.110286712646484\n",
      "Sample 6154 - loss: 5.4492506980896\n",
      "Sample 6155 - loss: 7.9741926193237305\n",
      "Sample 6156 - loss: 0.08225346356630325\n",
      "Sample 6157 - loss: 0.31942451000213623\n",
      "Sample 6158 - loss: 0.08862937986850739\n",
      "Sample 6159 - loss: 0.8784236311912537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6160 - loss: 4.699068069458008\n",
      "Sample 6161 - loss: 1.8439559936523438\n",
      "Sample 6162 - loss: 4.408613681793213\n",
      "Sample 6163 - loss: 0.08099689334630966\n",
      "Sample 6164 - loss: 8.734045028686523\n",
      "Sample 6165 - loss: 0.1656321883201599\n",
      "Sample 6166 - loss: 6.717243671417236\n",
      "Sample 6167 - loss: 1.2370480298995972\n",
      "Sample 6168 - loss: 0.3578942120075226\n",
      "Sample 6169 - loss: 0.8529826998710632\n",
      "Sample 6170 - loss: 6.104450702667236\n",
      "Sample 6171 - loss: 4.089847564697266\n",
      "Sample 6172 - loss: 0.8595786094665527\n",
      "Sample 6173 - loss: 0.15639819204807281\n",
      "Sample 6174 - loss: 0.08574599027633667\n",
      "Sample 6175 - loss: 2.1244924068450928\n",
      "Sample 6176 - loss: 6.812766075134277\n",
      "Sample 6177 - loss: 0.5391920804977417\n",
      "Sample 6178 - loss: 3.4915921688079834\n",
      "Sample 6179 - loss: 1.6671936511993408\n",
      "Sample 6180 - loss: 0.8543413281440735\n",
      "Sample 6181 - loss: 4.600345611572266\n",
      "Sample 6182 - loss: 0.08376138657331467\n",
      "Sample 6183 - loss: 1.203601360321045\n",
      "Sample 6184 - loss: 0.3049080967903137\n",
      "Sample 6185 - loss: 0.22909879684448242\n",
      "Sample 6186 - loss: 2.573046922683716\n",
      "Sample 6187 - loss: 2.8562088012695312\n",
      "Sample 6188 - loss: 0.04911482706665993\n",
      "Sample 6189 - loss: 7.768761157989502\n",
      "Sample 6190 - loss: 0.05094357952475548\n",
      "Sample 6191 - loss: 7.499898910522461\n",
      "Sample 6192 - loss: 6.252539157867432\n",
      "Sample 6193 - loss: 0.07777290046215057\n",
      "Sample 6194 - loss: 2.646409034729004\n",
      "Sample 6195 - loss: 7.986169815063477\n",
      "Sample 6196 - loss: 0.5302832126617432\n",
      "Sample 6197 - loss: 3.4240190982818604\n",
      "Sample 6198 - loss: 5.999846935272217\n",
      "Sample 6199 - loss: 0.2803158462047577\n",
      "Sample 6200 - loss: 1.2832776308059692\n",
      "Sample 6201 - loss: 4.336767673492432\n",
      "Sample 6202 - loss: 7.406129837036133\n",
      "Sample 6203 - loss: 8.493743896484375\n",
      "Sample 6204 - loss: 0.05846960470080376\n",
      "Sample 6205 - loss: 0.12029770761728287\n",
      "Sample 6206 - loss: 2.911404609680176\n",
      "Sample 6207 - loss: 1.9775116443634033\n",
      "Sample 6208 - loss: 1.2866015434265137\n",
      "Sample 6209 - loss: 0.727668046951294\n",
      "Sample 6210 - loss: 0.0625462457537651\n",
      "Sample 6211 - loss: 2.662351608276367\n",
      "Sample 6212 - loss: 6.63768196105957\n",
      "Sample 6213 - loss: 2.0010757446289062\n",
      "Sample 6214 - loss: 10.296095848083496\n",
      "Sample 6215 - loss: 4.7727274894714355\n",
      "Sample 6216 - loss: 3.5025086402893066\n",
      "Sample 6217 - loss: 0.08077879250049591\n",
      "Sample 6218 - loss: 5.94720458984375\n",
      "Sample 6219 - loss: 6.532485485076904\n",
      "Sample 6220 - loss: 0.9392910599708557\n",
      "Sample 6221 - loss: 1.2540680170059204\n",
      "Sample 6222 - loss: 0.08066876232624054\n",
      "Sample 6223 - loss: 0.003915046341717243\n",
      "Sample 6224 - loss: 10.156177520751953\n",
      "Sample 6225 - loss: 6.769550323486328\n",
      "Sample 6226 - loss: 0.48169657588005066\n",
      "Sample 6227 - loss: 2.6495306491851807\n",
      "Sample 6228 - loss: 0.33976298570632935\n",
      "Sample 6229 - loss: 1.1289620399475098\n",
      "Sample 6230 - loss: 2.8238587379455566\n",
      "Sample 6231 - loss: 4.892448902130127\n",
      "Sample 6232 - loss: 9.169963836669922\n",
      "Sample 6233 - loss: 6.305377960205078\n",
      "Sample 6234 - loss: 4.972209453582764\n",
      "Sample 6235 - loss: 2.9389569759368896\n",
      "Sample 6236 - loss: 0.5142823457717896\n",
      "Sample 6237 - loss: 1.4404208660125732\n",
      "Sample 6238 - loss: 0.6245728135108948\n",
      "Sample 6239 - loss: 1.2666661739349365\n",
      "Sample 6240 - loss: 1.0201632976531982\n",
      "Sample 6241 - loss: 1.038590431213379\n",
      "Sample 6242 - loss: 1.9273663759231567\n",
      "Sample 6243 - loss: 5.7636237144470215\n",
      "Sample 6244 - loss: 3.8526384830474854\n",
      "Sample 6245 - loss: 7.9098005294799805\n",
      "Sample 6246 - loss: 2.042289972305298\n",
      "Sample 6247 - loss: 2.9888014793395996\n",
      "Sample 6248 - loss: 0.7139257192611694\n",
      "Sample 6249 - loss: 0.024472318589687347\n",
      "Sample 6250 - loss: 2.2551331520080566\n",
      "Sample 6251 - loss: 2.6903250217437744\n",
      "Sample 6252 - loss: 1.2397856712341309\n",
      "Sample 6253 - loss: 4.986344814300537\n",
      "Sample 6254 - loss: 0.19337798655033112\n",
      "Sample 6255 - loss: 1.5671809911727905\n",
      "Sample 6256 - loss: 3.630669355392456\n",
      "Sample 6257 - loss: 7.973370552062988\n",
      "Sample 6258 - loss: 0.8728163242340088\n",
      "Sample 6259 - loss: 8.522275924682617\n",
      "Sample 6260 - loss: 0.6638014912605286\n",
      "Sample 6261 - loss: 2.472602128982544\n",
      "Sample 6262 - loss: 6.627580165863037\n",
      "Sample 6263 - loss: 1.7227174043655396\n",
      "Sample 6264 - loss: 0.4965898394584656\n",
      "Sample 6265 - loss: 1.0152835845947266\n",
      "Sample 6266 - loss: 2.174981117248535\n",
      "Sample 6267 - loss: 4.926912784576416\n",
      "Sample 6268 - loss: 5.997117519378662\n",
      "Sample 6269 - loss: 2.0013811588287354\n",
      "Sample 6270 - loss: 0.4705195724964142\n",
      "Sample 6271 - loss: 3.880361318588257\n",
      "Sample 6272 - loss: 0.0730876550078392\n",
      "Sample 6273 - loss: 0.007281823083758354\n",
      "Sample 6274 - loss: 0.8334287405014038\n",
      "Sample 6275 - loss: 2.109936475753784\n",
      "Sample 6276 - loss: 3.5598740577697754\n",
      "Sample 6277 - loss: 1.9327561855316162\n",
      "Sample 6278 - loss: 3.7553789615631104\n",
      "Sample 6279 - loss: 0.33126458525657654\n",
      "Sample 6280 - loss: 7.017533779144287\n",
      "Sample 6281 - loss: 10.551329612731934\n",
      "Sample 6282 - loss: 1.3144677877426147\n",
      "Sample 6283 - loss: 1.3962883949279785\n",
      "Sample 6284 - loss: 3.160346031188965\n",
      "Sample 6285 - loss: 6.601118087768555\n",
      "Sample 6286 - loss: 0.07837589085102081\n",
      "Sample 6287 - loss: 5.115538597106934\n",
      "Sample 6288 - loss: 2.384450912475586\n",
      "Sample 6289 - loss: 1.7381759881973267\n",
      "Sample 6290 - loss: 0.3572991192340851\n",
      "Sample 6291 - loss: 0.367725133895874\n",
      "Sample 6292 - loss: 0.29455968737602234\n",
      "Sample 6293 - loss: 0.08889090269804001\n",
      "Sample 6294 - loss: 5.126816272735596\n",
      "Sample 6295 - loss: 0.02591409534215927\n",
      "Sample 6296 - loss: 8.78332805633545\n",
      "Sample 6297 - loss: 3.8650548458099365\n",
      "Sample 6298 - loss: 1.84071683883667\n",
      "Sample 6299 - loss: 3.8255231380462646\n",
      "Sample 6300 - loss: 0.45704105496406555\n",
      "Sample 6301 - loss: 1.6157857179641724\n",
      "Sample 6302 - loss: 0.27124637365341187\n",
      "Sample 6303 - loss: 7.161032676696777\n",
      "Sample 6304 - loss: 0.3558739125728607\n",
      "Sample 6305 - loss: 2.0330610275268555\n",
      "Sample 6306 - loss: 0.9358961582183838\n",
      "Sample 6307 - loss: 6.393497467041016\n",
      "Sample 6308 - loss: 5.548938751220703\n",
      "Sample 6309 - loss: 0.0017411410808563232\n",
      "Sample 6310 - loss: 3.2155356407165527\n",
      "Sample 6311 - loss: 3.6986443996429443\n",
      "Sample 6312 - loss: 1.5325089693069458\n",
      "Sample 6313 - loss: 1.9600404500961304\n",
      "Sample 6314 - loss: 9.599570274353027\n",
      "Sample 6315 - loss: 1.289809226989746\n",
      "Sample 6316 - loss: 3.5870516300201416\n",
      "Sample 6317 - loss: 0.030230548232793808\n",
      "Sample 6318 - loss: 0.2867959141731262\n",
      "Sample 6319 - loss: 2.227106809616089\n",
      "Sample 6320 - loss: 0.2291676551103592\n",
      "Sample 6321 - loss: 4.859203338623047\n",
      "Sample 6322 - loss: 3.1769213676452637\n",
      "Sample 6323 - loss: 6.0804123878479\n",
      "Sample 6324 - loss: 2.559124231338501\n",
      "Sample 6325 - loss: 0.1174921989440918\n",
      "Sample 6326 - loss: 5.962079048156738\n",
      "Sample 6327 - loss: 4.907606601715088\n",
      "Sample 6328 - loss: 2.682664155960083\n",
      "Sample 6329 - loss: 6.696009635925293\n",
      "Sample 6330 - loss: 5.978836536407471\n",
      "Sample 6331 - loss: 3.1789050102233887\n",
      "Sample 6332 - loss: 2.1233553886413574\n",
      "Sample 6333 - loss: 5.695211410522461\n",
      "Sample 6334 - loss: 1.5719658136367798\n",
      "Sample 6335 - loss: 6.950922966003418\n",
      "Sample 6336 - loss: 1.6023080348968506\n",
      "Sample 6337 - loss: 1.8842134475708008\n",
      "Sample 6338 - loss: 2.7899487018585205\n",
      "Sample 6339 - loss: 5.738834381103516\n",
      "Sample 6340 - loss: 2.6853907108306885\n",
      "Sample 6341 - loss: 0.002517905319109559\n",
      "Sample 6342 - loss: 0.02266656421124935\n",
      "Sample 6343 - loss: 3.412410259246826\n",
      "Sample 6344 - loss: 2.746486186981201\n",
      "Sample 6345 - loss: 2.1036906242370605\n",
      "Sample 6346 - loss: 0.32091060280799866\n",
      "Sample 6347 - loss: 0.14607489109039307\n",
      "Sample 6348 - loss: 0.37112441658973694\n",
      "Sample 6349 - loss: 0.22362355887889862\n",
      "Sample 6350 - loss: 1.2919772863388062\n",
      "Sample 6351 - loss: 2.2360992431640625\n",
      "Sample 6352 - loss: 2.391096830368042\n",
      "Sample 6353 - loss: 5.551613807678223\n",
      "Sample 6354 - loss: 1.7918038368225098\n",
      "Sample 6355 - loss: 4.050454616546631\n",
      "Sample 6356 - loss: 0.04150741919875145\n",
      "Sample 6357 - loss: 7.021428108215332\n",
      "Sample 6358 - loss: 2.821732521057129\n",
      "Sample 6359 - loss: 6.785091400146484\n",
      "Sample 6360 - loss: 1.3591110706329346\n",
      "Sample 6361 - loss: 0.3428865671157837\n",
      "Sample 6362 - loss: 3.039539098739624\n",
      "Sample 6363 - loss: 0.321272611618042\n",
      "Sample 6364 - loss: 0.19762098789215088\n",
      "Sample 6365 - loss: 1.4332488775253296\n",
      "Sample 6366 - loss: 1.4847735166549683\n",
      "Sample 6367 - loss: 0.9607602953910828\n",
      "Sample 6368 - loss: 2.532252311706543\n",
      "Sample 6369 - loss: 1.0527312755584717\n",
      "Sample 6370 - loss: 7.512386322021484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6371 - loss: 0.4935416281223297\n",
      "Sample 6372 - loss: 4.6493611335754395\n",
      "Sample 6373 - loss: 7.753335475921631\n",
      "Sample 6374 - loss: 0.540151834487915\n",
      "Sample 6375 - loss: 6.98179817199707\n",
      "Sample 6376 - loss: 0.6876477599143982\n",
      "Sample 6377 - loss: 0.5841436982154846\n",
      "Sample 6378 - loss: 0.38821351528167725\n",
      "Sample 6379 - loss: 0.32125940918922424\n",
      "Sample 6380 - loss: 6.422905445098877\n",
      "Sample 6381 - loss: 1.8763600587844849\n",
      "Sample 6382 - loss: 1.7021081447601318\n",
      "Sample 6383 - loss: 0.054112508893013\n",
      "Sample 6384 - loss: 2.7864084243774414\n",
      "Sample 6385 - loss: 1.9277223348617554\n",
      "Sample 6386 - loss: 6.767810821533203\n",
      "Sample 6387 - loss: 0.6654064059257507\n",
      "Sample 6388 - loss: 1.3835369348526\n",
      "Sample 6389 - loss: 1.4049800634384155\n",
      "Sample 6390 - loss: 8.050588607788086\n",
      "Sample 6391 - loss: 5.412259578704834\n",
      "Sample 6392 - loss: 0.5070671439170837\n",
      "Sample 6393 - loss: 1.7240105867385864\n",
      "Sample 6394 - loss: 0.6082732677459717\n",
      "Sample 6395 - loss: 0.7592970132827759\n",
      "Sample 6396 - loss: 6.330278396606445\n",
      "Sample 6397 - loss: 7.424920558929443\n",
      "Sample 6398 - loss: 0.07747483998537064\n",
      "Sample 6399 - loss: 1.2821203470230103\n",
      "Sample 6400 - loss: 0.3218121826648712\n",
      "Sample 6401 - loss: 0.47484415769577026\n",
      "Sample 6402 - loss: 9.404823303222656\n",
      "Sample 6403 - loss: 1.9691991806030273\n",
      "Sample 6404 - loss: 8.329394340515137\n",
      "Sample 6405 - loss: 4.937240123748779\n",
      "Sample 6406 - loss: 0.611901044845581\n",
      "Sample 6407 - loss: 0.25139081478118896\n",
      "Sample 6408 - loss: 5.301213264465332\n",
      "Sample 6409 - loss: 7.210328578948975\n",
      "Sample 6410 - loss: 5.859823703765869\n",
      "Sample 6411 - loss: 4.8681206703186035\n",
      "Sample 6412 - loss: 1.6069108247756958\n",
      "Sample 6413 - loss: 0.15204741060733795\n",
      "Sample 6414 - loss: 7.545507907867432\n",
      "Sample 6415 - loss: 0.07432183623313904\n",
      "Sample 6416 - loss: 2.9457430839538574\n",
      "Sample 6417 - loss: 1.2030243873596191\n",
      "Sample 6418 - loss: 6.126156806945801\n",
      "Sample 6419 - loss: 6.2613959312438965\n",
      "Sample 6420 - loss: 0.059265702962875366\n",
      "Sample 6421 - loss: 0.3434159457683563\n",
      "Sample 6422 - loss: 5.954127788543701\n",
      "Sample 6423 - loss: 0.07510246336460114\n",
      "Sample 6424 - loss: 7.665210723876953\n",
      "Sample 6425 - loss: 0.017265604808926582\n",
      "Sample 6426 - loss: 0.0752185508608818\n",
      "Sample 6427 - loss: 6.364516735076904\n",
      "Sample 6428 - loss: 3.549666166305542\n",
      "Sample 6429 - loss: 2.0474977493286133\n",
      "Sample 6430 - loss: 0.019363654777407646\n",
      "Sample 6431 - loss: 1.4351849555969238\n",
      "Sample 6432 - loss: 3.2415173053741455\n",
      "Sample 6433 - loss: 2.352573871612549\n",
      "Sample 6434 - loss: 4.305157661437988\n",
      "Sample 6435 - loss: 3.18723201751709\n",
      "Sample 6436 - loss: 1.7566516399383545\n",
      "Sample 6437 - loss: 1.1138306856155396\n",
      "Sample 6438 - loss: 1.7478121519088745\n",
      "Sample 6439 - loss: 0.03247643634676933\n",
      "Sample 6440 - loss: 3.9563002586364746\n",
      "Sample 6441 - loss: 6.747317314147949\n",
      "Sample 6442 - loss: 9.16996955871582\n",
      "Sample 6443 - loss: 3.793994188308716\n",
      "Sample 6444 - loss: 5.269771575927734\n",
      "Sample 6445 - loss: 0.4212877154350281\n",
      "Sample 6446 - loss: 0.1515972763299942\n",
      "Sample 6447 - loss: 0.41460368037223816\n",
      "Sample 6448 - loss: 0.0942550003528595\n",
      "Sample 6449 - loss: 3.360200881958008\n",
      "Sample 6450 - loss: 5.376804351806641\n",
      "Sample 6451 - loss: 0.32017266750335693\n",
      "Sample 6452 - loss: 2.4360921382904053\n",
      "Sample 6453 - loss: 0.4337367117404938\n",
      "Sample 6454 - loss: 7.7190937995910645\n",
      "Sample 6455 - loss: 2.393346071243286\n",
      "Sample 6456 - loss: 0.0882134810090065\n",
      "Sample 6457 - loss: 0.8687030076980591\n",
      "Sample 6458 - loss: 3.764570713043213\n",
      "Sample 6459 - loss: 4.491210460662842\n",
      "Sample 6460 - loss: 1.1334542036056519\n",
      "Sample 6461 - loss: 0.10741963237524033\n",
      "Sample 6462 - loss: 6.363277435302734\n",
      "Sample 6463 - loss: 5.85650634765625\n",
      "Sample 6464 - loss: 2.3580710887908936\n",
      "Sample 6465 - loss: 7.4970622062683105\n",
      "Sample 6466 - loss: 3.7802200317382812\n",
      "Sample 6467 - loss: 0.1352819949388504\n",
      "Sample 6468 - loss: 2.9109041690826416\n",
      "Sample 6469 - loss: 5.464369297027588\n",
      "Sample 6470 - loss: 4.41326904296875\n",
      "Sample 6471 - loss: 10.595280647277832\n",
      "Sample 6472 - loss: 7.788763523101807\n",
      "Sample 6473 - loss: 0.6088019609451294\n",
      "Sample 6474 - loss: 3.8334238529205322\n",
      "Sample 6475 - loss: 2.287135601043701\n",
      "Sample 6476 - loss: 0.9863066077232361\n",
      "Sample 6477 - loss: 4.520803928375244\n",
      "Sample 6478 - loss: 3.9222116470336914\n",
      "Sample 6479 - loss: 8.884306907653809\n",
      "Sample 6480 - loss: 2.9102542400360107\n",
      "Sample 6481 - loss: 0.540158748626709\n",
      "Sample 6482 - loss: 9.095680236816406\n",
      "Sample 6483 - loss: 8.10600757598877\n",
      "Sample 6484 - loss: 3.627281904220581\n",
      "Sample 6485 - loss: 2.768409490585327\n",
      "Sample 6486 - loss: 0.36045682430267334\n",
      "Sample 6487 - loss: 0.35660144686698914\n",
      "Sample 6488 - loss: 0.10253430157899857\n",
      "Sample 6489 - loss: 0.005806905683130026\n",
      "Sample 6490 - loss: 4.1344990730285645\n",
      "Sample 6491 - loss: 0.112224280834198\n",
      "Sample 6492 - loss: 7.889975070953369\n",
      "Sample 6493 - loss: 6.2151336669921875\n",
      "Sample 6494 - loss: 5.796562671661377\n",
      "Sample 6495 - loss: 5.857532978057861\n",
      "Sample 6496 - loss: 0.20067737996578217\n",
      "Sample 6497 - loss: 0.1243019700050354\n",
      "Sample 6498 - loss: 1.1285529136657715\n",
      "Sample 6499 - loss: 0.32143914699554443\n",
      "Sample 6500 - loss: 0.45157110691070557\n",
      "Sample 6501 - loss: 1.6081639528274536\n",
      "Sample 6502 - loss: 8.146340370178223\n",
      "Sample 6503 - loss: 2.7246222496032715\n",
      "Sample 6504 - loss: 2.7743258476257324\n",
      "Sample 6505 - loss: 0.13463358581066132\n",
      "Sample 6506 - loss: 2.503401517868042\n",
      "Sample 6507 - loss: 1.1956586837768555\n",
      "Sample 6508 - loss: 7.184863090515137\n",
      "Sample 6509 - loss: 1.3963772058486938\n",
      "Sample 6510 - loss: 9.742682456970215\n",
      "Sample 6511 - loss: 4.369467735290527\n",
      "Sample 6512 - loss: 1.511655569076538\n",
      "Sample 6513 - loss: 1.167343020439148\n",
      "Sample 6514 - loss: 2.779022455215454\n",
      "Sample 6515 - loss: 5.477911472320557\n",
      "Sample 6516 - loss: 2.2181241512298584\n",
      "Sample 6517 - loss: 1.3467833995819092\n",
      "Sample 6518 - loss: 7.500298976898193\n",
      "Sample 6519 - loss: 4.796704292297363\n",
      "Sample 6520 - loss: 0.8320180773735046\n",
      "Sample 6521 - loss: 3.286900043487549\n",
      "Sample 6522 - loss: 0.15845927596092224\n",
      "Sample 6523 - loss: 3.375739812850952\n",
      "Sample 6524 - loss: 3.0999503135681152\n",
      "Sample 6525 - loss: 1.1423447132110596\n",
      "Sample 6526 - loss: 1.8750839233398438\n",
      "Sample 6527 - loss: 3.0388214588165283\n",
      "Sample 6528 - loss: 6.967272758483887\n",
      "Sample 6529 - loss: 0.9722588062286377\n",
      "Sample 6530 - loss: 1.6188937425613403\n",
      "Sample 6531 - loss: 0.4206616282463074\n",
      "Sample 6532 - loss: 3.4975292682647705\n",
      "Sample 6533 - loss: 6.781016826629639\n",
      "Sample 6534 - loss: 3.9483706951141357\n",
      "Sample 6535 - loss: 9.023082733154297\n",
      "Sample 6536 - loss: 6.576779842376709\n",
      "Sample 6537 - loss: 2.7794806957244873\n",
      "Sample 6538 - loss: 4.693328857421875\n",
      "Sample 6539 - loss: 1.2837975025177002\n",
      "Sample 6540 - loss: 4.293523788452148\n",
      "Sample 6541 - loss: 7.157783031463623\n",
      "Sample 6542 - loss: 6.16557502746582\n",
      "Sample 6543 - loss: 1.6574492454528809\n",
      "Sample 6544 - loss: 0.93778395652771\n",
      "Sample 6545 - loss: 6.578481674194336\n",
      "Sample 6546 - loss: 0.2310255616903305\n",
      "Sample 6547 - loss: 1.4927761554718018\n",
      "Sample 6548 - loss: 0.12619948387145996\n",
      "Sample 6549 - loss: 2.7917261123657227\n",
      "Sample 6550 - loss: 5.993985176086426\n",
      "Sample 6551 - loss: 0.04975907877087593\n",
      "Sample 6552 - loss: 5.534029483795166\n",
      "Sample 6553 - loss: 0.6246201395988464\n",
      "Sample 6554 - loss: 0.01924041472375393\n",
      "Sample 6555 - loss: 0.7501446604728699\n",
      "Sample 6556 - loss: 0.6336516737937927\n",
      "Sample 6557 - loss: 9.942646980285645\n",
      "Sample 6558 - loss: 7.848715782165527\n",
      "Sample 6559 - loss: 1.8966968059539795\n",
      "Sample 6560 - loss: 6.357254505157471\n",
      "Sample 6561 - loss: 0.3406938910484314\n",
      "Sample 6562 - loss: 8.629356384277344\n",
      "Sample 6563 - loss: 0.014324265532195568\n",
      "Sample 6564 - loss: 1.6434952020645142\n",
      "Sample 6565 - loss: 5.491713047027588\n",
      "Sample 6566 - loss: 0.006264392752200365\n",
      "Sample 6567 - loss: 5.113838195800781\n",
      "Sample 6568 - loss: 0.8052201867103577\n",
      "Sample 6569 - loss: 8.716409683227539\n",
      "Sample 6570 - loss: 1.7149769067764282\n",
      "Sample 6571 - loss: 2.9535093307495117\n",
      "Sample 6572 - loss: 4.756199359893799\n",
      "Sample 6573 - loss: 8.469292640686035\n",
      "Sample 6574 - loss: 5.671236038208008\n",
      "Sample 6575 - loss: 3.961948871612549\n",
      "Sample 6576 - loss: 0.03895188122987747\n",
      "Sample 6577 - loss: 0.9686580896377563\n",
      "Sample 6578 - loss: 0.1472889930009842\n",
      "Sample 6579 - loss: 5.3728132247924805\n",
      "Sample 6580 - loss: 1.1798720359802246\n",
      "Sample 6581 - loss: 6.744866371154785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6582 - loss: 4.063327312469482\n",
      "Sample 6583 - loss: 1.6529258489608765\n",
      "Sample 6584 - loss: 0.17630231380462646\n",
      "Sample 6585 - loss: 8.736261367797852\n",
      "Sample 6586 - loss: 3.7759737968444824\n",
      "Sample 6587 - loss: 7.75344181060791\n",
      "Sample 6588 - loss: 6.102630138397217\n",
      "Sample 6589 - loss: 7.519289016723633\n",
      "Sample 6590 - loss: 0.5181826949119568\n",
      "Sample 6591 - loss: 5.508260726928711\n",
      "Sample 6592 - loss: 1.0952216386795044\n",
      "Sample 6593 - loss: 0.7977900505065918\n",
      "Sample 6594 - loss: 7.589993953704834\n",
      "Sample 6595 - loss: 1.0574527978897095\n",
      "Sample 6596 - loss: 6.091337203979492\n",
      "Sample 6597 - loss: 7.63702392578125\n",
      "Sample 6598 - loss: 4.1278300285339355\n",
      "Sample 6599 - loss: 4.83108377456665\n",
      "Sample 6600 - loss: 1.0756878852844238\n",
      "Sample 6601 - loss: 6.016512870788574\n",
      "Sample 6602 - loss: 2.1697380542755127\n",
      "Sample 6603 - loss: 4.772522926330566\n",
      "Sample 6604 - loss: 2.633612871170044\n",
      "Sample 6605 - loss: 3.20204496383667\n",
      "Sample 6606 - loss: 7.727748870849609\n",
      "Sample 6607 - loss: 6.419852256774902\n",
      "Sample 6608 - loss: 0.3843387961387634\n",
      "Sample 6609 - loss: 0.050955306738615036\n",
      "Sample 6610 - loss: 7.446534633636475\n",
      "Sample 6611 - loss: 5.825489044189453\n",
      "Sample 6612 - loss: 1.3949278593063354\n",
      "Sample 6613 - loss: 2.995344877243042\n",
      "Sample 6614 - loss: 2.266409158706665\n",
      "Sample 6615 - loss: 2.2342615127563477\n",
      "Sample 6616 - loss: 1.8446218967437744\n",
      "Sample 6617 - loss: 4.807391166687012\n",
      "Sample 6618 - loss: 2.2350029945373535\n",
      "Sample 6619 - loss: 3.1010265350341797\n",
      "Sample 6620 - loss: 0.9359771013259888\n",
      "Sample 6621 - loss: 4.261252403259277\n",
      "Sample 6622 - loss: 0.028360523283481598\n",
      "Sample 6623 - loss: 1.9415000677108765\n",
      "Sample 6624 - loss: 6.752123832702637\n",
      "Sample 6625 - loss: 8.199426651000977\n",
      "Sample 6626 - loss: 0.13959364593029022\n",
      "Sample 6627 - loss: 0.06257586181163788\n",
      "Sample 6628 - loss: 0.025356238707900047\n",
      "Sample 6629 - loss: 1.0955798625946045\n",
      "Sample 6630 - loss: 0.29095444083213806\n",
      "Sample 6631 - loss: 7.265042781829834\n",
      "Sample 6632 - loss: 0.025059038773179054\n",
      "Sample 6633 - loss: 3.6275246143341064\n",
      "Sample 6634 - loss: 2.0949020385742188\n",
      "Sample 6635 - loss: 0.6080050468444824\n",
      "Sample 6636 - loss: 5.155345916748047\n",
      "Sample 6637 - loss: 8.784832000732422\n",
      "Sample 6638 - loss: 0.4023713767528534\n",
      "Sample 6639 - loss: 0.26602575182914734\n",
      "Sample 6640 - loss: 6.627788066864014\n",
      "Sample 6641 - loss: 2.411436080932617\n",
      "Sample 6642 - loss: 1.515091896057129\n",
      "Sample 6643 - loss: 7.998683452606201\n",
      "Sample 6644 - loss: 0.3710183799266815\n",
      "Sample 6645 - loss: 1.8033878803253174\n",
      "Sample 6646 - loss: 4.8093485832214355\n",
      "Sample 6647 - loss: 6.481252670288086\n",
      "Sample 6648 - loss: 0.29218482971191406\n",
      "Sample 6649 - loss: 0.9680290818214417\n",
      "Sample 6650 - loss: 6.664607524871826\n",
      "Sample 6651 - loss: 3.3836557865142822\n",
      "Sample 6652 - loss: 1.5187891721725464\n",
      "Sample 6653 - loss: 0.07651928067207336\n",
      "Sample 6654 - loss: 2.0081164836883545\n",
      "Sample 6655 - loss: 0.5661614537239075\n",
      "Sample 6656 - loss: 0.8411105275154114\n",
      "Sample 6657 - loss: 0.8563376665115356\n",
      "Sample 6658 - loss: 6.853374004364014\n",
      "Sample 6659 - loss: 1.7921005487442017\n",
      "Sample 6660 - loss: 6.461155891418457\n",
      "Sample 6661 - loss: 2.4251604080200195\n",
      "Sample 6662 - loss: 7.985333442687988\n",
      "Sample 6663 - loss: 0.8381235003471375\n",
      "Sample 6664 - loss: 0.5078150033950806\n",
      "Sample 6665 - loss: 6.381389141082764\n",
      "Sample 6666 - loss: 6.566725254058838\n",
      "Sample 6667 - loss: 7.185976028442383\n",
      "Sample 6668 - loss: 2.9556262493133545\n",
      "Sample 6669 - loss: 0.009968279860913754\n",
      "Sample 6670 - loss: 6.88121223449707\n",
      "Sample 6671 - loss: 6.621120452880859\n",
      "Sample 6672 - loss: 5.125769138336182\n",
      "Sample 6673 - loss: 0.3908862769603729\n",
      "Sample 6674 - loss: 0.5503171682357788\n",
      "Sample 6675 - loss: 0.028493328019976616\n",
      "Sample 6676 - loss: 0.01965329982340336\n",
      "Sample 6677 - loss: 1.4890012741088867\n",
      "Sample 6678 - loss: 0.11948335915803909\n",
      "Sample 6679 - loss: 5.785478115081787\n",
      "Sample 6680 - loss: 6.325064659118652\n",
      "Sample 6681 - loss: 1.0681581497192383\n",
      "Sample 6682 - loss: 0.16709519922733307\n",
      "Sample 6683 - loss: 1.3764811754226685\n",
      "Sample 6684 - loss: 5.979581832885742\n",
      "Sample 6685 - loss: 0.5764926075935364\n",
      "Sample 6686 - loss: 0.07320967316627502\n",
      "Sample 6687 - loss: 1.4766987562179565\n",
      "Sample 6688 - loss: 4.555786609649658\n",
      "Sample 6689 - loss: 6.113613128662109\n",
      "Sample 6690 - loss: 0.528317391872406\n",
      "Sample 6691 - loss: 0.6388096809387207\n",
      "Sample 6692 - loss: 1.0569669008255005\n",
      "Sample 6693 - loss: 8.047784805297852\n",
      "Sample 6694 - loss: 2.8489270210266113\n",
      "Sample 6695 - loss: 4.421438694000244\n",
      "Sample 6696 - loss: 2.588486909866333\n",
      "Sample 6697 - loss: 1.7183929681777954\n",
      "Sample 6698 - loss: 1.3701834678649902\n",
      "Sample 6699 - loss: 3.6649017333984375\n",
      "Sample 6700 - loss: 2.068124294281006\n",
      "Sample 6701 - loss: 8.344768524169922\n",
      "Sample 6702 - loss: 5.724536895751953\n",
      "Sample 6703 - loss: 2.53251314163208\n",
      "Sample 6704 - loss: 10.749578475952148\n",
      "Sample 6705 - loss: 3.9500765800476074\n",
      "Sample 6706 - loss: 0.18744774162769318\n",
      "Sample 6707 - loss: 3.278033494949341\n",
      "Sample 6708 - loss: 0.8344619274139404\n",
      "Sample 6709 - loss: 2.1593892574310303\n",
      "Sample 6710 - loss: 1.704892635345459\n",
      "Sample 6711 - loss: 0.6341694593429565\n",
      "Sample 6712 - loss: 4.470253944396973\n",
      "Sample 6713 - loss: 0.39047566056251526\n",
      "Sample 6714 - loss: 2.8737282752990723\n",
      "Sample 6715 - loss: 2.3247580528259277\n",
      "Sample 6716 - loss: 3.3356521129608154\n",
      "Sample 6717 - loss: 3.250922918319702\n",
      "Sample 6718 - loss: 3.674243211746216\n",
      "Sample 6719 - loss: 6.557960033416748\n",
      "Sample 6720 - loss: 0.03399407118558884\n",
      "Sample 6721 - loss: 3.6562345027923584\n",
      "Sample 6722 - loss: 3.0716772079467773\n",
      "Sample 6723 - loss: 0.26286038756370544\n",
      "Sample 6724 - loss: 1.2274010181427002\n",
      "Sample 6725 - loss: 0.20652996003627777\n",
      "Sample 6726 - loss: 5.784905433654785\n",
      "Sample 6727 - loss: 1.1858069896697998\n",
      "Sample 6728 - loss: 6.8475189208984375\n",
      "Sample 6729 - loss: 1.0018330812454224\n",
      "Sample 6730 - loss: 0.2259402722120285\n",
      "Sample 6731 - loss: 1.2465260028839111\n",
      "Sample 6732 - loss: 5.614793300628662\n",
      "Sample 6733 - loss: 2.0139055252075195\n",
      "Sample 6734 - loss: 1.1058006286621094\n",
      "Sample 6735 - loss: 0.7575179934501648\n",
      "Sample 6736 - loss: 6.993258476257324\n",
      "Sample 6737 - loss: 3.0098161697387695\n",
      "Sample 6738 - loss: 0.6742324233055115\n",
      "Sample 6739 - loss: 3.0576937198638916\n",
      "Sample 6740 - loss: 1.234090805053711\n",
      "Sample 6741 - loss: 4.776639461517334\n",
      "Sample 6742 - loss: 1.7752891778945923\n",
      "Sample 6743 - loss: 3.238896369934082\n",
      "Sample 6744 - loss: 2.051591396331787\n",
      "Sample 6745 - loss: 2.7411458492279053\n",
      "Sample 6746 - loss: 3.0717363357543945\n",
      "Sample 6747 - loss: 4.957334518432617\n",
      "Sample 6748 - loss: 0.08484339714050293\n",
      "Sample 6749 - loss: 0.23326273262500763\n",
      "Sample 6750 - loss: 1.7299364805221558\n",
      "Sample 6751 - loss: 1.8650288581848145\n",
      "Sample 6752 - loss: 0.08957748115062714\n",
      "Sample 6753 - loss: 0.004845003597438335\n",
      "Sample 6754 - loss: 3.237445592880249\n",
      "Sample 6755 - loss: 3.4281673431396484\n",
      "Sample 6756 - loss: 0.0229563657194376\n",
      "Sample 6757 - loss: 0.10549430549144745\n",
      "Sample 6758 - loss: 2.301539659500122\n",
      "Sample 6759 - loss: 1.066939115524292\n",
      "Sample 6760 - loss: 7.948580265045166\n",
      "Sample 6761 - loss: 7.254710674285889\n",
      "Sample 6762 - loss: 6.865083694458008\n",
      "Sample 6763 - loss: 2.4314932823181152\n",
      "Sample 6764 - loss: 1.1688194274902344\n",
      "Sample 6765 - loss: 4.180335998535156\n",
      "Sample 6766 - loss: 0.02562694065272808\n",
      "Sample 6767 - loss: 7.5626420974731445\n",
      "Sample 6768 - loss: 2.365819215774536\n",
      "Sample 6769 - loss: 4.957083225250244\n",
      "Sample 6770 - loss: 2.0341196060180664\n",
      "Sample 6771 - loss: 3.8441643714904785\n",
      "Sample 6772 - loss: 3.476837158203125\n",
      "Sample 6773 - loss: 2.355811834335327\n",
      "Sample 6774 - loss: 3.3390841484069824\n",
      "Sample 6775 - loss: 6.563047885894775\n",
      "Sample 6776 - loss: 2.8730592727661133\n",
      "Sample 6777 - loss: 4.741362571716309\n",
      "Sample 6778 - loss: 2.22160267829895\n",
      "Sample 6779 - loss: 6.134232997894287\n",
      "Sample 6780 - loss: 3.58343505859375\n",
      "Sample 6781 - loss: 5.043325424194336\n",
      "Sample 6782 - loss: 2.3186373710632324\n",
      "Sample 6783 - loss: 3.5749518871307373\n",
      "Sample 6784 - loss: 1.5038801431655884\n",
      "Sample 6785 - loss: 6.107663631439209\n",
      "Sample 6786 - loss: 2.8163764476776123\n",
      "Sample 6787 - loss: 1.417218804359436\n",
      "Sample 6788 - loss: 2.447340726852417\n",
      "Sample 6789 - loss: 0.6842872500419617\n",
      "Sample 6790 - loss: 0.7172039747238159\n",
      "Sample 6791 - loss: 0.4837173819541931\n",
      "Sample 6792 - loss: 0.841693103313446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6793 - loss: 0.37505072355270386\n",
      "Sample 6794 - loss: 1.7827948331832886\n",
      "Sample 6795 - loss: 8.422574043273926\n",
      "Sample 6796 - loss: 7.862325668334961\n",
      "Sample 6797 - loss: 0.3479045629501343\n",
      "Sample 6798 - loss: 2.7018191814422607\n",
      "Sample 6799 - loss: 3.4924585819244385\n",
      "Sample 6800 - loss: 2.051316022872925\n",
      "Sample 6801 - loss: 0.7426549792289734\n",
      "Sample 6802 - loss: 0.6731424927711487\n",
      "Sample 6803 - loss: 4.345933437347412\n",
      "Sample 6804 - loss: 1.8931634426116943\n",
      "Sample 6805 - loss: 6.810971736907959\n",
      "Sample 6806 - loss: 5.1638312339782715\n",
      "Sample 6807 - loss: 0.10024340450763702\n",
      "Sample 6808 - loss: 2.2381386756896973\n",
      "Sample 6809 - loss: 1.9146801233291626\n",
      "Sample 6810 - loss: 0.7259458899497986\n",
      "Sample 6811 - loss: 8.212409019470215\n",
      "Sample 6812 - loss: 9.303218841552734\n",
      "Sample 6813 - loss: 3.0169544219970703\n",
      "Sample 6814 - loss: 6.643243789672852\n",
      "Sample 6815 - loss: 5.545319080352783\n",
      "Sample 6816 - loss: 3.67012095451355\n",
      "Sample 6817 - loss: 4.846198558807373\n",
      "Sample 6818 - loss: 6.294646739959717\n",
      "Sample 6819 - loss: 1.9211784601211548\n",
      "Sample 6820 - loss: 1.1017788648605347\n",
      "Sample 6821 - loss: 3.164633274078369\n",
      "Sample 6822 - loss: 0.015601246617734432\n",
      "Sample 6823 - loss: 5.4815754890441895\n",
      "Sample 6824 - loss: 1.599746584892273\n",
      "Sample 6825 - loss: 9.189764022827148\n",
      "Sample 6826 - loss: 0.6158828139305115\n",
      "Sample 6827 - loss: 0.47486555576324463\n",
      "Sample 6828 - loss: 0.42110690474510193\n",
      "Sample 6829 - loss: 8.736248016357422\n",
      "Sample 6830 - loss: 0.7609356641769409\n",
      "Sample 6831 - loss: 2.462251663208008\n",
      "Sample 6832 - loss: 7.895380973815918\n",
      "Sample 6833 - loss: 0.8128781318664551\n",
      "Sample 6834 - loss: 5.287538051605225\n",
      "Sample 6835 - loss: 0.3010748624801636\n",
      "Sample 6836 - loss: 0.0878266990184784\n",
      "Sample 6837 - loss: 2.1991541385650635\n",
      "Sample 6838 - loss: 1.5475941896438599\n",
      "Sample 6839 - loss: 2.032038927078247\n",
      "Sample 6840 - loss: 4.97226095199585\n",
      "Sample 6841 - loss: 1.8443238735198975\n",
      "Sample 6842 - loss: 7.786905288696289\n",
      "Sample 6843 - loss: 0.1527215540409088\n",
      "Sample 6844 - loss: 0.1482086181640625\n",
      "Sample 6845 - loss: 0.18988117575645447\n",
      "Sample 6846 - loss: 5.2426276206970215\n",
      "Sample 6847 - loss: 5.931695938110352\n",
      "Sample 6848 - loss: 4.35105037689209\n",
      "Sample 6849 - loss: 0.3698213994503021\n",
      "Sample 6850 - loss: 5.857542514801025\n",
      "Sample 6851 - loss: 4.5712971687316895\n",
      "Sample 6852 - loss: 2.2944700717926025\n",
      "Sample 6853 - loss: 4.4041852951049805\n",
      "Sample 6854 - loss: 0.27389416098594666\n",
      "Sample 6855 - loss: 4.494524955749512\n",
      "Sample 6856 - loss: 4.902141571044922\n",
      "Sample 6857 - loss: 1.4933737516403198\n",
      "Sample 6858 - loss: 7.516916275024414\n",
      "Sample 6859 - loss: 0.2449822872877121\n",
      "Sample 6860 - loss: 0.4476638436317444\n",
      "Sample 6861 - loss: 0.4960732161998749\n",
      "Sample 6862 - loss: 4.102632522583008\n",
      "Sample 6863 - loss: 3.2669525146484375\n",
      "Sample 6864 - loss: 9.355679512023926\n",
      "Sample 6865 - loss: 0.23521219193935394\n",
      "Sample 6866 - loss: 7.256532192230225\n",
      "Sample 6867 - loss: 2.596660852432251\n",
      "Sample 6868 - loss: 6.734647274017334\n",
      "Sample 6869 - loss: 0.055866390466690063\n",
      "Sample 6870 - loss: 1.9582017660140991\n",
      "Sample 6871 - loss: 2.4364771842956543\n",
      "Sample 6872 - loss: 5.379522800445557\n",
      "Sample 6873 - loss: 7.242658615112305\n",
      "Sample 6874 - loss: 0.4324468672275543\n",
      "Sample 6875 - loss: 7.2376909255981445\n",
      "Sample 6876 - loss: 6.7603044509887695\n",
      "Sample 6877 - loss: 1.7061505317687988\n",
      "Sample 6878 - loss: 0.1434062421321869\n",
      "Sample 6879 - loss: 4.563944339752197\n",
      "Sample 6880 - loss: 2.7080953121185303\n",
      "Sample 6881 - loss: 4.669355392456055\n",
      "Sample 6882 - loss: 5.150540351867676\n",
      "Sample 6883 - loss: 6.557006359100342\n",
      "Sample 6884 - loss: 5.98427677154541\n",
      "Sample 6885 - loss: 0.030864737927913666\n",
      "Sample 6886 - loss: 0.30995309352874756\n",
      "Sample 6887 - loss: 0.6581668257713318\n",
      "Sample 6888 - loss: 1.9499150514602661\n",
      "Sample 6889 - loss: 0.6633090972900391\n",
      "Sample 6890 - loss: 0.06400243937969208\n",
      "Sample 6891 - loss: 2.5994112491607666\n",
      "Sample 6892 - loss: 0.31881043314933777\n",
      "Sample 6893 - loss: 0.022494511678814888\n",
      "Sample 6894 - loss: 3.6415960788726807\n",
      "Sample 6895 - loss: 3.4045541286468506\n",
      "Sample 6896 - loss: 0.6252579092979431\n",
      "Sample 6897 - loss: 0.8639675378799438\n",
      "Sample 6898 - loss: 2.841498613357544\n",
      "Sample 6899 - loss: 0.029423534870147705\n",
      "Sample 6900 - loss: 3.5192787647247314\n",
      "Sample 6901 - loss: 4.669082164764404\n",
      "Sample 6902 - loss: 3.397958755493164\n",
      "Sample 6903 - loss: 1.4403572082519531\n",
      "Sample 6904 - loss: 2.676579475402832\n",
      "Sample 6905 - loss: 3.761789321899414\n",
      "Sample 6906 - loss: 1.7364834547042847\n",
      "Sample 6907 - loss: 0.6799106597900391\n",
      "Sample 6908 - loss: 3.104820966720581\n",
      "Sample 6909 - loss: 0.6321249604225159\n",
      "Sample 6910 - loss: 0.14225426316261292\n",
      "Sample 6911 - loss: 1.4025239944458008\n",
      "Sample 6912 - loss: 4.680293560028076\n",
      "Sample 6913 - loss: 3.5428292751312256\n",
      "Sample 6914 - loss: 1.131548523902893\n",
      "Sample 6915 - loss: 6.721663951873779\n",
      "Sample 6916 - loss: 5.923852920532227\n",
      "Sample 6917 - loss: 0.39418724179267883\n",
      "Sample 6918 - loss: 6.231207370758057\n",
      "Sample 6919 - loss: 6.111015796661377\n",
      "Sample 6920 - loss: 4.567867279052734\n",
      "Sample 6921 - loss: 1.6223200559616089\n",
      "Sample 6922 - loss: 0.015225183218717575\n",
      "Sample 6923 - loss: 0.315603107213974\n",
      "Sample 6924 - loss: 6.977608680725098\n",
      "Sample 6925 - loss: 5.119241237640381\n",
      "Sample 6926 - loss: 4.876978874206543\n",
      "Sample 6927 - loss: 1.5564651489257812\n",
      "Sample 6928 - loss: 0.21775197982788086\n",
      "Sample 6929 - loss: 5.407928466796875\n",
      "Sample 6930 - loss: 0.5102860927581787\n",
      "Sample 6931 - loss: 0.8428075313568115\n",
      "Sample 6932 - loss: 7.8110527992248535\n",
      "Sample 6933 - loss: 0.352420449256897\n",
      "Sample 6934 - loss: 7.300881862640381\n",
      "Sample 6935 - loss: 7.199013710021973\n",
      "Sample 6936 - loss: 3.8325133323669434\n",
      "Sample 6937 - loss: 3.890343427658081\n",
      "Sample 6938 - loss: 2.914700984954834\n",
      "Sample 6939 - loss: 8.360247611999512\n",
      "Sample 6940 - loss: 1.4474897384643555\n",
      "Sample 6941 - loss: 1.6947965621948242\n",
      "Sample 6942 - loss: 1.8885220289230347\n",
      "Sample 6943 - loss: 3.721766710281372\n",
      "Sample 6944 - loss: 2.8750011920928955\n",
      "Sample 6945 - loss: 5.306376934051514\n",
      "Sample 6946 - loss: 0.27208563685417175\n",
      "Sample 6947 - loss: 0.42385417222976685\n",
      "Sample 6948 - loss: 0.6376899480819702\n",
      "Sample 6949 - loss: 2.5678904056549072\n",
      "Sample 6950 - loss: 0.8503364324569702\n",
      "Sample 6951 - loss: 0.7257341742515564\n",
      "Sample 6952 - loss: 8.554296493530273\n",
      "Sample 6953 - loss: 1.0705246925354004\n",
      "Sample 6954 - loss: 7.288727283477783\n",
      "Sample 6955 - loss: 3.3777997493743896\n",
      "Sample 6956 - loss: 7.148422718048096\n",
      "Sample 6957 - loss: 3.2616934776306152\n",
      "Sample 6958 - loss: 1.3113982677459717\n",
      "Sample 6959 - loss: 6.612186908721924\n",
      "Sample 6960 - loss: 1.269102692604065\n",
      "Sample 6961 - loss: 0.08332648128271103\n",
      "Sample 6962 - loss: 1.044283390045166\n",
      "Sample 6963 - loss: 5.36483907699585\n",
      "Sample 6964 - loss: 0.222383514046669\n",
      "Sample 6965 - loss: 0.8170212507247925\n",
      "Sample 6966 - loss: 0.07850075513124466\n",
      "Sample 6967 - loss: 0.1852034032344818\n",
      "Sample 6968 - loss: 4.9105963706970215\n",
      "Sample 6969 - loss: 2.6711575984954834\n",
      "Sample 6970 - loss: 0.47170326113700867\n",
      "Sample 6971 - loss: 0.08513591438531876\n",
      "Sample 6972 - loss: 1.9504905939102173\n",
      "Sample 6973 - loss: 0.051527127623558044\n",
      "Sample 6974 - loss: 3.0424611568450928\n",
      "Sample 6975 - loss: 3.5606839656829834\n",
      "Sample 6976 - loss: 1.7919490337371826\n",
      "Sample 6977 - loss: 0.7863223552703857\n",
      "Sample 6978 - loss: 5.2692084312438965\n",
      "Sample 6979 - loss: 7.5588603019714355\n",
      "Sample 6980 - loss: 4.732631683349609\n",
      "Sample 6981 - loss: 0.6651065945625305\n",
      "Sample 6982 - loss: 0.2320130467414856\n",
      "Sample 6983 - loss: 0.05266239121556282\n",
      "Sample 6984 - loss: 1.920628547668457\n",
      "Sample 6985 - loss: 0.0027069493662565947\n",
      "Sample 6986 - loss: 7.780300140380859\n",
      "Sample 6987 - loss: 3.3152804374694824\n",
      "Sample 6988 - loss: 0.31145983934402466\n",
      "Sample 6989 - loss: 4.572714328765869\n",
      "Sample 6990 - loss: 0.7227030992507935\n",
      "Sample 6991 - loss: 1.457924485206604\n",
      "Sample 6992 - loss: 6.437503814697266\n",
      "Sample 6993 - loss: 4.690232753753662\n",
      "Sample 6994 - loss: 3.0208017826080322\n",
      "Sample 6995 - loss: 0.47463855147361755\n",
      "Sample 6996 - loss: 2.782111883163452\n",
      "Sample 6997 - loss: 1.590482473373413\n",
      "Sample 6998 - loss: 3.525275230407715\n",
      "Sample 6999 - loss: 0.414095014333725\n",
      "Sample 7000 - loss: 0.3980358839035034\n",
      "Sample 7001 - loss: 9.975138664245605\n",
      "Sample 7002 - loss: 0.007292566820979118\n",
      "Sample 7003 - loss: 1.8161920309066772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7004 - loss: 0.5127984881401062\n",
      "Sample 7005 - loss: 6.711535453796387\n",
      "Sample 7006 - loss: 0.8395031690597534\n",
      "Sample 7007 - loss: 4.871967792510986\n",
      "Sample 7008 - loss: 3.896951913833618\n",
      "Sample 7009 - loss: 7.172264575958252\n",
      "Sample 7010 - loss: 3.4696249961853027\n",
      "Sample 7011 - loss: 4.125284671783447\n",
      "Sample 7012 - loss: 2.6015126705169678\n",
      "Sample 7013 - loss: 0.34061935544013977\n",
      "Sample 7014 - loss: 7.342222213745117\n",
      "Sample 7015 - loss: 2.3811614513397217\n",
      "Sample 7016 - loss: 6.111218452453613\n",
      "Sample 7017 - loss: 4.604427337646484\n",
      "Sample 7018 - loss: 0.11081399768590927\n",
      "Sample 7019 - loss: 0.29640698432922363\n",
      "Sample 7020 - loss: 6.273463726043701\n",
      "Sample 7021 - loss: 3.3217544555664062\n",
      "Sample 7022 - loss: 0.32511797547340393\n",
      "Sample 7023 - loss: 1.2690341472625732\n",
      "Sample 7024 - loss: 1.5152745246887207\n",
      "Sample 7025 - loss: 2.273024559020996\n",
      "Sample 7026 - loss: 0.018933916464447975\n",
      "Sample 7027 - loss: 7.649655818939209\n",
      "Sample 7028 - loss: 4.724937915802002\n",
      "Sample 7029 - loss: 1.4886736869812012\n",
      "Sample 7030 - loss: 0.875732958316803\n",
      "Sample 7031 - loss: 0.075288787484169\n",
      "Sample 7032 - loss: 1.3543219566345215\n",
      "Sample 7033 - loss: 0.011244885623455048\n",
      "Sample 7034 - loss: 0.5196698307991028\n",
      "Sample 7035 - loss: 0.04115234687924385\n",
      "Sample 7036 - loss: 1.8735333681106567\n",
      "Sample 7037 - loss: 1.1186614036560059\n",
      "Sample 7038 - loss: 1.6386516094207764\n",
      "Sample 7039 - loss: 3.897282600402832\n",
      "Sample 7040 - loss: 2.370007276535034\n",
      "Sample 7041 - loss: 1.5055930614471436\n",
      "Sample 7042 - loss: 6.474422454833984\n",
      "Sample 7043 - loss: 0.951732337474823\n",
      "Sample 7044 - loss: 0.25139886140823364\n",
      "Sample 7045 - loss: 7.175088882446289\n",
      "Sample 7046 - loss: 2.1438071727752686\n",
      "Sample 7047 - loss: 1.8886477947235107\n",
      "Sample 7048 - loss: 0.4113805890083313\n",
      "Sample 7049 - loss: 5.514325141906738\n",
      "Sample 7050 - loss: 4.423064231872559\n",
      "Sample 7051 - loss: 5.949926376342773\n",
      "Sample 7052 - loss: 2.042567253112793\n",
      "Sample 7053 - loss: 2.1346659660339355\n",
      "Sample 7054 - loss: 4.186075210571289\n",
      "Sample 7055 - loss: 3.1254384517669678\n",
      "Sample 7056 - loss: 2.9003777503967285\n",
      "Sample 7057 - loss: 1.6989091634750366\n",
      "Sample 7058 - loss: 8.621298789978027\n",
      "Sample 7059 - loss: 0.6877473592758179\n",
      "Sample 7060 - loss: 0.10642950981855392\n",
      "Sample 7061 - loss: 5.931008815765381\n",
      "Sample 7062 - loss: 4.99120569229126\n",
      "Sample 7063 - loss: 3.371849298477173\n",
      "Sample 7064 - loss: 3.7557566165924072\n",
      "Sample 7065 - loss: 5.613167762756348\n",
      "Sample 7066 - loss: 5.224001407623291\n",
      "Sample 7067 - loss: 3.51557993888855\n",
      "Sample 7068 - loss: 2.273721694946289\n",
      "Sample 7069 - loss: 8.056889533996582\n",
      "Sample 7070 - loss: 0.900428831577301\n",
      "Sample 7071 - loss: 0.0062739048153162\n",
      "Sample 7072 - loss: 3.3352811336517334\n",
      "Sample 7073 - loss: 6.679192543029785\n",
      "Sample 7074 - loss: 0.8880008459091187\n",
      "Sample 7075 - loss: 0.391348272562027\n",
      "Sample 7076 - loss: 6.392828464508057\n",
      "Sample 7077 - loss: 1.2570836544036865\n",
      "Sample 7078 - loss: 5.207510471343994\n",
      "Sample 7079 - loss: 4.3971076011657715\n",
      "Sample 7080 - loss: 0.12397027015686035\n",
      "Sample 7081 - loss: 0.03673776984214783\n",
      "Sample 7082 - loss: 7.327968597412109\n",
      "Sample 7083 - loss: 1.0294429063796997\n",
      "Sample 7084 - loss: 4.068338871002197\n",
      "Sample 7085 - loss: 0.3634301424026489\n",
      "Sample 7086 - loss: 1.3736364841461182\n",
      "Sample 7087 - loss: 0.5024609565734863\n",
      "Sample 7088 - loss: 0.47592630982398987\n",
      "Sample 7089 - loss: 0.35416939854621887\n",
      "Sample 7090 - loss: 2.3371376991271973\n",
      "Sample 7091 - loss: 1.532700777053833\n",
      "Sample 7092 - loss: 5.0528669357299805\n",
      "Sample 7093 - loss: 6.863730430603027\n",
      "Sample 7094 - loss: 0.03921620920300484\n",
      "Sample 7095 - loss: 9.297005653381348\n",
      "Sample 7096 - loss: 0.3058713972568512\n",
      "Sample 7097 - loss: 2.844525098800659\n",
      "Sample 7098 - loss: 5.097111701965332\n",
      "Sample 7099 - loss: 1.4643975496292114\n",
      "Sample 7100 - loss: 0.9649146795272827\n",
      "Sample 7101 - loss: 5.599260330200195\n",
      "Sample 7102 - loss: 3.0827279090881348\n",
      "Sample 7103 - loss: 0.2637771964073181\n",
      "Sample 7104 - loss: 6.322115898132324\n",
      "Sample 7105 - loss: 1.5599273443222046\n",
      "Sample 7106 - loss: 0.08774308860301971\n",
      "Sample 7107 - loss: 2.434514045715332\n",
      "Sample 7108 - loss: 0.3190051317214966\n",
      "Sample 7109 - loss: 0.5082868933677673\n",
      "Sample 7110 - loss: 6.731430530548096\n",
      "Sample 7111 - loss: 4.547699928283691\n",
      "Sample 7112 - loss: 2.208184003829956\n",
      "Sample 7113 - loss: 0.2223907709121704\n",
      "Sample 7114 - loss: 1.0483587980270386\n",
      "Sample 7115 - loss: 2.4321508407592773\n",
      "Sample 7116 - loss: 4.516842842102051\n",
      "Sample 7117 - loss: 7.57368278503418\n",
      "Sample 7118 - loss: 5.607082366943359\n",
      "Sample 7119 - loss: 0.5024113655090332\n",
      "Sample 7120 - loss: 4.275310516357422\n",
      "Sample 7121 - loss: 0.01271518599241972\n",
      "Sample 7122 - loss: 0.19908998906612396\n",
      "Sample 7123 - loss: 4.234155654907227\n",
      "Sample 7124 - loss: 4.534830093383789\n",
      "Sample 7125 - loss: 3.4855659008026123\n",
      "Sample 7126 - loss: 0.0502622164785862\n",
      "Sample 7127 - loss: 0.20522014796733856\n",
      "Sample 7128 - loss: 3.9189634323120117\n",
      "Sample 7129 - loss: 6.059128284454346\n",
      "Sample 7130 - loss: 0.3192518949508667\n",
      "Sample 7131 - loss: 5.4310712814331055\n",
      "Sample 7132 - loss: 8.302188873291016\n",
      "Sample 7133 - loss: 4.277259349822998\n",
      "Sample 7134 - loss: 0.9941359162330627\n",
      "Sample 7135 - loss: 4.416114330291748\n",
      "Sample 7136 - loss: 7.932523727416992\n",
      "Sample 7137 - loss: 0.32804715633392334\n",
      "Sample 7138 - loss: 1.0231207609176636\n",
      "Sample 7139 - loss: 3.0157172679901123\n",
      "Sample 7140 - loss: 0.0789531022310257\n",
      "Sample 7141 - loss: 1.310145378112793\n",
      "Sample 7142 - loss: 2.2918338775634766\n",
      "Sample 7143 - loss: 2.6099767684936523\n",
      "Sample 7144 - loss: 5.207404613494873\n",
      "Sample 7145 - loss: 3.921027898788452\n",
      "Sample 7146 - loss: 1.4821581840515137\n",
      "Sample 7147 - loss: 0.9687796831130981\n",
      "Sample 7148 - loss: 5.73529052734375\n",
      "Sample 7149 - loss: 1.869826078414917\n",
      "Sample 7150 - loss: 5.376379013061523\n",
      "Sample 7151 - loss: 5.340330123901367\n",
      "Sample 7152 - loss: 5.914844512939453\n",
      "Sample 7153 - loss: 2.940704107284546\n",
      "Sample 7154 - loss: 0.5840798020362854\n",
      "Sample 7155 - loss: 6.9609551429748535\n",
      "Sample 7156 - loss: 1.008998155593872\n",
      "Sample 7157 - loss: 2.2080841064453125\n",
      "Sample 7158 - loss: 0.15414895117282867\n",
      "Sample 7159 - loss: 2.629768133163452\n",
      "Sample 7160 - loss: 0.07165785133838654\n",
      "Sample 7161 - loss: 0.048835400491952896\n",
      "Sample 7162 - loss: 7.299687385559082\n",
      "Sample 7163 - loss: 1.5802817344665527\n",
      "Sample 7164 - loss: 2.327885627746582\n",
      "Sample 7165 - loss: 0.1222478598356247\n",
      "Sample 7166 - loss: 7.0953168869018555\n",
      "Sample 7167 - loss: 5.602838516235352\n",
      "Sample 7168 - loss: 4.2155585289001465\n",
      "Sample 7169 - loss: 0.043449096381664276\n",
      "Sample 7170 - loss: 3.3257744312286377\n",
      "Sample 7171 - loss: 4.320130825042725\n",
      "Sample 7172 - loss: 0.535190224647522\n",
      "Sample 7173 - loss: 0.547921895980835\n",
      "Sample 7174 - loss: 5.963649272918701\n",
      "Sample 7175 - loss: 1.2879714965820312\n",
      "Sample 7176 - loss: 0.02521628327667713\n",
      "Sample 7177 - loss: 0.017537225037813187\n",
      "Sample 7178 - loss: 1.9701985120773315\n",
      "Sample 7179 - loss: 0.8474333882331848\n",
      "Sample 7180 - loss: 4.761501789093018\n",
      "Sample 7181 - loss: 2.779829502105713\n",
      "Sample 7182 - loss: 0.40631020069122314\n",
      "Sample 7183 - loss: 1.211442232131958\n",
      "Sample 7184 - loss: 0.35061195492744446\n",
      "Sample 7185 - loss: 3.4696848392486572\n",
      "Sample 7186 - loss: 0.3254621922969818\n",
      "Sample 7187 - loss: 2.512342691421509\n",
      "Sample 7188 - loss: 4.117834091186523\n",
      "Sample 7189 - loss: 0.05394944176077843\n",
      "Sample 7190 - loss: 9.402151107788086\n",
      "Sample 7191 - loss: 2.586287021636963\n",
      "Sample 7192 - loss: 1.3149058818817139\n",
      "Sample 7193 - loss: 2.1772031784057617\n",
      "Sample 7194 - loss: 3.636608600616455\n",
      "Sample 7195 - loss: 7.614372730255127\n",
      "Sample 7196 - loss: 0.5308808088302612\n",
      "Sample 7197 - loss: 1.6167359352111816\n",
      "Sample 7198 - loss: 1.036056399345398\n",
      "Sample 7199 - loss: 0.24011348187923431\n",
      "Sample 7200 - loss: 1.9132901430130005\n",
      "Sample 7201 - loss: 0.1873057335615158\n",
      "Sample 7202 - loss: 2.1538360118865967\n",
      "Sample 7203 - loss: 0.010541004128754139\n",
      "Sample 7204 - loss: 1.515859842300415\n",
      "Sample 7205 - loss: 0.4910544157028198\n",
      "Sample 7206 - loss: 5.660121440887451\n",
      "Sample 7207 - loss: 0.6921531558036804\n",
      "Sample 7208 - loss: 3.1688849925994873\n",
      "Sample 7209 - loss: 0.5858507752418518\n",
      "Sample 7210 - loss: 0.040366463363170624\n",
      "Sample 7211 - loss: 1.0995988845825195\n",
      "Sample 7212 - loss: 0.17142541706562042\n",
      "Sample 7213 - loss: 7.5633111000061035\n",
      "Sample 7214 - loss: 0.8983117938041687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7215 - loss: 0.020446471869945526\n",
      "Sample 7216 - loss: 0.6648706197738647\n",
      "Sample 7217 - loss: 1.4122650623321533\n",
      "Sample 7218 - loss: 2.398831844329834\n",
      "Sample 7219 - loss: 2.971567153930664\n",
      "Sample 7220 - loss: 0.34016817808151245\n",
      "Sample 7221 - loss: 1.8607535362243652\n",
      "Sample 7222 - loss: 5.627710342407227\n",
      "Sample 7223 - loss: 4.669456958770752\n",
      "Sample 7224 - loss: 3.6321682929992676\n",
      "Sample 7225 - loss: 3.8718392848968506\n",
      "Sample 7226 - loss: 5.807623386383057\n",
      "Sample 7227 - loss: 7.973222255706787\n",
      "Sample 7228 - loss: 1.8269104957580566\n",
      "Sample 7229 - loss: 0.4198939800262451\n",
      "Sample 7230 - loss: 6.430382251739502\n",
      "Sample 7231 - loss: 0.2417396903038025\n",
      "Sample 7232 - loss: 1.7120262384414673\n",
      "Sample 7233 - loss: 0.3943796455860138\n",
      "Sample 7234 - loss: 0.6122217178344727\n",
      "Sample 7235 - loss: 2.5358221530914307\n",
      "Sample 7236 - loss: 0.18959398567676544\n",
      "Sample 7237 - loss: 2.2781741619110107\n",
      "Sample 7238 - loss: 7.279443740844727\n",
      "Sample 7239 - loss: 5.787117958068848\n",
      "Sample 7240 - loss: 1.798679232597351\n",
      "Sample 7241 - loss: 2.7068614959716797\n",
      "Sample 7242 - loss: 0.04320775344967842\n",
      "Sample 7243 - loss: 2.1581642627716064\n",
      "Sample 7244 - loss: 5.662961006164551\n",
      "Sample 7245 - loss: 6.314400672912598\n",
      "Sample 7246 - loss: 5.150850772857666\n",
      "Sample 7247 - loss: 8.878740310668945\n",
      "Sample 7248 - loss: 0.1396084576845169\n",
      "Sample 7249 - loss: 3.8529322147369385\n",
      "Sample 7250 - loss: 0.9830911755561829\n",
      "Sample 7251 - loss: 0.7906625270843506\n",
      "Sample 7252 - loss: 2.3580760955810547\n",
      "Sample 7253 - loss: 7.456136703491211\n",
      "Sample 7254 - loss: 0.0456463061273098\n",
      "Sample 7255 - loss: 6.029170989990234\n",
      "Sample 7256 - loss: 3.9369735717773438\n",
      "Sample 7257 - loss: 2.1510074138641357\n",
      "Sample 7258 - loss: 6.053215503692627\n",
      "Sample 7259 - loss: 6.1121625900268555\n",
      "Sample 7260 - loss: 2.874706745147705\n",
      "Sample 7261 - loss: 0.16915643215179443\n",
      "Sample 7262 - loss: 5.210822105407715\n",
      "Sample 7263 - loss: 1.9663455486297607\n",
      "Sample 7264 - loss: 6.817633152008057\n",
      "Sample 7265 - loss: 0.9684118032455444\n",
      "Sample 7266 - loss: 0.20800840854644775\n",
      "Sample 7267 - loss: 5.188894271850586\n",
      "Sample 7268 - loss: 1.3690742254257202\n",
      "Sample 7269 - loss: 4.828607559204102\n",
      "Sample 7270 - loss: 6.178464889526367\n",
      "Sample 7271 - loss: 4.382693290710449\n",
      "Sample 7272 - loss: 0.7323806285858154\n",
      "Sample 7273 - loss: 3.3675591945648193\n",
      "Sample 7274 - loss: 4.670775890350342\n",
      "Sample 7275 - loss: 1.4656131267547607\n",
      "Sample 7276 - loss: 0.7913324236869812\n",
      "Sample 7277 - loss: 1.8430206775665283\n",
      "Sample 7278 - loss: 0.9645709991455078\n",
      "Sample 7279 - loss: 5.49212646484375\n",
      "Sample 7280 - loss: 6.706649303436279\n",
      "Sample 7281 - loss: 2.3758716583251953\n",
      "Sample 7282 - loss: 4.395989418029785\n",
      "Sample 7283 - loss: 0.6957628726959229\n",
      "Sample 7284 - loss: 6.219055652618408\n",
      "Sample 7285 - loss: 0.40708133578300476\n",
      "Sample 7286 - loss: 6.164959907531738\n",
      "Sample 7287 - loss: 4.158105373382568\n",
      "Sample 7288 - loss: 4.461404323577881\n",
      "Sample 7289 - loss: 0.3985626697540283\n",
      "Sample 7290 - loss: 3.495929002761841\n",
      "Sample 7291 - loss: 5.5241594314575195\n",
      "Sample 7292 - loss: 1.9397224187850952\n",
      "Sample 7293 - loss: 5.451833724975586\n",
      "Sample 7294 - loss: 4.911330223083496\n",
      "Sample 7295 - loss: 0.8480369448661804\n",
      "Sample 7296 - loss: 0.16663338243961334\n",
      "Sample 7297 - loss: 1.3247538805007935\n",
      "Sample 7298 - loss: 1.0423623323440552\n",
      "Sample 7299 - loss: 5.266618251800537\n",
      "Sample 7300 - loss: 3.2189736366271973\n",
      "Sample 7301 - loss: 4.571666240692139\n",
      "Sample 7302 - loss: 6.36284065246582\n",
      "Sample 7303 - loss: 1.5403918027877808\n",
      "Sample 7304 - loss: 6.456460952758789\n",
      "Sample 7305 - loss: 0.5123404860496521\n",
      "Sample 7306 - loss: 3.723395347595215\n",
      "Sample 7307 - loss: 2.4618985652923584\n",
      "Sample 7308 - loss: 0.202860489487648\n",
      "Sample 7309 - loss: 6.298129081726074\n",
      "Sample 7310 - loss: 5.883778095245361\n",
      "Sample 7311 - loss: 0.520760715007782\n",
      "Sample 7312 - loss: 2.4321672916412354\n",
      "Sample 7313 - loss: 2.2121381759643555\n",
      "Sample 7314 - loss: 0.41606995463371277\n",
      "Sample 7315 - loss: 8.2737398147583\n",
      "Sample 7316 - loss: 0.0723574087023735\n",
      "Sample 7317 - loss: 4.473003387451172\n",
      "Sample 7318 - loss: 5.7513017654418945\n",
      "Sample 7319 - loss: 3.785006046295166\n",
      "Sample 7320 - loss: 0.12992431223392487\n",
      "Sample 7321 - loss: 4.684354782104492\n",
      "Sample 7322 - loss: 0.14774587750434875\n",
      "Sample 7323 - loss: 0.5084485411643982\n",
      "Sample 7324 - loss: 4.9227142333984375\n",
      "Sample 7325 - loss: 0.5078044533729553\n",
      "Sample 7326 - loss: 0.2959684431552887\n",
      "Sample 7327 - loss: 0.5578184723854065\n",
      "Sample 7328 - loss: 0.025023069232702255\n",
      "Sample 7329 - loss: 0.5393239855766296\n",
      "Sample 7330 - loss: 3.7800328731536865\n",
      "Sample 7331 - loss: 6.047182559967041\n",
      "Sample 7332 - loss: 2.3696277141571045\n",
      "Sample 7333 - loss: 7.336558818817139\n",
      "Sample 7334 - loss: 1.5814824104309082\n",
      "Sample 7335 - loss: 3.212822198867798\n",
      "Sample 7336 - loss: 0.03086012415587902\n",
      "Sample 7337 - loss: 5.757352352142334\n",
      "Sample 7338 - loss: 5.978804111480713\n",
      "Sample 7339 - loss: 0.33521994948387146\n",
      "Sample 7340 - loss: 3.6622426509857178\n",
      "Sample 7341 - loss: 2.1379849910736084\n",
      "Sample 7342 - loss: 1.0511683225631714\n",
      "Sample 7343 - loss: 6.280451774597168\n",
      "Sample 7344 - loss: 4.588277339935303\n",
      "Sample 7345 - loss: 2.5173401832580566\n",
      "Sample 7346 - loss: 0.21532393991947174\n",
      "Sample 7347 - loss: 0.24454179406166077\n",
      "Sample 7348 - loss: 2.3527987003326416\n",
      "Sample 7349 - loss: 6.5315704345703125\n",
      "Sample 7350 - loss: 0.37661972641944885\n",
      "Sample 7351 - loss: 1.3905175924301147\n",
      "Sample 7352 - loss: 0.9225385189056396\n",
      "Sample 7353 - loss: 0.485261470079422\n",
      "Sample 7354 - loss: 5.788572311401367\n",
      "Sample 7355 - loss: 0.02835465408861637\n",
      "Sample 7356 - loss: 0.19384931027889252\n",
      "Sample 7357 - loss: 4.330968856811523\n",
      "Sample 7358 - loss: 0.08280344307422638\n",
      "Sample 7359 - loss: 0.05621269345283508\n",
      "Sample 7360 - loss: 0.3391536772251129\n",
      "Sample 7361 - loss: 1.610628604888916\n",
      "Sample 7362 - loss: 5.187211513519287\n",
      "Sample 7363 - loss: 0.34855395555496216\n",
      "Sample 7364 - loss: 0.0015250772703438997\n",
      "Sample 7365 - loss: 2.0284860134124756\n",
      "Sample 7366 - loss: 0.2016611099243164\n",
      "Sample 7367 - loss: 6.157452583312988\n",
      "Sample 7368 - loss: 1.9939072132110596\n",
      "Sample 7369 - loss: 1.6405982971191406\n",
      "Sample 7370 - loss: 3.073976755142212\n",
      "Sample 7371 - loss: 6.511754035949707\n",
      "Sample 7372 - loss: 2.600388526916504\n",
      "Sample 7373 - loss: 1.3045529127120972\n",
      "Sample 7374 - loss: 0.22886528074741364\n",
      "Sample 7375 - loss: 4.7925028800964355\n",
      "Sample 7376 - loss: 1.480453372001648\n",
      "Sample 7377 - loss: 6.626489639282227\n",
      "Sample 7378 - loss: 0.04652927443385124\n",
      "Sample 7379 - loss: 0.757606029510498\n",
      "Sample 7380 - loss: 1.3408085107803345\n",
      "Sample 7381 - loss: 2.267199754714966\n",
      "Sample 7382 - loss: 8.716466903686523\n",
      "Sample 7383 - loss: 8.520755767822266\n",
      "Sample 7384 - loss: 0.7762718200683594\n",
      "Sample 7385 - loss: 3.71768856048584\n",
      "Sample 7386 - loss: 0.44082656502723694\n",
      "Sample 7387 - loss: 4.83470344543457\n",
      "Sample 7388 - loss: 3.669048547744751\n",
      "Sample 7389 - loss: 3.7940664291381836\n",
      "Sample 7390 - loss: 8.997649192810059\n",
      "Sample 7391 - loss: 0.9659999012947083\n",
      "Sample 7392 - loss: 1.212024211883545\n",
      "Sample 7393 - loss: 1.7306082248687744\n",
      "Sample 7394 - loss: 0.9691210985183716\n",
      "Sample 7395 - loss: 4.425680160522461\n",
      "Sample 7396 - loss: 0.6240714192390442\n",
      "Sample 7397 - loss: 1.3668054342269897\n",
      "Sample 7398 - loss: 0.1241716593503952\n",
      "Sample 7399 - loss: 6.467799663543701\n",
      "Sample 7400 - loss: 1.2404512166976929\n",
      "Sample 7401 - loss: 0.6630968451499939\n",
      "Sample 7402 - loss: 4.391622543334961\n",
      "Sample 7403 - loss: 0.15984611213207245\n",
      "Sample 7404 - loss: 0.22507619857788086\n",
      "Sample 7405 - loss: 5.2539238929748535\n",
      "Sample 7406 - loss: 0.428340345621109\n",
      "Sample 7407 - loss: 6.971855640411377\n",
      "Sample 7408 - loss: 0.40099895000457764\n",
      "Sample 7409 - loss: 4.400313854217529\n",
      "Sample 7410 - loss: 0.1690976768732071\n",
      "Sample 7411 - loss: 0.0470503531396389\n",
      "Sample 7412 - loss: 3.9031360149383545\n",
      "Sample 7413 - loss: 0.9209038615226746\n",
      "Sample 7414 - loss: 2.775458335876465\n",
      "Sample 7415 - loss: 4.796932220458984\n",
      "Sample 7416 - loss: 0.010005035437643528\n",
      "Sample 7417 - loss: 2.4890918731689453\n",
      "Sample 7418 - loss: 2.113964557647705\n",
      "Sample 7419 - loss: 1.2895612716674805\n",
      "Sample 7420 - loss: 0.07037056982517242\n",
      "Sample 7421 - loss: 6.592286586761475\n",
      "Sample 7422 - loss: 0.27864977717399597\n",
      "Sample 7423 - loss: 1.4583441019058228\n",
      "Sample 7424 - loss: 0.13748185336589813\n",
      "Sample 7425 - loss: 5.136407375335693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7426 - loss: 10.148890495300293\n",
      "Sample 7427 - loss: 0.24114403128623962\n",
      "Sample 7428 - loss: 3.592808723449707\n",
      "Sample 7429 - loss: 0.12138788402080536\n",
      "Sample 7430 - loss: 4.853419303894043\n",
      "Sample 7431 - loss: 0.15714238584041595\n",
      "Sample 7432 - loss: 4.9874348640441895\n",
      "Sample 7433 - loss: 6.792701244354248\n",
      "Sample 7434 - loss: 0.5724468231201172\n",
      "Sample 7435 - loss: 1.0256741046905518\n",
      "Sample 7436 - loss: 0.2183333784341812\n",
      "Sample 7437 - loss: 2.442370653152466\n",
      "Sample 7438 - loss: 1.1528509855270386\n",
      "Sample 7439 - loss: 5.034995079040527\n",
      "Sample 7440 - loss: 1.675644040107727\n",
      "Sample 7441 - loss: 0.5447024703025818\n",
      "Sample 7442 - loss: 0.022357024252414703\n",
      "Sample 7443 - loss: 1.6168354749679565\n",
      "Sample 7444 - loss: 5.288761138916016\n",
      "Sample 7445 - loss: 0.04617730528116226\n",
      "Sample 7446 - loss: 6.873814582824707\n",
      "Sample 7447 - loss: 5.302468776702881\n",
      "Sample 7448 - loss: 0.03538895025849342\n",
      "Sample 7449 - loss: 0.263848215341568\n",
      "Sample 7450 - loss: 2.427816390991211\n",
      "Sample 7451 - loss: 0.14653638005256653\n",
      "Sample 7452 - loss: 4.372490406036377\n",
      "Sample 7453 - loss: 2.702327251434326\n",
      "Sample 7454 - loss: 6.5035552978515625\n",
      "Sample 7455 - loss: 0.6057559847831726\n",
      "Sample 7456 - loss: 3.9844024181365967\n",
      "Sample 7457 - loss: 7.323223114013672\n",
      "Sample 7458 - loss: 0.006515034008771181\n",
      "Sample 7459 - loss: 0.7262752652168274\n",
      "Sample 7460 - loss: 5.685840606689453\n",
      "Sample 7461 - loss: 6.088045597076416\n",
      "Sample 7462 - loss: 2.6446433067321777\n",
      "Sample 7463 - loss: 6.219240665435791\n",
      "Sample 7464 - loss: 6.672801971435547\n",
      "Sample 7465 - loss: 6.052706241607666\n",
      "Sample 7466 - loss: 0.08238950371742249\n",
      "Sample 7467 - loss: 2.3272600173950195\n",
      "Sample 7468 - loss: 0.30668139457702637\n",
      "Sample 7469 - loss: 3.2105984687805176\n",
      "Sample 7470 - loss: 6.395833969116211\n",
      "Sample 7471 - loss: 2.5352468490600586\n",
      "Sample 7472 - loss: 0.6969825625419617\n",
      "Sample 7473 - loss: 2.574617385864258\n",
      "Sample 7474 - loss: 2.417726516723633\n",
      "Sample 7475 - loss: 1.781592607498169\n",
      "Sample 7476 - loss: 0.23341137170791626\n",
      "Sample 7477 - loss: 0.6057495474815369\n",
      "Sample 7478 - loss: 5.474276542663574\n",
      "Sample 7479 - loss: 0.8253307342529297\n",
      "Sample 7480 - loss: 1.008487343788147\n",
      "Sample 7481 - loss: 0.6667827367782593\n",
      "Sample 7482 - loss: 1.0351426601409912\n",
      "Sample 7483 - loss: 0.015187034383416176\n",
      "Sample 7484 - loss: 2.536423444747925\n",
      "Sample 7485 - loss: 0.8199656009674072\n",
      "Sample 7486 - loss: 2.9250965118408203\n",
      "Sample 7487 - loss: 4.160364627838135\n",
      "Sample 7488 - loss: 0.27508601546287537\n",
      "Sample 7489 - loss: 4.075401782989502\n",
      "Sample 7490 - loss: 0.41116252541542053\n",
      "Sample 7491 - loss: 7.021024703979492\n",
      "Sample 7492 - loss: 3.532421588897705\n",
      "Sample 7493 - loss: 1.7659612894058228\n",
      "Sample 7494 - loss: 2.9171383380889893\n",
      "Sample 7495 - loss: 4.497893333435059\n",
      "Sample 7496 - loss: 0.3578791916370392\n",
      "Sample 7497 - loss: 5.736663341522217\n",
      "Sample 7498 - loss: 7.968161106109619\n",
      "Sample 7499 - loss: 1.3348779678344727\n",
      "Sample 7500 - loss: 3.614821434020996\n",
      "Sample 7501 - loss: 3.2283382415771484\n",
      "Sample 7502 - loss: 3.053171157836914\n",
      "Sample 7503 - loss: 2.0617547035217285\n",
      "Sample 7504 - loss: 3.157625198364258\n",
      "Sample 7505 - loss: 0.9898760318756104\n",
      "Sample 7506 - loss: 1.2275855541229248\n",
      "Sample 7507 - loss: 1.5998709201812744\n",
      "Sample 7508 - loss: 0.8058972358703613\n",
      "Sample 7509 - loss: 2.251202344894409\n",
      "Sample 7510 - loss: 2.780529737472534\n",
      "Sample 7511 - loss: 2.489553213119507\n",
      "Sample 7512 - loss: 7.093479156494141\n",
      "Sample 7513 - loss: 4.815784454345703\n",
      "Sample 7514 - loss: 0.21016336977481842\n",
      "Sample 7515 - loss: 0.09653063118457794\n",
      "Sample 7516 - loss: 1.830521821975708\n",
      "Sample 7517 - loss: 1.7688053846359253\n",
      "Sample 7518 - loss: 7.613563060760498\n",
      "Sample 7519 - loss: 0.5536506175994873\n",
      "Sample 7520 - loss: 3.160536527633667\n",
      "Sample 7521 - loss: 1.188538670539856\n",
      "Sample 7522 - loss: 2.986128807067871\n",
      "Sample 7523 - loss: 1.5900306701660156\n",
      "Sample 7524 - loss: 0.15670645236968994\n",
      "Sample 7525 - loss: 0.0774417519569397\n",
      "Sample 7526 - loss: 2.4151198863983154\n",
      "Sample 7527 - loss: 0.10834691673517227\n",
      "Sample 7528 - loss: 0.16828182339668274\n",
      "Sample 7529 - loss: 0.8690569996833801\n",
      "Sample 7530 - loss: 4.047109603881836\n",
      "Sample 7531 - loss: 0.48940062522888184\n",
      "Sample 7532 - loss: 3.860978126525879\n",
      "Sample 7533 - loss: 0.088570736348629\n",
      "Sample 7534 - loss: 5.782649517059326\n",
      "Sample 7535 - loss: 0.617780327796936\n",
      "Sample 7536 - loss: 2.4198455810546875\n",
      "Sample 7537 - loss: 4.004421234130859\n",
      "Sample 7538 - loss: 0.7927720546722412\n",
      "Sample 7539 - loss: 0.5338963866233826\n",
      "Sample 7540 - loss: 0.06824946403503418\n",
      "Sample 7541 - loss: 6.321882247924805\n",
      "Sample 7542 - loss: 6.1194562911987305\n",
      "Sample 7543 - loss: 5.092272758483887\n",
      "Sample 7544 - loss: 0.23816242814064026\n",
      "Sample 7545 - loss: 3.8603222370147705\n",
      "Sample 7546 - loss: 0.031420473009347916\n",
      "Sample 7547 - loss: 0.2621108293533325\n",
      "Sample 7548 - loss: 0.9299659729003906\n",
      "Sample 7549 - loss: 4.624038219451904\n",
      "Sample 7550 - loss: 0.4458385407924652\n",
      "Sample 7551 - loss: 3.5999298095703125\n",
      "Sample 7552 - loss: 7.645148277282715\n",
      "Sample 7553 - loss: 1.531840205192566\n",
      "Sample 7554 - loss: 0.1520271599292755\n",
      "Sample 7555 - loss: 8.383125305175781\n",
      "Sample 7556 - loss: 1.2088221311569214\n",
      "Sample 7557 - loss: 1.9014058113098145\n",
      "Sample 7558 - loss: 1.401567816734314\n",
      "Sample 7559 - loss: 3.5002224445343018\n",
      "Sample 7560 - loss: 0.8067011833190918\n",
      "Sample 7561 - loss: 0.5425026416778564\n",
      "Sample 7562 - loss: 0.6965999603271484\n",
      "Sample 7563 - loss: 4.315080642700195\n",
      "Sample 7564 - loss: 5.606430530548096\n",
      "Sample 7565 - loss: 4.2242302894592285\n",
      "Sample 7566 - loss: 5.147485256195068\n",
      "Sample 7567 - loss: 6.374032497406006\n",
      "Sample 7568 - loss: 0.025215087458491325\n",
      "Sample 7569 - loss: 5.3063435554504395\n",
      "Sample 7570 - loss: 3.4582831859588623\n",
      "Sample 7571 - loss: 7.937246799468994\n",
      "Sample 7572 - loss: 0.36385926604270935\n",
      "Sample 7573 - loss: 5.558797836303711\n",
      "Sample 7574 - loss: 2.3075990676879883\n",
      "Sample 7575 - loss: 0.01872333325445652\n",
      "Sample 7576 - loss: 0.4088975489139557\n",
      "Sample 7577 - loss: 1.8686143159866333\n",
      "Sample 7578 - loss: 3.3142082691192627\n",
      "Sample 7579 - loss: 0.08781066536903381\n",
      "Sample 7580 - loss: 7.084722518920898\n",
      "Sample 7581 - loss: 0.8182411193847656\n",
      "Sample 7582 - loss: 0.5184522867202759\n",
      "Sample 7583 - loss: 0.4283284842967987\n",
      "Sample 7584 - loss: 0.38096001744270325\n",
      "Sample 7585 - loss: 1.6412121057510376\n",
      "Sample 7586 - loss: 0.6693359613418579\n",
      "Sample 7587 - loss: 6.153444290161133\n",
      "Sample 7588 - loss: 8.80578327178955\n",
      "Sample 7589 - loss: 1.0990923643112183\n",
      "Sample 7590 - loss: 3.4061062335968018\n",
      "Sample 7591 - loss: 0.12321595102548599\n",
      "Sample 7592 - loss: 1.1698408126831055\n",
      "Sample 7593 - loss: 2.173034906387329\n",
      "Sample 7594 - loss: 2.518624782562256\n",
      "Sample 7595 - loss: 3.094564199447632\n",
      "Sample 7596 - loss: 0.2621484696865082\n",
      "Sample 7597 - loss: 0.00940756220370531\n",
      "Sample 7598 - loss: 1.4877874851226807\n",
      "Sample 7599 - loss: 3.6494693756103516\n",
      "Sample 7600 - loss: 0.009466822259128094\n",
      "Sample 7601 - loss: 0.6675095558166504\n",
      "Sample 7602 - loss: 0.3670518100261688\n",
      "Sample 7603 - loss: 2.310704469680786\n",
      "Sample 7604 - loss: 0.40900513529777527\n",
      "Sample 7605 - loss: 0.4889436364173889\n",
      "Sample 7606 - loss: 1.2915774583816528\n",
      "Sample 7607 - loss: 0.17338725924491882\n",
      "Sample 7608 - loss: 3.395820379257202\n",
      "Sample 7609 - loss: 2.891958713531494\n",
      "Sample 7610 - loss: 0.04350724071264267\n",
      "Sample 7611 - loss: 1.9220584630966187\n",
      "Sample 7612 - loss: 0.6700439453125\n",
      "Sample 7613 - loss: 0.04652813822031021\n",
      "Sample 7614 - loss: 7.247380256652832\n",
      "Sample 7615 - loss: 1.8435020446777344\n",
      "Sample 7616 - loss: 4.472405433654785\n",
      "Sample 7617 - loss: 0.059947457164525986\n",
      "Sample 7618 - loss: 2.7049312591552734\n",
      "Sample 7619 - loss: 2.78004789352417\n",
      "Sample 7620 - loss: 2.604015588760376\n",
      "Sample 7621 - loss: 5.39057731628418\n",
      "Sample 7622 - loss: 0.463649719953537\n",
      "Sample 7623 - loss: 0.11723937094211578\n",
      "Sample 7624 - loss: 5.162005424499512\n",
      "Sample 7625 - loss: 0.8017573356628418\n",
      "Sample 7626 - loss: 5.932091236114502\n",
      "Sample 7627 - loss: 3.0313992500305176\n",
      "Sample 7628 - loss: 0.06867287307977676\n",
      "Sample 7629 - loss: 0.07191626727581024\n",
      "Sample 7630 - loss: 5.295737266540527\n",
      "Sample 7631 - loss: 3.295225143432617\n",
      "Sample 7632 - loss: 0.32578185200691223\n",
      "Sample 7633 - loss: 0.9116981029510498\n",
      "Sample 7634 - loss: 6.211528778076172\n",
      "Sample 7635 - loss: 3.267012119293213\n",
      "Sample 7636 - loss: 1.2275593280792236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7637 - loss: 0.6931155920028687\n",
      "Sample 7638 - loss: 6.364226818084717\n",
      "Sample 7639 - loss: 1.4250906705856323\n",
      "Sample 7640 - loss: 0.6502219438552856\n",
      "Sample 7641 - loss: 1.7403825521469116\n",
      "Sample 7642 - loss: 1.9108538627624512\n",
      "Sample 7643 - loss: 0.7660821676254272\n",
      "Sample 7644 - loss: 0.12011577934026718\n",
      "Sample 7645 - loss: 0.4319108724594116\n",
      "Sample 7646 - loss: 0.05707906186580658\n",
      "Sample 7647 - loss: 5.8295578956604\n",
      "Sample 7648 - loss: 2.014930009841919\n",
      "Sample 7649 - loss: 7.030427932739258\n",
      "Sample 7650 - loss: 1.6259466409683228\n",
      "Sample 7651 - loss: 0.03684961423277855\n",
      "Sample 7652 - loss: 8.05398178100586\n",
      "Sample 7653 - loss: 3.0450210571289062\n",
      "Sample 7654 - loss: 1.8405598402023315\n",
      "Sample 7655 - loss: 8.020086288452148\n",
      "Sample 7656 - loss: 1.31703519821167\n",
      "Sample 7657 - loss: 1.8908308744430542\n",
      "Sample 7658 - loss: 4.233496189117432\n",
      "Sample 7659 - loss: 0.10284430533647537\n",
      "Sample 7660 - loss: 1.8607685565948486\n",
      "Sample 7661 - loss: 2.5014760494232178\n",
      "Sample 7662 - loss: 1.1647263765335083\n",
      "Sample 7663 - loss: 0.2786753475666046\n",
      "Sample 7664 - loss: 4.580199718475342\n",
      "Sample 7665 - loss: 1.4307301044464111\n",
      "Sample 7666 - loss: 0.6958228945732117\n",
      "Sample 7667 - loss: 0.5136291980743408\n",
      "Sample 7668 - loss: 1.639957070350647\n",
      "Sample 7669 - loss: 1.6460371017456055\n",
      "Sample 7670 - loss: 5.344181060791016\n",
      "Sample 7671 - loss: 4.639369487762451\n",
      "Sample 7672 - loss: 0.34345245361328125\n",
      "Sample 7673 - loss: 4.361800670623779\n",
      "Sample 7674 - loss: 0.5621463060379028\n",
      "Sample 7675 - loss: 0.21723626554012299\n",
      "Sample 7676 - loss: 5.0363616943359375\n",
      "Sample 7677 - loss: 5.541231155395508\n",
      "Sample 7678 - loss: 0.16595397889614105\n",
      "Sample 7679 - loss: 6.443760871887207\n",
      "Sample 7680 - loss: 1.0307594537734985\n",
      "Sample 7681 - loss: 0.12165196239948273\n",
      "Sample 7682 - loss: 8.213366508483887\n",
      "Sample 7683 - loss: 1.2221816778182983\n",
      "Sample 7684 - loss: 0.5031697750091553\n",
      "Sample 7685 - loss: 2.3740122318267822\n",
      "Sample 7686 - loss: 5.239589691162109\n",
      "Sample 7687 - loss: 4.440843105316162\n",
      "Sample 7688 - loss: 3.757753610610962\n",
      "Sample 7689 - loss: 0.113732248544693\n",
      "Sample 7690 - loss: 4.317282199859619\n",
      "Sample 7691 - loss: 6.8441481590271\n",
      "Sample 7692 - loss: 1.318477749824524\n",
      "Sample 7693 - loss: 3.9841742515563965\n",
      "Sample 7694 - loss: 0.7563914656639099\n",
      "Sample 7695 - loss: 0.8654821515083313\n",
      "Sample 7696 - loss: 5.952103137969971\n",
      "Sample 7697 - loss: 5.991678237915039\n",
      "Sample 7698 - loss: 5.3246049880981445\n",
      "Sample 7699 - loss: 0.011634706519544125\n",
      "Sample 7700 - loss: 0.5324426889419556\n",
      "Sample 7701 - loss: 0.2524923086166382\n",
      "Sample 7702 - loss: 0.40723592042922974\n",
      "Sample 7703 - loss: 0.0491676889359951\n",
      "Sample 7704 - loss: 1.0604289770126343\n",
      "Sample 7705 - loss: 0.2633081376552582\n",
      "Sample 7706 - loss: 3.3666837215423584\n",
      "Sample 7707 - loss: 0.81328946352005\n",
      "Sample 7708 - loss: 5.389828681945801\n",
      "Sample 7709 - loss: 2.793302536010742\n",
      "Sample 7710 - loss: 3.254002571105957\n",
      "Sample 7711 - loss: 0.9019908308982849\n",
      "Sample 7712 - loss: 3.710603952407837\n",
      "Sample 7713 - loss: 3.542764186859131\n",
      "Sample 7714 - loss: 0.14895500242710114\n",
      "Sample 7715 - loss: 0.26287609338760376\n",
      "Sample 7716 - loss: 0.31734272837638855\n",
      "Sample 7717 - loss: 4.527284622192383\n",
      "Sample 7718 - loss: 0.003537158016115427\n",
      "Sample 7719 - loss: 5.7325053215026855\n",
      "Sample 7720 - loss: 5.4020514488220215\n",
      "Sample 7721 - loss: 4.403528213500977\n",
      "Sample 7722 - loss: 0.12901809811592102\n",
      "Sample 7723 - loss: 4.27085542678833\n",
      "Sample 7724 - loss: 0.9200279116630554\n",
      "Sample 7725 - loss: 3.5290844440460205\n",
      "Sample 7726 - loss: 3.3174619674682617\n",
      "Sample 7727 - loss: 3.7627763748168945\n",
      "Sample 7728 - loss: 0.007826250977814198\n",
      "Sample 7729 - loss: 0.29562005400657654\n",
      "Sample 7730 - loss: 6.934945106506348\n",
      "Sample 7731 - loss: 5.038363456726074\n",
      "Sample 7732 - loss: 0.691455066204071\n",
      "Sample 7733 - loss: 0.34986647963523865\n",
      "Sample 7734 - loss: 3.5815889835357666\n",
      "Sample 7735 - loss: 2.7684552669525146\n",
      "Sample 7736 - loss: 4.753100395202637\n",
      "Sample 7737 - loss: 0.8571501970291138\n",
      "Sample 7738 - loss: 2.750307321548462\n",
      "Sample 7739 - loss: 3.2635226249694824\n",
      "Sample 7740 - loss: 0.029789648950099945\n",
      "Sample 7741 - loss: 0.5503486394882202\n",
      "Sample 7742 - loss: 0.7946818470954895\n",
      "Sample 7743 - loss: 8.920376777648926\n",
      "Sample 7744 - loss: 3.0028791427612305\n",
      "Sample 7745 - loss: 3.022451400756836\n",
      "Sample 7746 - loss: 8.05296516418457\n",
      "Sample 7747 - loss: 6.059430122375488\n",
      "Sample 7748 - loss: 0.6654694080352783\n",
      "Sample 7749 - loss: 0.30074724555015564\n",
      "Sample 7750 - loss: 2.3850340843200684\n",
      "Sample 7751 - loss: 4.631693363189697\n",
      "Sample 7752 - loss: 5.483880043029785\n",
      "Sample 7753 - loss: 0.15808838605880737\n",
      "Sample 7754 - loss: 1.3062543869018555\n",
      "Sample 7755 - loss: 0.0749623030424118\n",
      "Sample 7756 - loss: 0.041361793875694275\n",
      "Sample 7757 - loss: 2.7217800617218018\n",
      "Sample 7758 - loss: 1.6963618993759155\n",
      "Sample 7759 - loss: 4.0541157722473145\n",
      "Sample 7760 - loss: 1.5673584938049316\n",
      "Sample 7761 - loss: 2.675149917602539\n",
      "Sample 7762 - loss: 0.07346862554550171\n",
      "Sample 7763 - loss: 4.209411144256592\n",
      "Sample 7764 - loss: 1.7951983213424683\n",
      "Sample 7765 - loss: 5.064635276794434\n",
      "Sample 7766 - loss: 0.08229809999465942\n",
      "Sample 7767 - loss: 0.538459837436676\n",
      "Sample 7768 - loss: 0.508564293384552\n",
      "Sample 7769 - loss: 0.08451784402132034\n",
      "Sample 7770 - loss: 1.167340874671936\n",
      "Sample 7771 - loss: 5.085158348083496\n",
      "Sample 7772 - loss: 0.5868552327156067\n",
      "Sample 7773 - loss: 0.17783765494823456\n",
      "Sample 7774 - loss: 0.1152786985039711\n",
      "Sample 7775 - loss: 5.052778720855713\n",
      "Sample 7776 - loss: 7.008819580078125\n",
      "Sample 7777 - loss: 4.429907321929932\n",
      "Sample 7778 - loss: 3.5910871028900146\n",
      "Sample 7779 - loss: 1.1685694456100464\n",
      "Sample 7780 - loss: 2.949169635772705\n",
      "Sample 7781 - loss: 0.04292136803269386\n",
      "Sample 7782 - loss: 2.8122479915618896\n",
      "Sample 7783 - loss: 0.3415150046348572\n",
      "Sample 7784 - loss: 0.06314010173082352\n",
      "Sample 7785 - loss: 1.230600118637085\n",
      "Sample 7786 - loss: 1.3355698585510254\n",
      "Sample 7787 - loss: 3.509007453918457\n",
      "Sample 7788 - loss: 2.0084121227264404\n",
      "Sample 7789 - loss: 3.577425241470337\n",
      "Sample 7790 - loss: 0.15594160556793213\n",
      "Sample 7791 - loss: 0.007164116017520428\n",
      "Sample 7792 - loss: 0.545245349407196\n",
      "Sample 7793 - loss: 2.5335097312927246\n",
      "Sample 7794 - loss: 0.008932691067457199\n",
      "Sample 7795 - loss: 4.939507961273193\n",
      "Sample 7796 - loss: 1.632472038269043\n",
      "Sample 7797 - loss: 2.638218879699707\n",
      "Sample 7798 - loss: 0.12908512353897095\n",
      "Sample 7799 - loss: 4.063528060913086\n",
      "Sample 7800 - loss: 1.5835224390029907\n",
      "Sample 7801 - loss: 0.2762623131275177\n",
      "Sample 7802 - loss: 0.3808916211128235\n",
      "Sample 7803 - loss: 3.3953371047973633\n",
      "Sample 7804 - loss: 2.964632034301758\n",
      "Sample 7805 - loss: 6.718554496765137\n",
      "Sample 7806 - loss: 1.650473952293396\n",
      "Sample 7807 - loss: 1.1274855136871338\n",
      "Sample 7808 - loss: 0.10982697457075119\n",
      "Sample 7809 - loss: 1.606654405593872\n",
      "Sample 7810 - loss: 0.4509056806564331\n",
      "Sample 7811 - loss: 2.9174110889434814\n",
      "Sample 7812 - loss: 7.348514556884766\n",
      "Sample 7813 - loss: 0.4648384749889374\n",
      "Sample 7814 - loss: 0.1674463450908661\n",
      "Sample 7815 - loss: 0.9437099695205688\n",
      "Sample 7816 - loss: 0.8802697658538818\n",
      "Sample 7817 - loss: 1.9789206981658936\n",
      "Sample 7818 - loss: 6.201287746429443\n",
      "Sample 7819 - loss: 5.244081020355225\n",
      "Sample 7820 - loss: 1.0919543504714966\n",
      "Sample 7821 - loss: 3.364400625228882\n",
      "Sample 7822 - loss: 0.470801442861557\n",
      "Sample 7823 - loss: 2.6517693996429443\n",
      "Sample 7824 - loss: 10.924339294433594\n",
      "Sample 7825 - loss: 0.9749128818511963\n",
      "Sample 7826 - loss: 0.06333431601524353\n",
      "Sample 7827 - loss: 2.760648727416992\n",
      "Sample 7828 - loss: 0.3762844204902649\n",
      "Sample 7829 - loss: 0.6208699941635132\n",
      "Sample 7830 - loss: 3.4438836574554443\n",
      "Sample 7831 - loss: 6.112727165222168\n",
      "Sample 7832 - loss: 0.5331315398216248\n",
      "Sample 7833 - loss: 0.25585052371025085\n",
      "Sample 7834 - loss: 0.34464114904403687\n",
      "Sample 7835 - loss: 5.264992713928223\n",
      "Sample 7836 - loss: 0.3796062171459198\n",
      "Sample 7837 - loss: 0.20810404419898987\n",
      "Sample 7838 - loss: 1.9745274782180786\n",
      "Sample 7839 - loss: 2.4486336708068848\n",
      "Sample 7840 - loss: 1.4595052003860474\n",
      "Sample 7841 - loss: 1.1827688217163086\n",
      "Sample 7842 - loss: 1.128616213798523\n",
      "Sample 7843 - loss: 0.13696971535682678\n",
      "Sample 7844 - loss: 0.8061805963516235\n",
      "Sample 7845 - loss: 0.5255545377731323\n",
      "Sample 7846 - loss: 0.9453487396240234\n",
      "Sample 7847 - loss: 3.7435381412506104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7848 - loss: 0.4983004033565521\n",
      "Sample 7849 - loss: 0.05257473140954971\n",
      "Sample 7850 - loss: 5.4861555099487305\n",
      "Sample 7851 - loss: 1.6360907554626465\n",
      "Sample 7852 - loss: 3.2914159297943115\n",
      "Sample 7853 - loss: 0.010601806454360485\n",
      "Sample 7854 - loss: 0.07387132942676544\n",
      "Sample 7855 - loss: 3.5210137367248535\n",
      "Sample 7856 - loss: 0.12247908860445023\n",
      "Sample 7857 - loss: 4.971039295196533\n",
      "Sample 7858 - loss: 6.443819046020508\n",
      "Sample 7859 - loss: 5.559747219085693\n",
      "Sample 7860 - loss: 2.105055809020996\n",
      "Sample 7861 - loss: 3.6331522464752197\n",
      "Sample 7862 - loss: 3.503218650817871\n",
      "Sample 7863 - loss: 2.2509987354278564\n",
      "Sample 7864 - loss: 0.41787204146385193\n",
      "Sample 7865 - loss: 3.524043083190918\n",
      "Sample 7866 - loss: 3.692451238632202\n",
      "Sample 7867 - loss: 0.4744299054145813\n",
      "Sample 7868 - loss: 0.4173499345779419\n",
      "Sample 7869 - loss: 6.0853376388549805\n",
      "Sample 7870 - loss: 2.1867573261260986\n",
      "Sample 7871 - loss: 0.5206272602081299\n",
      "Sample 7872 - loss: 2.634808301925659\n",
      "Sample 7873 - loss: 1.7111178636550903\n",
      "Sample 7874 - loss: 0.1562838852405548\n",
      "Sample 7875 - loss: 1.4554612636566162\n",
      "Sample 7876 - loss: 6.124919891357422\n",
      "Sample 7877 - loss: 5.479732036590576\n",
      "Sample 7878 - loss: 3.4584078788757324\n",
      "Sample 7879 - loss: 3.8448777198791504\n",
      "Sample 7880 - loss: 3.8429975509643555\n",
      "Sample 7881 - loss: 1.5070276260375977\n",
      "Sample 7882 - loss: 0.6197345852851868\n",
      "Sample 7883 - loss: 1.8410688638687134\n",
      "Sample 7884 - loss: 0.6387125849723816\n",
      "Sample 7885 - loss: 0.6327866911888123\n",
      "Sample 7886 - loss: 5.429508209228516\n",
      "Sample 7887 - loss: 6.455739974975586\n",
      "Sample 7888 - loss: 0.5057675242424011\n",
      "Sample 7889 - loss: 1.647180199623108\n",
      "Sample 7890 - loss: 2.0960030555725098\n",
      "Sample 7891 - loss: 1.3681786060333252\n",
      "Sample 7892 - loss: 3.2274999618530273\n",
      "Sample 7893 - loss: 2.956496477127075\n",
      "Sample 7894 - loss: 0.49154528975486755\n",
      "Sample 7895 - loss: 3.537292718887329\n",
      "Sample 7896 - loss: 3.0750226974487305\n",
      "Sample 7897 - loss: 1.5234477519989014\n",
      "Sample 7898 - loss: 1.9089165925979614\n",
      "Sample 7899 - loss: 0.8316559791564941\n",
      "Sample 7900 - loss: 6.813384532928467\n",
      "Sample 7901 - loss: 2.173684597015381\n",
      "Sample 7902 - loss: 0.2526293992996216\n",
      "Sample 7903 - loss: 0.5296688675880432\n",
      "Sample 7904 - loss: 1.8022288084030151\n",
      "Sample 7905 - loss: 1.3723167181015015\n",
      "Sample 7906 - loss: 0.28052911162376404\n",
      "Sample 7907 - loss: 0.07359421253204346\n",
      "Sample 7908 - loss: 4.674505710601807\n",
      "Sample 7909 - loss: 8.601452827453613\n",
      "Sample 7910 - loss: 0.6098357439041138\n",
      "Sample 7911 - loss: 2.748647689819336\n",
      "Sample 7912 - loss: 0.1367723047733307\n",
      "Sample 7913 - loss: 5.181447982788086\n",
      "Sample 7914 - loss: 0.04527272284030914\n",
      "Sample 7915 - loss: 2.8322982788085938\n",
      "Sample 7916 - loss: 1.112865686416626\n",
      "Sample 7917 - loss: 0.32849499583244324\n",
      "Sample 7918 - loss: 4.341048717498779\n",
      "Sample 7919 - loss: 3.4987785816192627\n",
      "Sample 7920 - loss: 0.05759499594569206\n",
      "Sample 7921 - loss: 3.7636992931365967\n",
      "Sample 7922 - loss: 6.80218505859375\n",
      "Sample 7923 - loss: 1.7104912996292114\n",
      "Sample 7924 - loss: 0.5086871981620789\n",
      "Sample 7925 - loss: 0.9246889352798462\n",
      "Sample 7926 - loss: 0.05825316533446312\n",
      "Sample 7927 - loss: 3.6183743476867676\n",
      "Sample 7928 - loss: 6.604681491851807\n",
      "Sample 7929 - loss: 5.070944309234619\n",
      "Sample 7930 - loss: 3.393646001815796\n",
      "Sample 7931 - loss: 1.9169540405273438\n",
      "Sample 7932 - loss: 0.041330479085445404\n",
      "Sample 7933 - loss: 0.17222104966640472\n",
      "Sample 7934 - loss: 2.634443998336792\n",
      "Sample 7935 - loss: 2.656121015548706\n",
      "Sample 7936 - loss: 2.5763397216796875\n",
      "Sample 7937 - loss: 2.862151861190796\n",
      "Sample 7938 - loss: 4.404098987579346\n",
      "Sample 7939 - loss: 8.748178482055664\n",
      "Sample 7940 - loss: 1.0395110845565796\n",
      "Sample 7941 - loss: 3.9855825901031494\n",
      "Sample 7942 - loss: 3.818244695663452\n",
      "Sample 7943 - loss: 3.147135019302368\n",
      "Sample 7944 - loss: 1.4467169046401978\n",
      "Sample 7945 - loss: 4.445679187774658\n",
      "Sample 7946 - loss: 10.061853408813477\n",
      "Sample 7947 - loss: 6.428808689117432\n",
      "Sample 7948 - loss: 3.4641573429107666\n",
      "Sample 7949 - loss: 0.7795741558074951\n",
      "Sample 7950 - loss: 0.027839159592986107\n",
      "Sample 7951 - loss: 0.5977855920791626\n",
      "Sample 7952 - loss: 3.217921733856201\n",
      "Sample 7953 - loss: 0.09461824595928192\n",
      "Sample 7954 - loss: 4.900289535522461\n",
      "Sample 7955 - loss: 1.2494497299194336\n",
      "Sample 7956 - loss: 0.011025620624423027\n",
      "Sample 7957 - loss: 4.523118495941162\n",
      "Sample 7958 - loss: 0.17552104592323303\n",
      "Sample 7959 - loss: 4.645501613616943\n",
      "Sample 7960 - loss: 2.8092267513275146\n",
      "Sample 7961 - loss: 1.4714813232421875\n",
      "Sample 7962 - loss: 0.25230321288108826\n",
      "Sample 7963 - loss: 1.754531979560852\n",
      "Sample 7964 - loss: 0.5451101064682007\n",
      "Sample 7965 - loss: 0.787177324295044\n",
      "Sample 7966 - loss: 1.5085608959197998\n",
      "Sample 7967 - loss: 0.3055088520050049\n",
      "Sample 7968 - loss: 5.861937999725342\n",
      "Sample 7969 - loss: 0.9806291460990906\n",
      "Sample 7970 - loss: 0.7431307435035706\n",
      "Sample 7971 - loss: 5.724666595458984\n",
      "Sample 7972 - loss: 2.431701421737671\n",
      "Sample 7973 - loss: 3.55649995803833\n",
      "Sample 7974 - loss: 1.4464290142059326\n",
      "Sample 7975 - loss: 3.4583704471588135\n",
      "Sample 7976 - loss: 0.0895349383354187\n",
      "Sample 7977 - loss: 6.838872909545898\n",
      "Sample 7978 - loss: 2.2918598651885986\n",
      "Sample 7979 - loss: 1.323462724685669\n",
      "Sample 7980 - loss: 0.0417289100587368\n",
      "Sample 7981 - loss: 0.3519165813922882\n",
      "Sample 7982 - loss: 0.07017030566930771\n",
      "Sample 7983 - loss: 0.06592705845832825\n",
      "Sample 7984 - loss: 1.7640814781188965\n",
      "Sample 7985 - loss: 7.237908363342285\n",
      "Sample 7986 - loss: 3.0424697399139404\n",
      "Sample 7987 - loss: 4.847804069519043\n",
      "Sample 7988 - loss: 0.3807096481323242\n",
      "Sample 7989 - loss: 4.091413974761963\n",
      "Sample 7990 - loss: 1.1318646669387817\n",
      "Sample 7991 - loss: 2.379560708999634\n",
      "Sample 7992 - loss: 0.24704495072364807\n",
      "Sample 7993 - loss: 0.4634450674057007\n",
      "Sample 7994 - loss: 3.673612356185913\n",
      "Sample 7995 - loss: 0.30533528327941895\n",
      "Sample 7996 - loss: 3.2026779651641846\n",
      "Sample 7997 - loss: 0.48487144708633423\n",
      "Sample 7998 - loss: 8.54660415649414\n",
      "Sample 7999 - loss: 2.4640231132507324\n",
      "Sample 8000 - loss: 0.6604282855987549\n",
      "Sample 8001 - loss: 0.0788179561495781\n",
      "Sample 8002 - loss: 2.485617160797119\n",
      "Sample 8003 - loss: 0.9770566821098328\n",
      "Sample 8004 - loss: 4.756308078765869\n",
      "Sample 8005 - loss: 0.2566680610179901\n",
      "Sample 8006 - loss: 0.3948501944541931\n",
      "Sample 8007 - loss: 6.80992317199707\n",
      "Sample 8008 - loss: 0.7904040813446045\n",
      "Sample 8009 - loss: 4.022444725036621\n",
      "Sample 8010 - loss: 2.874896764755249\n",
      "Sample 8011 - loss: 4.796199798583984\n",
      "Sample 8012 - loss: 0.8315037488937378\n",
      "Sample 8013 - loss: 6.093196392059326\n",
      "Sample 8014 - loss: 4.835464000701904\n",
      "Sample 8015 - loss: 4.81132173538208\n",
      "Sample 8016 - loss: 4.887872219085693\n",
      "Sample 8017 - loss: 0.44751304388046265\n",
      "Sample 8018 - loss: 3.9960548877716064\n",
      "Sample 8019 - loss: 0.053469981998205185\n",
      "Sample 8020 - loss: 0.7619836330413818\n",
      "Sample 8021 - loss: 5.3235602378845215\n",
      "Sample 8022 - loss: 5.920571804046631\n",
      "Sample 8023 - loss: 0.16888895630836487\n",
      "Sample 8024 - loss: 5.209587574005127\n",
      "Sample 8025 - loss: 7.3207573890686035\n",
      "Sample 8026 - loss: 3.904468059539795\n",
      "Sample 8027 - loss: 0.8735755681991577\n",
      "Sample 8028 - loss: 0.8792520761489868\n",
      "Sample 8029 - loss: 0.658681333065033\n",
      "Sample 8030 - loss: 2.067472457885742\n",
      "Sample 8031 - loss: 0.502062201499939\n",
      "Sample 8032 - loss: 1.4669283628463745\n",
      "Sample 8033 - loss: 7.165309906005859\n",
      "Sample 8034 - loss: 1.2201488018035889\n",
      "Sample 8035 - loss: 1.6475850343704224\n",
      "Sample 8036 - loss: 1.7979376316070557\n",
      "Sample 8037 - loss: 0.11963097751140594\n",
      "Sample 8038 - loss: 0.013768105767667294\n",
      "Sample 8039 - loss: 7.230341911315918\n",
      "Sample 8040 - loss: 2.14312481880188\n",
      "Sample 8041 - loss: 3.748659610748291\n",
      "Sample 8042 - loss: 2.827410936355591\n",
      "Sample 8043 - loss: 0.21264995634555817\n",
      "Sample 8044 - loss: 0.042918965220451355\n",
      "Sample 8045 - loss: 3.634796380996704\n",
      "Sample 8046 - loss: 0.3156323730945587\n",
      "Sample 8047 - loss: 1.990738034248352\n",
      "Sample 8048 - loss: 0.12769822776317596\n",
      "Sample 8049 - loss: 0.714921236038208\n",
      "Sample 8050 - loss: 2.128396511077881\n",
      "Sample 8051 - loss: 4.268015384674072\n",
      "Sample 8052 - loss: 5.452635288238525\n",
      "Sample 8053 - loss: 0.5081052184104919\n",
      "Sample 8054 - loss: 9.916677474975586\n",
      "Sample 8055 - loss: 4.832741737365723\n",
      "Sample 8056 - loss: 6.479406833648682\n",
      "Sample 8057 - loss: 0.9240795969963074\n",
      "Sample 8058 - loss: 1.9257724285125732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8059 - loss: 0.3295906186103821\n",
      "Sample 8060 - loss: 0.3625878393650055\n",
      "Sample 8061 - loss: 2.0794317722320557\n",
      "Sample 8062 - loss: 2.417712926864624\n",
      "Sample 8063 - loss: 0.657555341720581\n",
      "Sample 8064 - loss: 6.686278820037842\n",
      "Sample 8065 - loss: 2.287827491760254\n",
      "Sample 8066 - loss: 0.33465245366096497\n",
      "Sample 8067 - loss: 5.541484355926514\n",
      "Sample 8068 - loss: 0.7618240118026733\n",
      "Sample 8069 - loss: 2.0921621322631836\n",
      "Sample 8070 - loss: 7.782907485961914\n",
      "Sample 8071 - loss: 2.5882885456085205\n",
      "Sample 8072 - loss: 0.7662693858146667\n",
      "Sample 8073 - loss: 7.554283618927002\n",
      "Sample 8074 - loss: 3.0916223526000977\n",
      "Sample 8075 - loss: 3.921436071395874\n",
      "Sample 8076 - loss: 0.13974638283252716\n",
      "Sample 8077 - loss: 5.269267559051514\n",
      "Sample 8078 - loss: 1.9212919473648071\n",
      "Sample 8079 - loss: 4.161238193511963\n",
      "Sample 8080 - loss: 1.4242143630981445\n",
      "Sample 8081 - loss: 1.3956292867660522\n",
      "Sample 8082 - loss: 2.5151641368865967\n",
      "Sample 8083 - loss: 4.120306015014648\n",
      "Sample 8084 - loss: 0.09875446557998657\n",
      "Sample 8085 - loss: 0.7840259075164795\n",
      "Sample 8086 - loss: 6.533686637878418\n",
      "Sample 8087 - loss: 4.206393718719482\n",
      "Sample 8088 - loss: 3.6450695991516113\n",
      "Sample 8089 - loss: 4.176641941070557\n",
      "Sample 8090 - loss: 2.154170036315918\n",
      "Sample 8091 - loss: 0.03765422850847244\n",
      "Sample 8092 - loss: 1.2918410301208496\n",
      "Sample 8093 - loss: 1.3867030143737793\n",
      "Sample 8094 - loss: 0.7992542386054993\n",
      "Sample 8095 - loss: 5.091214656829834\n",
      "Sample 8096 - loss: 8.365274429321289\n",
      "Sample 8097 - loss: 1.7340987920761108\n",
      "Sample 8098 - loss: 2.4270341396331787\n",
      "Sample 8099 - loss: 0.36322811245918274\n",
      "Sample 8100 - loss: 4.163604259490967\n",
      "Sample 8101 - loss: 0.14525270462036133\n",
      "Sample 8102 - loss: 0.8212559223175049\n",
      "Sample 8103 - loss: 0.9632443189620972\n",
      "Sample 8104 - loss: 0.3218931257724762\n",
      "Sample 8105 - loss: 1.0699706077575684\n",
      "Sample 8106 - loss: 6.628631591796875\n",
      "Sample 8107 - loss: 0.1939869076013565\n",
      "Sample 8108 - loss: 0.22859470546245575\n",
      "Sample 8109 - loss: 4.892977714538574\n",
      "Sample 8110 - loss: 1.8043997287750244\n",
      "Sample 8111 - loss: 1.0295888185501099\n",
      "Sample 8112 - loss: 0.03372114524245262\n",
      "Sample 8113 - loss: 4.360691070556641\n",
      "Sample 8114 - loss: 0.03150659427046776\n",
      "Sample 8115 - loss: 1.0021439790725708\n",
      "Sample 8116 - loss: 0.009326252155005932\n",
      "Sample 8117 - loss: 2.153998374938965\n",
      "Sample 8118 - loss: 4.007648944854736\n",
      "Sample 8119 - loss: 2.4836952686309814\n",
      "Sample 8120 - loss: 0.05932309478521347\n",
      "Sample 8121 - loss: 4.164926528930664\n",
      "Sample 8122 - loss: 0.39573603868484497\n",
      "Sample 8123 - loss: 4.428594589233398\n",
      "Sample 8124 - loss: 3.5466461181640625\n",
      "Sample 8125 - loss: 1.2525368928909302\n",
      "Sample 8126 - loss: 0.055373359471559525\n",
      "Sample 8127 - loss: 2.300529718399048\n",
      "Sample 8128 - loss: 0.40176185965538025\n",
      "Sample 8129 - loss: 0.29832693934440613\n",
      "Sample 8130 - loss: 0.7485133409500122\n",
      "Sample 8131 - loss: 2.381410598754883\n",
      "Sample 8132 - loss: 1.707363247871399\n",
      "Sample 8133 - loss: 4.9392924308776855\n",
      "Sample 8134 - loss: 0.7843775153160095\n",
      "Sample 8135 - loss: 0.4358632266521454\n",
      "Sample 8136 - loss: 0.6284613609313965\n",
      "Sample 8137 - loss: 3.363009452819824\n",
      "Sample 8138 - loss: 2.2185349464416504\n",
      "Sample 8139 - loss: 0.5705273747444153\n",
      "Sample 8140 - loss: 1.1214017868041992\n",
      "Sample 8141 - loss: 1.2545050382614136\n",
      "Sample 8142 - loss: 4.8586626052856445\n",
      "Sample 8143 - loss: 4.197136402130127\n",
      "Sample 8144 - loss: 0.7296636700630188\n",
      "Sample 8145 - loss: 0.3546625077724457\n",
      "Sample 8146 - loss: 6.864297389984131\n",
      "Sample 8147 - loss: 5.070240020751953\n",
      "Sample 8148 - loss: 0.03688223659992218\n",
      "Sample 8149 - loss: 0.13493293523788452\n",
      "Sample 8150 - loss: 0.5168623328208923\n",
      "Sample 8151 - loss: 0.039239440113306046\n",
      "Sample 8152 - loss: 1.222049355506897\n",
      "Sample 8153 - loss: 1.3826992511749268\n",
      "Sample 8154 - loss: 3.5249764919281006\n",
      "Sample 8155 - loss: 3.3125152587890625\n",
      "Sample 8156 - loss: 4.121126174926758\n",
      "Sample 8157 - loss: 0.15243172645568848\n",
      "Sample 8158 - loss: 5.604496002197266\n",
      "Sample 8159 - loss: 8.868172645568848\n",
      "Sample 8160 - loss: 0.02542765811085701\n",
      "Sample 8161 - loss: 1.7733372449874878\n",
      "Sample 8162 - loss: 1.242743730545044\n",
      "Sample 8163 - loss: 1.2592014074325562\n",
      "Sample 8164 - loss: 1.1279091835021973\n",
      "Sample 8165 - loss: 1.6016833782196045\n",
      "Sample 8166 - loss: 4.123615741729736\n",
      "Sample 8167 - loss: 1.4179340600967407\n",
      "Sample 8168 - loss: 7.878764629364014\n",
      "Sample 8169 - loss: 0.653434693813324\n",
      "Sample 8170 - loss: 0.026742856949567795\n",
      "Sample 8171 - loss: 0.1446688026189804\n",
      "Sample 8172 - loss: 5.804816722869873\n",
      "Sample 8173 - loss: 1.376774787902832\n",
      "Sample 8174 - loss: 0.73675537109375\n",
      "Sample 8175 - loss: 3.384866714477539\n",
      "Sample 8176 - loss: 1.0969094038009644\n",
      "Sample 8177 - loss: 0.2749624252319336\n",
      "Sample 8178 - loss: 2.1899688243865967\n",
      "Sample 8179 - loss: 1.6352523565292358\n",
      "Sample 8180 - loss: 2.1953063011169434\n",
      "Sample 8181 - loss: 0.9861670136451721\n",
      "Sample 8182 - loss: 0.015021204017102718\n",
      "Sample 8183 - loss: 4.129192352294922\n",
      "Sample 8184 - loss: 4.699753761291504\n",
      "Sample 8185 - loss: 2.4740958213806152\n",
      "Sample 8186 - loss: 3.8908746242523193\n",
      "Sample 8187 - loss: 2.3838605880737305\n",
      "Sample 8188 - loss: 0.3481351137161255\n",
      "Sample 8189 - loss: 1.1777783632278442\n",
      "Sample 8190 - loss: 0.7992028594017029\n",
      "Sample 8191 - loss: 4.48471212387085\n",
      "Sample 8192 - loss: 1.8751609325408936\n",
      "Sample 8193 - loss: 0.05849551036953926\n",
      "Sample 8194 - loss: 1.6397733688354492\n",
      "Sample 8195 - loss: 0.0720343217253685\n",
      "Sample 8196 - loss: 0.13666829466819763\n",
      "Sample 8197 - loss: 2.967379570007324\n",
      "Sample 8198 - loss: 0.1645393967628479\n",
      "Sample 8199 - loss: 5.023214817047119\n",
      "Sample 8200 - loss: 3.1350841522216797\n",
      "Sample 8201 - loss: 2.7457685470581055\n",
      "Sample 8202 - loss: 0.8847974538803101\n",
      "Sample 8203 - loss: 0.11813684552907944\n",
      "Sample 8204 - loss: 0.25811824202537537\n",
      "Sample 8205 - loss: 0.3144911825656891\n",
      "Sample 8206 - loss: 0.04556277394294739\n",
      "Sample 8207 - loss: 2.0464320182800293\n",
      "Sample 8208 - loss: 0.8158305883407593\n",
      "Sample 8209 - loss: 0.846854031085968\n",
      "Sample 8210 - loss: 4.440420150756836\n",
      "Sample 8211 - loss: 4.595892429351807\n",
      "Sample 8212 - loss: 2.2266159057617188\n",
      "Sample 8213 - loss: 2.8978164196014404\n",
      "Sample 8214 - loss: 4.911855220794678\n",
      "Sample 8215 - loss: 1.735701084136963\n",
      "Sample 8216 - loss: 3.2754836082458496\n",
      "Sample 8217 - loss: 0.8109018206596375\n",
      "Sample 8218 - loss: 3.0013222694396973\n",
      "Sample 8219 - loss: 1.535886526107788\n",
      "Sample 8220 - loss: 3.0859007835388184\n",
      "Sample 8221 - loss: 6.177031993865967\n",
      "Sample 8222 - loss: 1.2273706197738647\n",
      "Sample 8223 - loss: 1.4195876121520996\n",
      "Sample 8224 - loss: 6.859908580780029\n",
      "Sample 8225 - loss: 0.7493693828582764\n",
      "Sample 8226 - loss: 0.260098934173584\n",
      "Sample 8227 - loss: 2.72316312789917\n",
      "Sample 8228 - loss: 2.3168015480041504\n",
      "Sample 8229 - loss: 0.23412130773067474\n",
      "Sample 8230 - loss: 0.2238629162311554\n",
      "Sample 8231 - loss: 2.5754852294921875\n",
      "Sample 8232 - loss: 0.006915370002388954\n",
      "Sample 8233 - loss: 0.3283698558807373\n",
      "Sample 8234 - loss: 0.26336461305618286\n",
      "Sample 8235 - loss: 1.4998352527618408\n",
      "Sample 8236 - loss: 4.387060165405273\n",
      "Sample 8237 - loss: 3.3748037815093994\n",
      "Sample 8238 - loss: 2.3916499614715576\n",
      "Sample 8239 - loss: 0.764692485332489\n",
      "Sample 8240 - loss: 0.013709988445043564\n",
      "Sample 8241 - loss: 5.796948432922363\n",
      "Sample 8242 - loss: 1.142349362373352\n",
      "Sample 8243 - loss: 0.44838616251945496\n",
      "Sample 8244 - loss: 0.31951475143432617\n",
      "Sample 8245 - loss: 4.352518081665039\n",
      "Sample 8246 - loss: 0.07550197839736938\n",
      "Sample 8247 - loss: 5.209152698516846\n",
      "Sample 8248 - loss: 0.6105092763900757\n",
      "Sample 8249 - loss: 0.7503455877304077\n",
      "Sample 8250 - loss: 0.732246994972229\n",
      "Sample 8251 - loss: 1.5708703994750977\n",
      "Sample 8252 - loss: 1.1223777532577515\n",
      "Sample 8253 - loss: 0.11456622183322906\n",
      "Sample 8254 - loss: 4.523155689239502\n",
      "Sample 8255 - loss: 0.9100380539894104\n",
      "Sample 8256 - loss: 0.7115386128425598\n",
      "Sample 8257 - loss: 1.325172781944275\n",
      "Sample 8258 - loss: 5.249997138977051\n",
      "Sample 8259 - loss: 0.5818795561790466\n",
      "Sample 8260 - loss: 0.03234075382351875\n",
      "Sample 8261 - loss: 6.77354621887207\n",
      "Sample 8262 - loss: 1.4378782510757446\n",
      "Sample 8263 - loss: 0.7192671895027161\n",
      "Sample 8264 - loss: 0.7241886258125305\n",
      "Sample 8265 - loss: 0.5798760056495667\n",
      "Sample 8266 - loss: 0.8131853342056274\n",
      "Sample 8267 - loss: 0.018577026203274727\n",
      "Sample 8268 - loss: 7.03237771987915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8269 - loss: 2.54818058013916\n",
      "Sample 8270 - loss: 0.8311103582382202\n",
      "Sample 8271 - loss: 0.08528761565685272\n",
      "Sample 8272 - loss: 0.42671722173690796\n",
      "Sample 8273 - loss: 0.06941768527030945\n",
      "Sample 8274 - loss: 0.34247416257858276\n",
      "Sample 8275 - loss: 0.4515191614627838\n",
      "Sample 8276 - loss: 1.0214124917984009\n",
      "Sample 8277 - loss: 4.312208652496338\n",
      "Sample 8278 - loss: 1.8690780401229858\n",
      "Sample 8279 - loss: 2.0397744178771973\n",
      "Sample 8280 - loss: 1.3447754383087158\n",
      "Sample 8281 - loss: 1.715692162513733\n",
      "Sample 8282 - loss: 2.5771994590759277\n",
      "Sample 8283 - loss: 2.090031862258911\n",
      "Sample 8284 - loss: 0.06331396102905273\n",
      "Sample 8285 - loss: 0.9872279167175293\n",
      "Sample 8286 - loss: 1.5125125646591187\n",
      "Sample 8287 - loss: 0.049215249717235565\n",
      "Sample 8288 - loss: 0.3000708818435669\n",
      "Sample 8289 - loss: 1.086287498474121\n",
      "Sample 8290 - loss: 1.6740645170211792\n",
      "Sample 8291 - loss: 1.790956735610962\n",
      "Sample 8292 - loss: 3.1275668144226074\n",
      "Sample 8293 - loss: 1.919734239578247\n",
      "Sample 8294 - loss: 3.0784647464752197\n",
      "Sample 8295 - loss: 1.2803252935409546\n",
      "Sample 8296 - loss: 2.758577823638916\n",
      "Sample 8297 - loss: 0.4916151463985443\n",
      "Sample 8298 - loss: 0.6373597383499146\n",
      "Sample 8299 - loss: 0.12700334191322327\n",
      "Sample 8300 - loss: 1.0641279220581055\n",
      "Sample 8301 - loss: 0.24583382904529572\n",
      "Sample 8302 - loss: 5.436399936676025\n",
      "Sample 8303 - loss: 1.7545313835144043\n",
      "Sample 8304 - loss: 5.612732410430908\n",
      "Sample 8305 - loss: 3.3026649951934814\n",
      "Sample 8306 - loss: 1.5655969381332397\n",
      "Sample 8307 - loss: 1.7279750108718872\n",
      "Sample 8308 - loss: 1.3366265296936035\n",
      "Sample 8309 - loss: 3.825721502304077\n",
      "Sample 8310 - loss: 0.4897541105747223\n",
      "Sample 8311 - loss: 0.14895471930503845\n",
      "Sample 8312 - loss: 0.09996001422405243\n",
      "Sample 8313 - loss: 5.111902236938477\n",
      "Sample 8314 - loss: 7.39651346206665\n",
      "Sample 8315 - loss: 1.486624002456665\n",
      "Sample 8316 - loss: 0.4676724374294281\n",
      "Sample 8317 - loss: 0.33075010776519775\n",
      "Sample 8318 - loss: 0.29052090644836426\n",
      "Sample 8319 - loss: 2.722285747528076\n",
      "Sample 8320 - loss: 6.8438825607299805\n",
      "Sample 8321 - loss: 7.327245712280273\n",
      "Sample 8322 - loss: 4.14665412902832\n",
      "Sample 8323 - loss: 1.44895601272583\n",
      "Sample 8324 - loss: 4.818235397338867\n",
      "Sample 8325 - loss: 3.922090530395508\n",
      "Sample 8326 - loss: 0.24675412476062775\n",
      "Sample 8327 - loss: 2.646646022796631\n",
      "Sample 8328 - loss: 0.8356273174285889\n",
      "Sample 8329 - loss: 0.5428505539894104\n",
      "Sample 8330 - loss: 1.237675666809082\n",
      "Sample 8331 - loss: 0.2965414524078369\n",
      "Sample 8332 - loss: 5.732602596282959\n",
      "Sample 8333 - loss: 3.441309928894043\n",
      "Sample 8334 - loss: 0.0025700361002236605\n",
      "Sample 8335 - loss: 1.5350619554519653\n",
      "Sample 8336 - loss: 1.2418147325515747\n",
      "Sample 8337 - loss: 4.206480026245117\n",
      "Sample 8338 - loss: 2.761871099472046\n",
      "Sample 8339 - loss: 1.6681647300720215\n",
      "Sample 8340 - loss: 1.2870378494262695\n",
      "Sample 8341 - loss: 1.1523444652557373\n",
      "Sample 8342 - loss: 0.16511088609695435\n",
      "Sample 8343 - loss: 0.31620630621910095\n",
      "Sample 8344 - loss: 2.0778191089630127\n",
      "Sample 8345 - loss: 0.9037673473358154\n",
      "Sample 8346 - loss: 2.932055711746216\n",
      "Sample 8347 - loss: 2.8768417835235596\n",
      "Sample 8348 - loss: 2.8518733978271484\n",
      "Sample 8349 - loss: 0.17559021711349487\n",
      "Sample 8350 - loss: 1.7438732385635376\n",
      "Sample 8351 - loss: 4.148752212524414\n",
      "Sample 8352 - loss: 0.15619874000549316\n",
      "Sample 8353 - loss: 1.112765908241272\n",
      "Sample 8354 - loss: 0.0668642446398735\n",
      "Sample 8355 - loss: 0.8871092796325684\n",
      "Sample 8356 - loss: 2.599220037460327\n",
      "Sample 8357 - loss: 0.038822587579488754\n",
      "Sample 8358 - loss: 0.8208539485931396\n",
      "Sample 8359 - loss: 0.04082508012652397\n",
      "Sample 8360 - loss: 0.1406000703573227\n",
      "Sample 8361 - loss: 1.3002216815948486\n",
      "Sample 8362 - loss: 0.3310188949108124\n",
      "Sample 8363 - loss: 0.014046542346477509\n",
      "Sample 8364 - loss: 1.1075783967971802\n",
      "Sample 8365 - loss: 0.5004155039787292\n",
      "Sample 8366 - loss: 0.35955193638801575\n",
      "Sample 8367 - loss: 0.27076879143714905\n",
      "Sample 8368 - loss: 1.220579981803894\n",
      "Sample 8369 - loss: 0.2204481065273285\n",
      "Sample 8370 - loss: 3.6326565742492676\n",
      "Sample 8371 - loss: 5.355794906616211\n",
      "Sample 8372 - loss: 1.749089002609253\n",
      "Sample 8373 - loss: 3.935365676879883\n",
      "Sample 8374 - loss: 3.2810254096984863\n",
      "Sample 8375 - loss: 0.39367637038230896\n",
      "Sample 8376 - loss: 0.5479979515075684\n",
      "Sample 8377 - loss: 0.03300478309392929\n",
      "Sample 8378 - loss: 4.8481645584106445\n",
      "Sample 8379 - loss: 2.6606500148773193\n",
      "Sample 8380 - loss: 1.533826470375061\n",
      "Sample 8381 - loss: 0.5491840243339539\n",
      "Sample 8382 - loss: 3.1813604831695557\n",
      "Sample 8383 - loss: 3.879565477371216\n",
      "Sample 8384 - loss: 0.026958242058753967\n",
      "Sample 8385 - loss: 4.807369232177734\n",
      "Sample 8386 - loss: 0.7224739789962769\n",
      "Sample 8387 - loss: 6.25430154800415\n",
      "Sample 8388 - loss: 6.5206170082092285\n",
      "Sample 8389 - loss: 2.3953397274017334\n",
      "Sample 8390 - loss: 1.3762612342834473\n",
      "Sample 8391 - loss: 0.2700125277042389\n",
      "Sample 8392 - loss: 3.938187837600708\n",
      "Sample 8393 - loss: 5.376330375671387\n",
      "Sample 8394 - loss: 1.4965051412582397\n",
      "Sample 8395 - loss: 1.7592941522598267\n",
      "Sample 8396 - loss: 1.229515552520752\n",
      "Sample 8397 - loss: 2.241682767868042\n",
      "Sample 8398 - loss: 4.875300407409668\n",
      "Sample 8399 - loss: 1.0652785301208496\n",
      "Sample 8400 - loss: 1.0351961851119995\n",
      "Sample 8401 - loss: 3.522566318511963\n",
      "Sample 8402 - loss: 4.350683689117432\n",
      "Sample 8403 - loss: 0.7809803485870361\n",
      "Sample 8404 - loss: 3.5724103450775146\n",
      "Sample 8405 - loss: 0.323420912027359\n",
      "Sample 8406 - loss: 2.689706325531006\n",
      "Sample 8407 - loss: 4.2462286949157715\n",
      "Sample 8408 - loss: 0.9121273756027222\n",
      "Sample 8409 - loss: 6.9665069580078125\n",
      "Sample 8410 - loss: 0.5555873513221741\n",
      "Sample 8411 - loss: 2.7905285358428955\n",
      "Sample 8412 - loss: 0.9468730092048645\n",
      "Sample 8413 - loss: 5.308746337890625\n",
      "Sample 8414 - loss: 0.5407221913337708\n",
      "Sample 8415 - loss: 0.07863370329141617\n",
      "Sample 8416 - loss: 0.16521163284778595\n",
      "Sample 8417 - loss: 0.6086892485618591\n",
      "Sample 8418 - loss: 0.2533716857433319\n",
      "Sample 8419 - loss: 0.42600834369659424\n",
      "Sample 8420 - loss: 1.4802988767623901\n",
      "Sample 8421 - loss: 3.910851240158081\n",
      "Sample 8422 - loss: 2.1886589527130127\n",
      "Sample 8423 - loss: 0.33991503715515137\n",
      "Sample 8424 - loss: 1.1852672100067139\n",
      "Sample 8425 - loss: 3.8236048221588135\n",
      "Sample 8426 - loss: 2.934920072555542\n",
      "Sample 8427 - loss: 6.344587802886963\n",
      "Sample 8428 - loss: 2.4805874824523926\n",
      "Sample 8429 - loss: 0.023109162226319313\n",
      "Sample 8430 - loss: 2.713229179382324\n",
      "Sample 8431 - loss: 5.214049816131592\n",
      "Sample 8432 - loss: 0.21277214586734772\n",
      "Sample 8433 - loss: 2.0066232681274414\n",
      "Sample 8434 - loss: 3.0101537704467773\n",
      "Sample 8435 - loss: 6.116750717163086\n",
      "Sample 8436 - loss: 0.010262534953653812\n",
      "Sample 8437 - loss: 0.926533579826355\n",
      "Sample 8438 - loss: 1.2205983400344849\n",
      "Sample 8439 - loss: 2.2187530994415283\n",
      "Sample 8440 - loss: 6.1260271072387695\n",
      "Sample 8441 - loss: 4.721717357635498\n",
      "Sample 8442 - loss: 4.197957992553711\n",
      "Sample 8443 - loss: 1.418979287147522\n",
      "Sample 8444 - loss: 2.1896286010742188\n",
      "Sample 8445 - loss: 5.352473735809326\n",
      "Sample 8446 - loss: 0.20320872962474823\n",
      "Sample 8447 - loss: 3.22920560836792\n",
      "Sample 8448 - loss: 6.441283702850342\n",
      "Sample 8449 - loss: 2.769473075866699\n",
      "Sample 8450 - loss: 1.0142641067504883\n",
      "Sample 8451 - loss: 5.166203498840332\n",
      "Sample 8452 - loss: 1.8699884414672852\n",
      "Sample 8453 - loss: 0.04295049235224724\n",
      "Sample 8454 - loss: 0.06738007068634033\n",
      "Sample 8455 - loss: 4.895120620727539\n",
      "Sample 8456 - loss: 0.34306591749191284\n",
      "Sample 8457 - loss: 4.014986515045166\n",
      "Sample 8458 - loss: 2.6629867553710938\n",
      "Sample 8459 - loss: 1.474699854850769\n",
      "Sample 8460 - loss: 2.802305221557617\n",
      "Sample 8461 - loss: 0.19463537633419037\n",
      "Sample 8462 - loss: 0.04899494722485542\n",
      "Sample 8463 - loss: 1.1828432083129883\n",
      "Sample 8464 - loss: 0.5878170728683472\n",
      "Sample 8465 - loss: 0.49761641025543213\n",
      "Sample 8466 - loss: 0.002489033155143261\n",
      "Sample 8467 - loss: 0.15180715918540955\n",
      "Sample 8468 - loss: 5.579700946807861\n",
      "Sample 8469 - loss: 9.141329765319824\n",
      "Sample 8470 - loss: 2.352269172668457\n",
      "Sample 8471 - loss: 1.5207431316375732\n",
      "Sample 8472 - loss: 0.9776431322097778\n",
      "Sample 8473 - loss: 0.05043818801641464\n",
      "Sample 8474 - loss: 3.9220197200775146\n",
      "Sample 8475 - loss: 0.23484474420547485\n",
      "Sample 8476 - loss: 2.4192025661468506\n",
      "Sample 8477 - loss: 1.0942448377609253\n",
      "Sample 8478 - loss: 1.5060491561889648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8479 - loss: 0.5680900812149048\n",
      "Sample 8480 - loss: 1.413432002067566\n",
      "Sample 8481 - loss: 3.5736310482025146\n",
      "Sample 8482 - loss: 1.5217911005020142\n",
      "Sample 8483 - loss: 8.3735990524292\n",
      "Sample 8484 - loss: 4.599959850311279\n",
      "Sample 8485 - loss: 0.7080740332603455\n",
      "Sample 8486 - loss: 0.20540541410446167\n",
      "Sample 8487 - loss: 0.5797693729400635\n",
      "Sample 8488 - loss: 0.9565791487693787\n",
      "Sample 8489 - loss: 1.363558053970337\n",
      "Sample 8490 - loss: 0.9986569881439209\n",
      "Sample 8491 - loss: 5.284965991973877\n",
      "Sample 8492 - loss: 2.112600803375244\n",
      "Sample 8493 - loss: 1.2103890180587769\n",
      "Sample 8494 - loss: 2.425269365310669\n",
      "Sample 8495 - loss: 0.5171712040901184\n",
      "Sample 8496 - loss: 6.632695198059082\n",
      "Sample 8497 - loss: 2.5648109912872314\n",
      "Sample 8498 - loss: 5.896154403686523\n",
      "Sample 8499 - loss: 4.388968467712402\n",
      "Sample 8500 - loss: 1.2723379135131836\n",
      "Sample 8501 - loss: 3.3640823364257812\n",
      "Sample 8502 - loss: 4.386051654815674\n",
      "Sample 8503 - loss: 0.023210696876049042\n",
      "Sample 8504 - loss: 0.2747481167316437\n",
      "Sample 8505 - loss: 3.9039700031280518\n",
      "Sample 8506 - loss: 5.244968891143799\n",
      "Sample 8507 - loss: 2.4007654190063477\n",
      "Sample 8508 - loss: 1.0673209428787231\n",
      "Sample 8509 - loss: 4.426642417907715\n",
      "Sample 8510 - loss: 3.7765800952911377\n",
      "Sample 8511 - loss: 0.28163567185401917\n",
      "Sample 8512 - loss: 2.274904727935791\n",
      "Sample 8513 - loss: 0.23500117659568787\n",
      "Sample 8514 - loss: 2.7109267711639404\n",
      "Sample 8515 - loss: 0.3227486312389374\n",
      "Sample 8516 - loss: 0.011005369015038013\n",
      "Sample 8517 - loss: 3.353422164916992\n",
      "Sample 8518 - loss: 3.3704161643981934\n",
      "Sample 8519 - loss: 1.2010810375213623\n",
      "Sample 8520 - loss: 0.2565334439277649\n",
      "Sample 8521 - loss: 3.6135547161102295\n",
      "Sample 8522 - loss: 4.362720489501953\n",
      "Sample 8523 - loss: 0.19485363364219666\n",
      "Sample 8524 - loss: 4.123500347137451\n",
      "Sample 8525 - loss: 0.01138512697070837\n",
      "Sample 8526 - loss: 0.5247552990913391\n",
      "Sample 8527 - loss: 0.00693302508443594\n",
      "Sample 8528 - loss: 1.2650049924850464\n",
      "Sample 8529 - loss: 2.0993218421936035\n",
      "Sample 8530 - loss: 8.151240348815918\n",
      "Sample 8531 - loss: 0.364058256149292\n",
      "Sample 8532 - loss: 3.7354896068573\n",
      "Sample 8533 - loss: 3.356394052505493\n",
      "Sample 8534 - loss: 4.321935653686523\n",
      "Sample 8535 - loss: 1.9123109579086304\n",
      "Sample 8536 - loss: 1.7561243772506714\n",
      "Sample 8537 - loss: 0.017323194071650505\n",
      "Sample 8538 - loss: 1.3729536533355713\n",
      "Sample 8539 - loss: 0.6504746079444885\n",
      "Sample 8540 - loss: 0.29311391711235046\n",
      "Sample 8541 - loss: 7.05116081237793\n",
      "Sample 8542 - loss: 2.7038967609405518\n",
      "Sample 8543 - loss: 1.0339857339859009\n",
      "Sample 8544 - loss: 1.048996090888977\n",
      "Sample 8545 - loss: 0.07860792428255081\n",
      "Sample 8546 - loss: 2.9579572677612305\n",
      "Sample 8547 - loss: 2.3065295219421387\n",
      "Sample 8548 - loss: 0.016155842691659927\n",
      "Sample 8549 - loss: 6.238217830657959\n",
      "Sample 8550 - loss: 2.1420469284057617\n",
      "Sample 8551 - loss: 0.8337928056716919\n",
      "Sample 8552 - loss: 2.9795544147491455\n",
      "Sample 8553 - loss: 1.3463305234909058\n",
      "Sample 8554 - loss: 1.4745001792907715\n",
      "Sample 8555 - loss: 2.663437604904175\n",
      "Sample 8556 - loss: 0.8522911667823792\n",
      "Sample 8557 - loss: 1.3208690881729126\n",
      "Sample 8558 - loss: 0.7930874824523926\n",
      "Sample 8559 - loss: 2.427779197692871\n",
      "Sample 8560 - loss: 0.08566518127918243\n",
      "Sample 8561 - loss: 0.013261391781270504\n",
      "Sample 8562 - loss: 0.5121222138404846\n",
      "Sample 8563 - loss: 0.9620729088783264\n",
      "Sample 8564 - loss: 1.1600677967071533\n",
      "Sample 8565 - loss: 3.5257623195648193\n",
      "Sample 8566 - loss: 4.172318935394287\n",
      "Sample 8567 - loss: 4.3775858879089355\n",
      "Sample 8568 - loss: 1.5120832920074463\n",
      "Sample 8569 - loss: 0.03971587494015694\n",
      "Sample 8570 - loss: 3.0921790599823\n",
      "Sample 8571 - loss: 2.6123569011688232\n",
      "Sample 8572 - loss: 1.4468109607696533\n",
      "Sample 8573 - loss: 0.21173572540283203\n",
      "Sample 8574 - loss: 3.9921329021453857\n",
      "Sample 8575 - loss: 0.12797589600086212\n",
      "Sample 8576 - loss: 0.2262730747461319\n",
      "Sample 8577 - loss: 0.29368484020233154\n",
      "Sample 8578 - loss: 0.3214878737926483\n",
      "Sample 8579 - loss: 0.988484263420105\n",
      "Sample 8580 - loss: 2.0417051315307617\n",
      "Sample 8581 - loss: 0.28341957926750183\n",
      "Sample 8582 - loss: 2.417872428894043\n",
      "Sample 8583 - loss: 0.005900771822780371\n",
      "Sample 8584 - loss: 0.6894460916519165\n",
      "Sample 8585 - loss: 0.4629446864128113\n",
      "Sample 8586 - loss: 0.0326613150537014\n",
      "Sample 8587 - loss: 6.074418544769287\n",
      "Sample 8588 - loss: 0.6532776355743408\n",
      "Sample 8589 - loss: 2.5705435276031494\n",
      "Sample 8590 - loss: 3.3581225872039795\n",
      "Sample 8591 - loss: 0.2549493908882141\n",
      "Sample 8592 - loss: 5.3989410400390625\n",
      "Sample 8593 - loss: 1.0317755937576294\n",
      "Sample 8594 - loss: 1.3836190700531006\n",
      "Sample 8595 - loss: 2.5866832733154297\n",
      "Sample 8596 - loss: 2.426870822906494\n",
      "Sample 8597 - loss: 0.10125121474266052\n",
      "Sample 8598 - loss: 2.3158669471740723\n",
      "Sample 8599 - loss: 3.8560051918029785\n",
      "Sample 8600 - loss: 3.4041948318481445\n",
      "Sample 8601 - loss: 6.36831521987915\n",
      "Sample 8602 - loss: 1.0331438779830933\n",
      "Sample 8603 - loss: 0.16158375144004822\n",
      "Sample 8604 - loss: 6.944140434265137\n",
      "Sample 8605 - loss: 1.1257586479187012\n",
      "Sample 8606 - loss: 4.23417854309082\n",
      "Sample 8607 - loss: 0.3918312191963196\n",
      "Sample 8608 - loss: 4.952425956726074\n",
      "Sample 8609 - loss: 0.525174081325531\n",
      "Sample 8610 - loss: 0.09354952722787857\n",
      "Sample 8611 - loss: 0.955556333065033\n",
      "Sample 8612 - loss: 4.915895462036133\n",
      "Sample 8613 - loss: 0.8636443614959717\n",
      "Sample 8614 - loss: 0.0014055323554202914\n",
      "Sample 8615 - loss: 2.422819137573242\n",
      "Sample 8616 - loss: 3.5080649852752686\n",
      "Sample 8617 - loss: 1.1008517742156982\n",
      "Sample 8618 - loss: 2.413438558578491\n",
      "Sample 8619 - loss: 0.15729598701000214\n",
      "Sample 8620 - loss: 0.5928175449371338\n",
      "Sample 8621 - loss: 0.48595574498176575\n",
      "Sample 8622 - loss: 0.6629518270492554\n",
      "Sample 8623 - loss: 0.005608402658253908\n",
      "Sample 8624 - loss: 3.339370012283325\n",
      "Sample 8625 - loss: 5.51326847076416\n",
      "Sample 8626 - loss: 2.0160915851593018\n",
      "Sample 8627 - loss: 0.04154571518301964\n",
      "Sample 8628 - loss: 0.057576004415750504\n",
      "Sample 8629 - loss: 0.3345412015914917\n",
      "Sample 8630 - loss: 0.2124105840921402\n",
      "Sample 8631 - loss: 0.15847507119178772\n",
      "Sample 8632 - loss: 0.29793062806129456\n",
      "Sample 8633 - loss: 0.3662036061286926\n",
      "Sample 8634 - loss: 6.050155162811279\n",
      "Sample 8635 - loss: 0.986043393611908\n",
      "Sample 8636 - loss: 1.4469974040985107\n",
      "Sample 8637 - loss: 5.7055745124816895\n",
      "Sample 8638 - loss: 5.792532920837402\n",
      "Sample 8639 - loss: 1.1278610229492188\n",
      "Sample 8640 - loss: 3.8867859840393066\n",
      "Sample 8641 - loss: 0.3453986346721649\n",
      "Sample 8642 - loss: 4.450549602508545\n",
      "Sample 8643 - loss: 0.8659351468086243\n",
      "Sample 8644 - loss: 3.080446243286133\n",
      "Sample 8645 - loss: 2.246211528778076\n",
      "Sample 8646 - loss: 3.201209306716919\n",
      "Sample 8647 - loss: 3.6860415935516357\n",
      "Sample 8648 - loss: 5.65254020690918\n",
      "Sample 8649 - loss: 0.06534631550312042\n",
      "Sample 8650 - loss: 0.6983930468559265\n",
      "Sample 8651 - loss: 1.475498914718628\n",
      "Sample 8652 - loss: 0.7619059681892395\n",
      "Sample 8653 - loss: 3.8077425956726074\n",
      "Sample 8654 - loss: 2.480860710144043\n",
      "Sample 8655 - loss: 2.1812431812286377\n",
      "Sample 8656 - loss: 0.3717502951622009\n",
      "Sample 8657 - loss: 2.423816204071045\n",
      "Sample 8658 - loss: 4.619516849517822\n",
      "Sample 8659 - loss: 0.8942130208015442\n",
      "Sample 8660 - loss: 3.738743782043457\n",
      "Sample 8661 - loss: 0.24606424570083618\n",
      "Sample 8662 - loss: 3.277651786804199\n",
      "Sample 8663 - loss: 0.3551415503025055\n",
      "Sample 8664 - loss: 1.5652564764022827\n",
      "Sample 8665 - loss: 0.8095940947532654\n",
      "Sample 8666 - loss: 3.939650535583496\n",
      "Sample 8667 - loss: 0.07565056532621384\n",
      "Sample 8668 - loss: 0.5951995849609375\n",
      "Sample 8669 - loss: 0.1681956648826599\n",
      "Sample 8670 - loss: 1.1457929611206055\n",
      "Sample 8671 - loss: 3.981923818588257\n",
      "Sample 8672 - loss: 2.4192726612091064\n",
      "Sample 8673 - loss: 2.9100911617279053\n",
      "Sample 8674 - loss: 7.182328701019287\n",
      "Sample 8675 - loss: 8.186678886413574\n",
      "Sample 8676 - loss: 0.2594369351863861\n",
      "Sample 8677 - loss: 2.094473361968994\n",
      "Sample 8678 - loss: 0.22299282252788544\n",
      "Sample 8679 - loss: 5.644639492034912\n",
      "Sample 8680 - loss: 1.0625087022781372\n",
      "Sample 8681 - loss: 2.1135976314544678\n",
      "Sample 8682 - loss: 0.7031338214874268\n",
      "Sample 8683 - loss: 5.744527816772461\n",
      "Sample 8684 - loss: 4.3631391525268555\n",
      "Sample 8685 - loss: 3.620378017425537\n",
      "Sample 8686 - loss: 0.22479276359081268\n",
      "Sample 8687 - loss: 0.020243650302290916\n",
      "Sample 8688 - loss: 0.37280333042144775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8689 - loss: 4.639659404754639\n",
      "Sample 8690 - loss: 2.7558813095092773\n",
      "Sample 8691 - loss: 0.03881509602069855\n",
      "Sample 8692 - loss: 0.771626889705658\n",
      "Sample 8693 - loss: 0.24683137238025665\n",
      "Sample 8694 - loss: 1.091058373451233\n",
      "Sample 8695 - loss: 3.736579179763794\n",
      "Sample 8696 - loss: 0.25325703620910645\n",
      "Sample 8697 - loss: 0.13690868020057678\n",
      "Sample 8698 - loss: 4.951959609985352\n",
      "Sample 8699 - loss: 1.9790366888046265\n",
      "Sample 8700 - loss: 3.7016539573669434\n",
      "Sample 8701 - loss: 3.524935007095337\n",
      "Sample 8702 - loss: 3.7170026302337646\n",
      "Sample 8703 - loss: 5.44577693939209\n",
      "Sample 8704 - loss: 1.4753588438034058\n",
      "Sample 8705 - loss: 0.23167158663272858\n",
      "Sample 8706 - loss: 0.19958944618701935\n",
      "Sample 8707 - loss: 0.9758987426757812\n",
      "Sample 8708 - loss: 7.406884670257568\n",
      "Sample 8709 - loss: 0.20108799636363983\n",
      "Sample 8710 - loss: 2.6971044540405273\n",
      "Sample 8711 - loss: 1.5964993238449097\n",
      "Sample 8712 - loss: 0.5897542238235474\n",
      "Sample 8713 - loss: 0.6538996696472168\n",
      "Sample 8714 - loss: 0.006788722239434719\n",
      "Sample 8715 - loss: 2.7796459197998047\n",
      "Sample 8716 - loss: 2.020354986190796\n",
      "Sample 8717 - loss: 0.3831509053707123\n",
      "Sample 8718 - loss: 4.9530510902404785\n",
      "Sample 8719 - loss: 2.650221586227417\n",
      "Sample 8720 - loss: 0.032630834728479385\n",
      "Sample 8721 - loss: 0.7583972215652466\n",
      "Sample 8722 - loss: 5.820006847381592\n",
      "Sample 8723 - loss: 2.45849871635437\n",
      "Sample 8724 - loss: 0.15738049149513245\n",
      "Sample 8725 - loss: 4.904028415679932\n",
      "Sample 8726 - loss: 0.04834047704935074\n",
      "Sample 8727 - loss: 0.3482968807220459\n",
      "Sample 8728 - loss: 4.170758247375488\n",
      "Sample 8729 - loss: 1.419661283493042\n",
      "Sample 8730 - loss: 0.44464796781539917\n",
      "Sample 8731 - loss: 3.8230292797088623\n",
      "Sample 8732 - loss: 4.129307746887207\n",
      "Sample 8733 - loss: 0.6839417815208435\n",
      "Sample 8734 - loss: 3.8052518367767334\n",
      "Sample 8735 - loss: 1.5045256614685059\n",
      "Sample 8736 - loss: 5.843604564666748\n",
      "Sample 8737 - loss: 1.379235029220581\n",
      "Sample 8738 - loss: 1.4822964668273926\n",
      "Sample 8739 - loss: 0.49823933839797974\n",
      "Sample 8740 - loss: 4.410208225250244\n",
      "Sample 8741 - loss: 4.170933246612549\n",
      "Sample 8742 - loss: 3.017002820968628\n",
      "Sample 8743 - loss: 2.1298794746398926\n",
      "Sample 8744 - loss: 2.0556466579437256\n",
      "Sample 8745 - loss: 1.6258745193481445\n",
      "Sample 8746 - loss: 0.9273725748062134\n",
      "Sample 8747 - loss: 0.6957672834396362\n",
      "Sample 8748 - loss: 4.036252021789551\n",
      "Sample 8749 - loss: 5.812831401824951\n",
      "Sample 8750 - loss: 0.9865067005157471\n",
      "Sample 8751 - loss: 1.9732654094696045\n",
      "Sample 8752 - loss: 0.6299035549163818\n",
      "Sample 8753 - loss: 0.04430541396141052\n",
      "Sample 8754 - loss: 0.22907602787017822\n",
      "Sample 8755 - loss: 0.017495347186923027\n",
      "Sample 8756 - loss: 2.113590955734253\n",
      "Sample 8757 - loss: 2.5597643852233887\n",
      "Sample 8758 - loss: 0.33028531074523926\n",
      "Sample 8759 - loss: 0.10994283854961395\n",
      "Sample 8760 - loss: 2.259610652923584\n",
      "Sample 8761 - loss: 5.226709365844727\n",
      "Sample 8762 - loss: 2.8118667602539062\n",
      "Sample 8763 - loss: 0.08747866749763489\n",
      "Sample 8764 - loss: 0.014006105251610279\n",
      "Sample 8765 - loss: 1.9862457513809204\n",
      "Sample 8766 - loss: 3.678096294403076\n",
      "Sample 8767 - loss: 1.0774191617965698\n",
      "Sample 8768 - loss: 0.785563588142395\n",
      "Sample 8769 - loss: 5.510487079620361\n",
      "Sample 8770 - loss: 2.424973726272583\n",
      "Sample 8771 - loss: 6.0586347579956055\n",
      "Sample 8772 - loss: 0.4421612620353699\n",
      "Sample 8773 - loss: 0.4178665280342102\n",
      "Sample 8774 - loss: 7.617570877075195\n",
      "Sample 8775 - loss: 6.711792469024658\n",
      "Sample 8776 - loss: 3.768237590789795\n",
      "Sample 8777 - loss: 1.5004935264587402\n",
      "Sample 8778 - loss: 1.683555006980896\n",
      "Sample 8779 - loss: 0.12230705469846725\n",
      "Sample 8780 - loss: 0.018531514331698418\n",
      "Sample 8781 - loss: 6.5638909339904785\n",
      "Sample 8782 - loss: 0.19164930284023285\n",
      "Sample 8783 - loss: 0.25325146317481995\n",
      "Sample 8784 - loss: 0.1112181544303894\n",
      "Sample 8785 - loss: 0.8318469524383545\n",
      "Sample 8786 - loss: 0.44202160835266113\n",
      "Sample 8787 - loss: 1.3207510709762573\n",
      "Sample 8788 - loss: 1.171465277671814\n",
      "Sample 8789 - loss: 0.7976329922676086\n",
      "Sample 8790 - loss: 6.684627056121826\n",
      "Sample 8791 - loss: 2.2916533946990967\n",
      "Sample 8792 - loss: 4.297945022583008\n",
      "Sample 8793 - loss: 4.869215965270996\n",
      "Sample 8794 - loss: 0.3822973668575287\n",
      "Sample 8795 - loss: 0.6176359057426453\n",
      "Sample 8796 - loss: 1.7695977687835693\n",
      "Sample 8797 - loss: 0.7553583383560181\n",
      "Sample 8798 - loss: 0.7007346153259277\n",
      "Sample 8799 - loss: 3.7388908863067627\n",
      "Sample 8800 - loss: 5.744743824005127\n",
      "Sample 8801 - loss: 3.905543327331543\n",
      "Sample 8802 - loss: 0.5837258100509644\n",
      "Sample 8803 - loss: 0.4834161698818207\n",
      "Sample 8804 - loss: 0.020936019718647003\n",
      "Sample 8805 - loss: 1.0194329023361206\n",
      "Sample 8806 - loss: 2.97921085357666\n",
      "Sample 8807 - loss: 4.622819900512695\n",
      "Sample 8808 - loss: 0.003031842177733779\n",
      "Sample 8809 - loss: 4.174928665161133\n",
      "Sample 8810 - loss: 0.3772106170654297\n",
      "Sample 8811 - loss: 4.708664417266846\n",
      "Sample 8812 - loss: 0.2980649769306183\n",
      "Sample 8813 - loss: 4.848980903625488\n",
      "Sample 8814 - loss: 2.4092085361480713\n",
      "Sample 8815 - loss: 3.830453872680664\n",
      "Sample 8816 - loss: 2.994150400161743\n",
      "Sample 8817 - loss: 0.5958461165428162\n",
      "Sample 8818 - loss: 0.17964743077754974\n",
      "Sample 8819 - loss: 0.026888705790042877\n",
      "Sample 8820 - loss: 0.5265408158302307\n",
      "Sample 8821 - loss: 1.7303767204284668\n",
      "Sample 8822 - loss: 0.19528207182884216\n",
      "Sample 8823 - loss: 0.050524644553661346\n",
      "Sample 8824 - loss: 2.2804038524627686\n",
      "Sample 8825 - loss: 1.6601530313491821\n",
      "Sample 8826 - loss: 0.37564513087272644\n",
      "Sample 8827 - loss: 2.322319269180298\n",
      "Sample 8828 - loss: 4.6769609451293945\n",
      "Sample 8829 - loss: 3.841428756713867\n",
      "Sample 8830 - loss: 0.23931658267974854\n",
      "Sample 8831 - loss: 4.992386341094971\n",
      "Sample 8832 - loss: 0.13659504055976868\n",
      "Sample 8833 - loss: 0.4286677837371826\n",
      "Sample 8834 - loss: 0.09695791453123093\n",
      "Sample 8835 - loss: 0.2802893817424774\n",
      "Sample 8836 - loss: 0.8834774494171143\n",
      "Sample 8837 - loss: 0.3324507772922516\n",
      "Sample 8838 - loss: 0.6755815148353577\n",
      "Sample 8839 - loss: 0.0891493633389473\n",
      "Sample 8840 - loss: 0.6417394876480103\n",
      "Sample 8841 - loss: 0.9904208183288574\n",
      "Sample 8842 - loss: 0.06473478674888611\n",
      "Sample 8843 - loss: 0.4068319797515869\n",
      "Sample 8844 - loss: 0.11141535639762878\n",
      "Sample 8845 - loss: 0.041591741144657135\n",
      "Sample 8846 - loss: 0.4927038252353668\n",
      "Sample 8847 - loss: 2.8543076515197754\n",
      "Sample 8848 - loss: 1.4451239109039307\n",
      "Sample 8849 - loss: 2.8617687225341797\n",
      "Sample 8850 - loss: 0.1758715957403183\n",
      "Sample 8851 - loss: 0.13096964359283447\n",
      "Sample 8852 - loss: 1.8718254566192627\n",
      "Sample 8853 - loss: 1.7955516576766968\n",
      "Sample 8854 - loss: 6.69723653793335\n",
      "Sample 8855 - loss: 1.279312014579773\n",
      "Sample 8856 - loss: 0.10602696239948273\n",
      "Sample 8857 - loss: 1.050978660583496\n",
      "Sample 8858 - loss: 0.3295063078403473\n",
      "Sample 8859 - loss: 0.5430629849433899\n",
      "Sample 8860 - loss: 2.485952377319336\n",
      "Sample 8861 - loss: 0.0634247362613678\n",
      "Sample 8862 - loss: 3.2270612716674805\n",
      "Sample 8863 - loss: 3.412893772125244\n",
      "Sample 8864 - loss: 0.2786141335964203\n",
      "Sample 8865 - loss: 1.405938744544983\n",
      "Sample 8866 - loss: 0.16414771974086761\n",
      "Sample 8867 - loss: 0.533775269985199\n",
      "Sample 8868 - loss: 1.0998384952545166\n",
      "Sample 8869 - loss: 0.9042690992355347\n",
      "Sample 8870 - loss: 1.549686074256897\n",
      "Sample 8871 - loss: 0.06179605796933174\n",
      "Sample 8872 - loss: 0.5758996605873108\n",
      "Sample 8873 - loss: 1.1580462455749512\n",
      "Sample 8874 - loss: 2.8708629608154297\n",
      "Sample 8875 - loss: 2.0851850509643555\n",
      "Sample 8876 - loss: 2.544046401977539\n",
      "Sample 8877 - loss: 3.154684543609619\n",
      "Sample 8878 - loss: 0.739388644695282\n",
      "Sample 8879 - loss: 6.0813727378845215\n",
      "Sample 8880 - loss: 3.6285083293914795\n",
      "Sample 8881 - loss: 6.110265731811523\n",
      "Sample 8882 - loss: 0.8501437306404114\n",
      "Sample 8883 - loss: 0.5438354015350342\n",
      "Sample 8884 - loss: 1.819886326789856\n",
      "Sample 8885 - loss: 2.0609378814697266\n",
      "Sample 8886 - loss: 5.565687656402588\n",
      "Sample 8887 - loss: 0.00144089269451797\n",
      "Sample 8888 - loss: 0.7246218323707581\n",
      "Sample 8889 - loss: 3.204281806945801\n",
      "Sample 8890 - loss: 0.02978327125310898\n",
      "Sample 8891 - loss: 0.4643191993236542\n",
      "Sample 8892 - loss: 6.142453670501709\n",
      "Sample 8893 - loss: 5.1674017906188965\n",
      "Sample 8894 - loss: 1.1965017318725586\n",
      "Sample 8895 - loss: 0.9910690188407898\n",
      "Sample 8896 - loss: 1.8675352334976196\n",
      "Sample 8897 - loss: 1.5653741359710693\n",
      "Sample 8898 - loss: 5.318683624267578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8899 - loss: 0.013633770868182182\n",
      "Sample 8900 - loss: 0.0715101808309555\n",
      "Sample 8901 - loss: 4.914303302764893\n",
      "Sample 8902 - loss: 1.7362884283065796\n",
      "Sample 8903 - loss: 0.28464993834495544\n",
      "Sample 8904 - loss: 3.5152428150177\n",
      "Sample 8905 - loss: 4.722088813781738\n",
      "Sample 8906 - loss: 1.9884788990020752\n",
      "Sample 8907 - loss: 0.49971023201942444\n",
      "Sample 8908 - loss: 0.5829059481620789\n",
      "Sample 8909 - loss: 2.659088373184204\n",
      "Sample 8910 - loss: 3.581036329269409\n",
      "Sample 8911 - loss: 1.067683219909668\n",
      "Sample 8912 - loss: 1.219698190689087\n",
      "Sample 8913 - loss: 3.6500895023345947\n",
      "Sample 8914 - loss: 0.8535771369934082\n",
      "Sample 8915 - loss: 0.07236852496862411\n",
      "Sample 8916 - loss: 0.1014934703707695\n",
      "Sample 8917 - loss: 4.948268413543701\n",
      "Sample 8918 - loss: 0.08689752221107483\n",
      "Sample 8919 - loss: 2.0585880279541016\n",
      "Sample 8920 - loss: 0.37430086731910706\n",
      "Sample 8921 - loss: 0.940549910068512\n",
      "Sample 8922 - loss: 3.0277493000030518\n",
      "Sample 8923 - loss: 3.3082244396209717\n",
      "Sample 8924 - loss: 0.7271867990493774\n",
      "Sample 8925 - loss: 0.665877103805542\n",
      "Sample 8926 - loss: 4.6794209480285645\n",
      "Sample 8927 - loss: 0.011790072545409203\n",
      "Sample 8928 - loss: 0.5239204168319702\n",
      "Sample 8929 - loss: 0.13345475494861603\n",
      "Sample 8930 - loss: 2.877899169921875\n",
      "Sample 8931 - loss: 0.38745060563087463\n",
      "Sample 8932 - loss: 0.28970396518707275\n",
      "Sample 8933 - loss: 1.8857275247573853\n",
      "Sample 8934 - loss: 3.3415210247039795\n",
      "Sample 8935 - loss: 2.532548189163208\n",
      "Sample 8936 - loss: 0.5936853885650635\n",
      "Sample 8937 - loss: 0.23812036216259003\n",
      "Sample 8938 - loss: 2.3289010524749756\n",
      "Sample 8939 - loss: 0.15560252964496613\n",
      "Sample 8940 - loss: 1.8763420581817627\n",
      "Sample 8941 - loss: 0.14468249678611755\n",
      "Sample 8942 - loss: 0.8541375994682312\n",
      "Sample 8943 - loss: 4.324556827545166\n",
      "Sample 8944 - loss: 1.5030697584152222\n",
      "Sample 8945 - loss: 1.3240922689437866\n",
      "Sample 8946 - loss: 3.23750376701355\n",
      "Sample 8947 - loss: 0.6421039700508118\n",
      "Sample 8948 - loss: 0.5975344181060791\n",
      "Sample 8949 - loss: 0.4305492341518402\n",
      "Sample 8950 - loss: 0.04677583649754524\n",
      "Sample 8951 - loss: 3.2490286827087402\n",
      "Sample 8952 - loss: 6.199037075042725\n",
      "Sample 8953 - loss: 1.7909362316131592\n",
      "Sample 8954 - loss: 0.021755559369921684\n",
      "Sample 8955 - loss: 2.7387802600860596\n",
      "Sample 8956 - loss: 3.6880593299865723\n",
      "Sample 8957 - loss: 2.128208875656128\n",
      "Sample 8958 - loss: 6.1234049797058105\n",
      "Sample 8959 - loss: 2.203338384628296\n",
      "Sample 8960 - loss: 0.36838364601135254\n",
      "Sample 8961 - loss: 4.378636837005615\n",
      "Sample 8962 - loss: 3.1352715492248535\n",
      "Sample 8963 - loss: 0.011456881649792194\n",
      "Sample 8964 - loss: 0.20869584381580353\n",
      "Sample 8965 - loss: 0.03645213693380356\n",
      "Sample 8966 - loss: 3.6725528240203857\n",
      "Sample 8967 - loss: 1.298958420753479\n",
      "Sample 8968 - loss: 2.2881433963775635\n",
      "Sample 8969 - loss: 1.959633469581604\n",
      "Sample 8970 - loss: 5.256011486053467\n",
      "Sample 8971 - loss: 1.546730637550354\n",
      "Sample 8972 - loss: 0.07979125529527664\n",
      "Sample 8973 - loss: 0.48881977796554565\n",
      "Sample 8974 - loss: 1.0769747495651245\n",
      "Sample 8975 - loss: 2.246595859527588\n",
      "Sample 8976 - loss: 0.30019909143447876\n",
      "Sample 8977 - loss: 0.0989411473274231\n",
      "Sample 8978 - loss: 0.8771862983703613\n",
      "Sample 8979 - loss: 1.4196888208389282\n",
      "Sample 8980 - loss: 1.131493091583252\n",
      "Sample 8981 - loss: 0.2512577176094055\n",
      "Sample 8982 - loss: 4.927901744842529\n",
      "Sample 8983 - loss: 3.127779960632324\n",
      "Sample 8984 - loss: 0.3113246560096741\n",
      "Sample 8985 - loss: 4.385643482208252\n",
      "Sample 8986 - loss: 6.6695122718811035\n",
      "Sample 8987 - loss: 6.110440731048584\n",
      "Sample 8988 - loss: 0.01688036322593689\n",
      "Sample 8989 - loss: 0.12043096870183945\n",
      "Sample 8990 - loss: 2.287233352661133\n",
      "Sample 8991 - loss: 1.0299705266952515\n",
      "Sample 8992 - loss: 0.6254485845565796\n",
      "Sample 8993 - loss: 1.6616129875183105\n",
      "Sample 8994 - loss: 1.7242441177368164\n",
      "Sample 8995 - loss: 7.127415657043457\n",
      "Sample 8996 - loss: 0.08469326794147491\n",
      "Sample 8997 - loss: 0.3598184585571289\n",
      "Sample 8998 - loss: 1.170911431312561\n",
      "Sample 8999 - loss: 0.11433947831392288\n",
      "Sample 9000 - loss: 0.7200028896331787\n",
      "Sample 9001 - loss: 0.743380606174469\n",
      "Sample 9002 - loss: 0.19898296892642975\n",
      "Sample 9003 - loss: 0.07685234397649765\n",
      "Sample 9004 - loss: 5.162054538726807\n",
      "Sample 9005 - loss: 1.2470890283584595\n",
      "Sample 9006 - loss: 1.383309006690979\n",
      "Sample 9007 - loss: 2.7374017238616943\n",
      "Sample 9008 - loss: 1.5306185483932495\n",
      "Sample 9009 - loss: 3.052184820175171\n",
      "Sample 9010 - loss: 3.2722949981689453\n",
      "Sample 9011 - loss: 4.81072473526001\n",
      "Sample 9012 - loss: 0.23725715279579163\n",
      "Sample 9013 - loss: 0.9073178768157959\n",
      "Sample 9014 - loss: 2.2048070430755615\n",
      "Sample 9015 - loss: 0.627441942691803\n",
      "Sample 9016 - loss: 5.813629627227783\n",
      "Sample 9017 - loss: 0.13487058877944946\n",
      "Sample 9018 - loss: 3.778416633605957\n",
      "Sample 9019 - loss: 0.08364223688840866\n",
      "Sample 9020 - loss: 1.1104589700698853\n",
      "Sample 9021 - loss: 1.5521483421325684\n",
      "Sample 9022 - loss: 0.306608110666275\n",
      "Sample 9023 - loss: 0.9180971384048462\n",
      "Sample 9024 - loss: 0.3869542181491852\n",
      "Sample 9025 - loss: 1.0847506523132324\n",
      "Sample 9026 - loss: 1.7286545038223267\n",
      "Sample 9027 - loss: 0.3677237629890442\n",
      "Sample 9028 - loss: 0.00691439351066947\n",
      "Sample 9029 - loss: 1.2182255983352661\n",
      "Sample 9030 - loss: 0.29214921593666077\n",
      "Sample 9031 - loss: 0.13684199750423431\n",
      "Sample 9032 - loss: 0.6573565006256104\n",
      "Sample 9033 - loss: 0.02880963869392872\n",
      "Sample 9034 - loss: 1.0805343389511108\n",
      "Sample 9035 - loss: 2.6081392765045166\n",
      "Sample 9036 - loss: 3.9887146949768066\n",
      "Sample 9037 - loss: 0.013535008765757084\n",
      "Sample 9038 - loss: 0.7492073774337769\n",
      "Sample 9039 - loss: 0.05325951427221298\n",
      "Sample 9040 - loss: 0.78094482421875\n",
      "Sample 9041 - loss: 2.5961008071899414\n",
      "Sample 9042 - loss: 1.6640219688415527\n",
      "Sample 9043 - loss: 1.9265875816345215\n",
      "Sample 9044 - loss: 1.6927000284194946\n",
      "Sample 9045 - loss: 6.082214832305908\n",
      "Sample 9046 - loss: 1.8559107780456543\n",
      "Sample 9047 - loss: 0.6578394174575806\n",
      "Sample 9048 - loss: 0.04467139393091202\n",
      "Sample 9049 - loss: 1.5063129663467407\n",
      "Sample 9050 - loss: 0.26602330803871155\n",
      "Sample 9051 - loss: 2.225285768508911\n",
      "Sample 9052 - loss: 2.286182403564453\n",
      "Sample 9053 - loss: 0.6888781785964966\n",
      "Sample 9054 - loss: 1.3834190368652344\n",
      "Sample 9055 - loss: 0.07848943769931793\n",
      "Sample 9056 - loss: 0.3150077164173126\n",
      "Sample 9057 - loss: 4.1122002601623535\n",
      "Sample 9058 - loss: 1.0630431175231934\n",
      "Sample 9059 - loss: 1.1891379356384277\n",
      "Sample 9060 - loss: 0.04049806669354439\n",
      "Sample 9061 - loss: 0.03627869114279747\n",
      "Sample 9062 - loss: 2.3657469749450684\n",
      "Sample 9063 - loss: 2.441197156906128\n",
      "Sample 9064 - loss: 0.040798500180244446\n",
      "Sample 9065 - loss: 1.748883843421936\n",
      "Sample 9066 - loss: 0.06350574642419815\n",
      "Sample 9067 - loss: 0.16916915774345398\n",
      "Sample 9068 - loss: 1.2003223896026611\n",
      "Sample 9069 - loss: 0.06413646787405014\n",
      "Sample 9070 - loss: 4.866736888885498\n",
      "Sample 9071 - loss: 0.012075909413397312\n",
      "Sample 9072 - loss: 0.7418660521507263\n",
      "Sample 9073 - loss: 1.1431061029434204\n",
      "Sample 9074 - loss: 0.36538875102996826\n",
      "Sample 9075 - loss: 0.02520591951906681\n",
      "Sample 9076 - loss: 2.285188913345337\n",
      "Sample 9077 - loss: 0.03724667429924011\n",
      "Sample 9078 - loss: 1.5075889825820923\n",
      "Sample 9079 - loss: 1.33854079246521\n",
      "Sample 9080 - loss: 0.32563552260398865\n",
      "Sample 9081 - loss: 0.22031062841415405\n",
      "Sample 9082 - loss: 1.0822902917861938\n",
      "Sample 9083 - loss: 6.549554347991943\n",
      "Sample 9084 - loss: 4.110029220581055\n",
      "Sample 9085 - loss: 0.9381330013275146\n",
      "Sample 9086 - loss: 0.6918188333511353\n",
      "Sample 9087 - loss: 0.5788403153419495\n",
      "Sample 9088 - loss: 0.44349586963653564\n",
      "Sample 9089 - loss: 0.4990255832672119\n",
      "Sample 9090 - loss: 1.8238036632537842\n",
      "Sample 9091 - loss: 0.6651684641838074\n",
      "Sample 9092 - loss: 5.454263687133789\n",
      "Sample 9093 - loss: 6.77360725402832\n",
      "Sample 9094 - loss: 2.8545753955841064\n",
      "Sample 9095 - loss: 0.514697253704071\n",
      "Sample 9096 - loss: 0.20898674428462982\n",
      "Sample 9097 - loss: 1.420143723487854\n",
      "Sample 9098 - loss: 0.3071838319301605\n",
      "Sample 9099 - loss: 2.901975154876709\n",
      "Sample 9100 - loss: 0.7698549032211304\n",
      "Sample 9101 - loss: 0.7436324954032898\n",
      "Sample 9102 - loss: 4.735479354858398\n",
      "Sample 9103 - loss: 2.296372890472412\n",
      "Sample 9104 - loss: 0.03325026482343674\n",
      "Sample 9105 - loss: 0.8233514428138733\n",
      "Sample 9106 - loss: 0.023018769919872284\n",
      "Sample 9107 - loss: 3.096874475479126\n",
      "Sample 9108 - loss: 1.0384010076522827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9109 - loss: 3.9807801246643066\n",
      "Sample 9110 - loss: 0.8311174511909485\n",
      "Sample 9111 - loss: 2.5792605876922607\n",
      "Sample 9112 - loss: 0.8215724229812622\n",
      "Sample 9113 - loss: 2.9871749877929688\n",
      "Sample 9114 - loss: 0.034913524985313416\n",
      "Sample 9115 - loss: 3.1074352264404297\n",
      "Sample 9116 - loss: 1.9495333433151245\n",
      "Sample 9117 - loss: 0.4119071066379547\n",
      "Sample 9118 - loss: 2.114556312561035\n",
      "Sample 9119 - loss: 0.3326568901538849\n",
      "Sample 9120 - loss: 1.1940693855285645\n",
      "Sample 9121 - loss: 0.2371469885110855\n",
      "Sample 9122 - loss: 1.6286715269088745\n",
      "Sample 9123 - loss: 2.027831792831421\n",
      "Sample 9124 - loss: 1.2475298643112183\n",
      "Sample 9125 - loss: 2.463792562484741\n",
      "Sample 9126 - loss: 0.7131487131118774\n",
      "Sample 9127 - loss: 1.5290191173553467\n",
      "Sample 9128 - loss: 0.4687136113643646\n",
      "Sample 9129 - loss: 1.9345327615737915\n",
      "Sample 9130 - loss: 2.139918804168701\n",
      "Sample 9131 - loss: 1.1418659687042236\n",
      "Sample 9132 - loss: 4.878259181976318\n",
      "Sample 9133 - loss: 0.33296898007392883\n",
      "Sample 9134 - loss: 5.689338207244873\n",
      "Sample 9135 - loss: 2.241525650024414\n",
      "Sample 9136 - loss: 2.2415616512298584\n",
      "Sample 9137 - loss: 1.1493512392044067\n",
      "Sample 9138 - loss: 2.49076247215271\n",
      "Sample 9139 - loss: 4.257941722869873\n",
      "Sample 9140 - loss: 0.04209084063768387\n",
      "Sample 9141 - loss: 4.5738019943237305\n",
      "Sample 9142 - loss: 0.9963822960853577\n",
      "Sample 9143 - loss: 4.294320583343506\n",
      "Sample 9144 - loss: 0.020182250067591667\n",
      "Sample 9145 - loss: 4.224737167358398\n",
      "Sample 9146 - loss: 2.4110004901885986\n",
      "Sample 9147 - loss: 1.8431711196899414\n",
      "Sample 9148 - loss: 0.325267493724823\n",
      "Sample 9149 - loss: 1.522565484046936\n",
      "Sample 9150 - loss: 0.9429713487625122\n",
      "Sample 9151 - loss: 0.8043677806854248\n",
      "Sample 9152 - loss: 0.11238208413124084\n",
      "Sample 9153 - loss: 1.4770468473434448\n",
      "Sample 9154 - loss: 3.301285982131958\n",
      "Sample 9155 - loss: 4.781845569610596\n",
      "Sample 9156 - loss: 0.3241824805736542\n",
      "Sample 9157 - loss: 6.833245754241943\n",
      "Sample 9158 - loss: 1.9049139022827148\n",
      "Sample 9159 - loss: 0.28544893860816956\n",
      "Sample 9160 - loss: 1.2605617046356201\n",
      "Sample 9161 - loss: 0.33430689573287964\n",
      "Sample 9162 - loss: 0.7219064235687256\n",
      "Sample 9163 - loss: 2.5966804027557373\n",
      "Sample 9164 - loss: 6.523219585418701\n",
      "Sample 9165 - loss: 0.7255708575248718\n",
      "Sample 9166 - loss: 0.7907801866531372\n",
      "Sample 9167 - loss: 0.008725014515221119\n",
      "Sample 9168 - loss: 0.4665576219558716\n",
      "Sample 9169 - loss: 0.26428547501564026\n",
      "Sample 9170 - loss: 5.810054302215576\n",
      "Sample 9171 - loss: 0.5733686685562134\n",
      "Sample 9172 - loss: 0.17886093258857727\n",
      "Sample 9173 - loss: 0.6040369272232056\n",
      "Sample 9174 - loss: 2.597729444503784\n",
      "Sample 9175 - loss: 5.14361572265625\n",
      "Sample 9176 - loss: 1.2374764680862427\n",
      "Sample 9177 - loss: 0.6033077836036682\n",
      "Sample 9178 - loss: 0.06115167960524559\n",
      "Sample 9179 - loss: 4.742253303527832\n",
      "Sample 9180 - loss: 0.8122782111167908\n",
      "Sample 9181 - loss: 0.01299306284636259\n",
      "Sample 9182 - loss: 2.2729597091674805\n",
      "Sample 9183 - loss: 2.0518364906311035\n",
      "Sample 9184 - loss: 0.014859387651085854\n",
      "Sample 9185 - loss: 0.6848689317703247\n",
      "Sample 9186 - loss: 0.015781711786985397\n",
      "Sample 9187 - loss: 1.6352081298828125\n",
      "Sample 9188 - loss: 1.0881305932998657\n",
      "Sample 9189 - loss: 0.011950217187404633\n",
      "Sample 9190 - loss: 1.4574916362762451\n",
      "Sample 9191 - loss: 4.639221668243408\n",
      "Sample 9192 - loss: 0.025842003524303436\n",
      "Sample 9193 - loss: 3.8024117946624756\n",
      "Sample 9194 - loss: 2.1811482906341553\n",
      "Sample 9195 - loss: 2.8415114879608154\n",
      "Sample 9196 - loss: 5.414989471435547\n",
      "Sample 9197 - loss: 2.567587375640869\n",
      "Sample 9198 - loss: 4.58329963684082\n",
      "Sample 9199 - loss: 1.126013159751892\n",
      "Sample 9200 - loss: 0.7037899494171143\n",
      "Sample 9201 - loss: 1.0920233726501465\n",
      "Sample 9202 - loss: 3.377051591873169\n",
      "Sample 9203 - loss: 6.803634166717529\n",
      "Sample 9204 - loss: 0.008264023810625076\n",
      "Sample 9205 - loss: 2.237090587615967\n",
      "Sample 9206 - loss: 0.2096690535545349\n",
      "Sample 9207 - loss: 0.12106207758188248\n",
      "Sample 9208 - loss: 0.39922845363616943\n",
      "Sample 9209 - loss: 1.929235577583313\n",
      "Sample 9210 - loss: 3.535581588745117\n",
      "Sample 9211 - loss: 2.018838882446289\n",
      "Sample 9212 - loss: 1.9153964519500732\n",
      "Sample 9213 - loss: 0.2838224172592163\n",
      "Sample 9214 - loss: 1.3057076930999756\n",
      "Sample 9215 - loss: 0.04732765257358551\n",
      "Sample 9216 - loss: 0.09333248436450958\n",
      "Sample 9217 - loss: 1.2040905952453613\n",
      "Sample 9218 - loss: 1.381546974182129\n",
      "Sample 9219 - loss: 0.16421476006507874\n",
      "Sample 9220 - loss: 7.857402324676514\n",
      "Sample 9221 - loss: 0.09115514904260635\n",
      "Sample 9222 - loss: 5.363754749298096\n",
      "Sample 9223 - loss: 0.428436279296875\n",
      "Sample 9224 - loss: 0.16362890601158142\n",
      "Sample 9225 - loss: 0.10938318073749542\n",
      "Sample 9226 - loss: 2.0349321365356445\n",
      "Sample 9227 - loss: 3.9194061756134033\n",
      "Sample 9228 - loss: 0.950852632522583\n",
      "Sample 9229 - loss: 0.11075568944215775\n",
      "Sample 9230 - loss: 0.878396213054657\n",
      "Sample 9231 - loss: 1.1857990026474\n",
      "Sample 9232 - loss: 3.0757110118865967\n",
      "Sample 9233 - loss: 0.591250479221344\n",
      "Sample 9234 - loss: 0.074204221367836\n",
      "Sample 9235 - loss: 0.42587047815322876\n",
      "Sample 9236 - loss: 3.3335704803466797\n",
      "Sample 9237 - loss: 4.053947925567627\n",
      "Sample 9238 - loss: 0.17174844443798065\n",
      "Sample 9239 - loss: 2.999539375305176\n",
      "Sample 9240 - loss: 1.5811817646026611\n",
      "Sample 9241 - loss: 0.1789703369140625\n",
      "Sample 9242 - loss: 0.4106256067752838\n",
      "Sample 9243 - loss: 3.382180690765381\n",
      "Sample 9244 - loss: 0.24063067138195038\n",
      "Sample 9245 - loss: 1.5150845050811768\n",
      "Sample 9246 - loss: 0.17358167469501495\n",
      "Sample 9247 - loss: 0.7640764713287354\n",
      "Sample 9248 - loss: 4.864790916442871\n",
      "Sample 9249 - loss: 0.600106418132782\n",
      "Sample 9250 - loss: 2.4409847259521484\n",
      "Sample 9251 - loss: 1.5291637182235718\n",
      "Sample 9252 - loss: 2.196810245513916\n",
      "Sample 9253 - loss: 2.4897384643554688\n",
      "Sample 9254 - loss: 2.054931163787842\n",
      "Sample 9255 - loss: 1.0596227645874023\n",
      "Sample 9256 - loss: 0.577276885509491\n",
      "Sample 9257 - loss: 0.3587990701198578\n",
      "Sample 9258 - loss: 0.07319582253694534\n",
      "Sample 9259 - loss: 1.8302754163742065\n",
      "Sample 9260 - loss: 3.150489568710327\n",
      "Sample 9261 - loss: 0.9140726327896118\n",
      "Sample 9262 - loss: 0.7445338368415833\n",
      "Sample 9263 - loss: 0.39694127440452576\n",
      "Sample 9264 - loss: 1.0401233434677124\n",
      "Sample 9265 - loss: 4.8039774894714355\n",
      "Sample 9266 - loss: 0.07785941660404205\n",
      "Sample 9267 - loss: 2.252948045730591\n",
      "Sample 9268 - loss: 0.04030020534992218\n",
      "Sample 9269 - loss: 4.607790946960449\n",
      "Sample 9270 - loss: 3.459350824356079\n",
      "Sample 9271 - loss: 5.069024562835693\n",
      "Sample 9272 - loss: 2.7247202396392822\n",
      "Sample 9273 - loss: 0.9912299513816833\n",
      "Sample 9274 - loss: 1.9447036981582642\n",
      "Sample 9275 - loss: 3.8636364936828613\n",
      "Sample 9276 - loss: 0.014524242840707302\n",
      "Sample 9277 - loss: 1.2601139545440674\n",
      "Sample 9278 - loss: 3.3315374851226807\n",
      "Sample 9279 - loss: 1.09453547000885\n",
      "Sample 9280 - loss: 1.07355535030365\n",
      "Sample 9281 - loss: 1.3422801494598389\n",
      "Sample 9282 - loss: 1.3648775815963745\n",
      "Sample 9283 - loss: 0.17946475744247437\n",
      "Sample 9284 - loss: 0.8479260206222534\n",
      "Sample 9285 - loss: 0.791339099407196\n",
      "Sample 9286 - loss: 1.0348280668258667\n",
      "Sample 9287 - loss: 0.16844941675662994\n",
      "Sample 9288 - loss: 0.46250611543655396\n",
      "Sample 9289 - loss: 2.347860813140869\n",
      "Sample 9290 - loss: 0.05535631626844406\n",
      "Sample 9291 - loss: 2.899967908859253\n",
      "Sample 9292 - loss: 3.714881181716919\n",
      "Sample 9293 - loss: 0.6127390265464783\n",
      "Sample 9294 - loss: 0.4989945888519287\n",
      "Sample 9295 - loss: 2.5400171279907227\n",
      "Sample 9296 - loss: 2.890577793121338\n",
      "Sample 9297 - loss: 2.181243896484375\n",
      "Sample 9298 - loss: 0.21054363250732422\n",
      "Sample 9299 - loss: 1.0213398933410645\n",
      "Sample 9300 - loss: 3.3346328735351562\n",
      "Sample 9301 - loss: 0.29081785678863525\n",
      "Sample 9302 - loss: 1.1276034116744995\n",
      "Sample 9303 - loss: 1.8362797498703003\n",
      "Sample 9304 - loss: 0.046636976301670074\n",
      "Sample 9305 - loss: 2.4764766693115234\n",
      "Sample 9306 - loss: 1.8438141345977783\n",
      "Sample 9307 - loss: 5.3567328453063965\n",
      "Sample 9308 - loss: 2.8425710201263428\n",
      "Sample 9309 - loss: 1.108428955078125\n",
      "Sample 9310 - loss: 1.1570507287979126\n",
      "Sample 9311 - loss: 0.017269214615225792\n",
      "Sample 9312 - loss: 0.5076224207878113\n",
      "Sample 9313 - loss: 4.949129104614258\n",
      "Sample 9314 - loss: 1.4302423000335693\n",
      "Sample 9315 - loss: 0.6031715273857117\n",
      "Sample 9316 - loss: 1.5720897912979126\n",
      "Sample 9317 - loss: 1.1426020860671997\n",
      "Sample 9318 - loss: 1.0592963695526123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9319 - loss: 4.203414440155029\n",
      "Sample 9320 - loss: 3.9022557735443115\n",
      "Sample 9321 - loss: 0.05890766158699989\n",
      "Sample 9322 - loss: 0.2931261956691742\n",
      "Sample 9323 - loss: 0.03327822685241699\n",
      "Sample 9324 - loss: 3.0871429443359375\n",
      "Sample 9325 - loss: 0.4106058180332184\n",
      "Sample 9326 - loss: 0.16351330280303955\n",
      "Sample 9327 - loss: 0.4252275824546814\n",
      "Sample 9328 - loss: 1.4564770460128784\n",
      "Sample 9329 - loss: 1.8636221885681152\n",
      "Sample 9330 - loss: 3.263662099838257\n",
      "Sample 9331 - loss: 1.4554028511047363\n",
      "Sample 9332 - loss: 3.547023296356201\n",
      "Sample 9333 - loss: 0.03353949263691902\n",
      "Sample 9334 - loss: 2.03304386138916\n",
      "Sample 9335 - loss: 0.042210813611745834\n",
      "Sample 9336 - loss: 1.6112010478973389\n",
      "Sample 9337 - loss: 2.3222475051879883\n",
      "Sample 9338 - loss: 0.38071736693382263\n",
      "Sample 9339 - loss: 1.3094604015350342\n",
      "Sample 9340 - loss: 0.36368435621261597\n",
      "Sample 9341 - loss: 0.8859326243400574\n",
      "Sample 9342 - loss: 0.011986255645751953\n",
      "Sample 9343 - loss: 5.154790878295898\n",
      "Sample 9344 - loss: 6.916891098022461\n",
      "Sample 9345 - loss: 0.029346400871872902\n",
      "Sample 9346 - loss: 6.811041355133057\n",
      "Sample 9347 - loss: 2.1203460693359375\n",
      "Sample 9348 - loss: 0.6699054837226868\n",
      "Sample 9349 - loss: 0.12094644457101822\n",
      "Sample 9350 - loss: 1.7297658920288086\n",
      "Sample 9351 - loss: 0.570733368396759\n",
      "Sample 9352 - loss: 0.7161791920661926\n",
      "Sample 9353 - loss: 0.1429174840450287\n",
      "Sample 9354 - loss: 0.6335543990135193\n",
      "Sample 9355 - loss: 2.331404209136963\n",
      "Sample 9356 - loss: 0.0030687465332448483\n",
      "Sample 9357 - loss: 0.06297647207975388\n",
      "Sample 9358 - loss: 2.205400228500366\n",
      "Sample 9359 - loss: 0.2595568895339966\n",
      "Sample 9360 - loss: 1.0512442588806152\n",
      "Sample 9361 - loss: 4.772609233856201\n",
      "Sample 9362 - loss: 0.5784750580787659\n",
      "Sample 9363 - loss: 3.4195058345794678\n",
      "Sample 9364 - loss: 5.3852033615112305\n",
      "Sample 9365 - loss: 2.8376898765563965\n",
      "Sample 9366 - loss: 2.2402117252349854\n",
      "Sample 9367 - loss: 1.9509412050247192\n",
      "Sample 9368 - loss: 3.6286826133728027\n",
      "Sample 9369 - loss: 1.2570658922195435\n",
      "Sample 9370 - loss: 0.4519510567188263\n",
      "Sample 9371 - loss: 1.0305362939834595\n",
      "Sample 9372 - loss: 0.5614237785339355\n",
      "Sample 9373 - loss: 1.0021299123764038\n",
      "Sample 9374 - loss: 0.1596481055021286\n",
      "Sample 9375 - loss: 1.7756980657577515\n",
      "Sample 9376 - loss: 7.227682590484619\n",
      "Sample 9377 - loss: 5.027231216430664\n",
      "Sample 9378 - loss: 2.1195998191833496\n",
      "Sample 9379 - loss: 5.297607421875\n",
      "Sample 9380 - loss: 7.318271636962891\n",
      "Sample 9381 - loss: 0.8153248429298401\n",
      "Sample 9382 - loss: 2.331200122833252\n",
      "Sample 9383 - loss: 1.4184107780456543\n",
      "Sample 9384 - loss: 2.280186414718628\n",
      "Sample 9385 - loss: 0.16803987324237823\n",
      "Sample 9386 - loss: 0.7357568144798279\n",
      "Sample 9387 - loss: 0.8347702622413635\n",
      "Sample 9388 - loss: 0.9146878123283386\n",
      "Sample 9389 - loss: 2.046311140060425\n",
      "Sample 9390 - loss: 0.552348792552948\n",
      "Sample 9391 - loss: 5.204376220703125\n",
      "Sample 9392 - loss: 3.1895265579223633\n",
      "Sample 9393 - loss: 2.304548978805542\n",
      "Sample 9394 - loss: 4.080567359924316\n",
      "Sample 9395 - loss: 1.5404516458511353\n",
      "Sample 9396 - loss: 2.99790096282959\n",
      "Sample 9397 - loss: 0.2843400835990906\n",
      "Sample 9398 - loss: 1.2362736463546753\n",
      "Sample 9399 - loss: 4.579947471618652\n",
      "Sample 9400 - loss: 1.4256205558776855\n",
      "Sample 9401 - loss: 0.135747492313385\n",
      "Sample 9402 - loss: 6.858237266540527\n",
      "Sample 9403 - loss: 0.752488374710083\n",
      "Sample 9404 - loss: 2.383341073989868\n",
      "Sample 9405 - loss: 0.6762934327125549\n",
      "Sample 9406 - loss: 0.7242162823677063\n",
      "Sample 9407 - loss: 1.9078054428100586\n",
      "Sample 9408 - loss: 0.7048540711402893\n",
      "Sample 9409 - loss: 2.187321424484253\n",
      "Sample 9410 - loss: 0.0399194061756134\n",
      "Sample 9411 - loss: 0.5383039712905884\n",
      "Sample 9412 - loss: 0.04663288593292236\n",
      "Sample 9413 - loss: 0.10147710144519806\n",
      "Sample 9414 - loss: 6.792944431304932\n",
      "Sample 9415 - loss: 0.14893193542957306\n",
      "Sample 9416 - loss: 0.7301420569419861\n",
      "Sample 9417 - loss: 0.06538749486207962\n",
      "Sample 9418 - loss: 1.314194679260254\n",
      "Sample 9419 - loss: 0.9157843589782715\n",
      "Sample 9420 - loss: 4.119166374206543\n",
      "Sample 9421 - loss: 3.3637235164642334\n",
      "Sample 9422 - loss: 0.08720201253890991\n",
      "Sample 9423 - loss: 0.1135958582162857\n",
      "Sample 9424 - loss: 4.067773818969727\n",
      "Sample 9425 - loss: 0.6523194909095764\n",
      "Sample 9426 - loss: 2.634117841720581\n",
      "Sample 9427 - loss: 0.31077802181243896\n",
      "Sample 9428 - loss: 0.2156417965888977\n",
      "Sample 9429 - loss: 4.365577697753906\n",
      "Sample 9430 - loss: 4.588756084442139\n",
      "Sample 9431 - loss: 5.63526725769043\n",
      "Sample 9432 - loss: 0.4447180926799774\n",
      "Sample 9433 - loss: 0.6833435297012329\n",
      "Sample 9434 - loss: 0.32595425844192505\n",
      "Sample 9435 - loss: 0.5234800577163696\n",
      "Sample 9436 - loss: 1.9138751029968262\n",
      "Sample 9437 - loss: 0.784827709197998\n",
      "Sample 9438 - loss: 0.012192899361252785\n",
      "Sample 9439 - loss: 0.5130218863487244\n",
      "Sample 9440 - loss: 2.2823009490966797\n",
      "Sample 9441 - loss: 1.6146334409713745\n",
      "Sample 9442 - loss: 0.2996710240840912\n",
      "Sample 9443 - loss: 0.052680712193250656\n",
      "Sample 9444 - loss: 2.908050298690796\n",
      "Sample 9445 - loss: 4.054320812225342\n",
      "Sample 9446 - loss: 2.0490903854370117\n",
      "Sample 9447 - loss: 0.13945315778255463\n",
      "Sample 9448 - loss: 0.06534820050001144\n",
      "Sample 9449 - loss: 0.029818721115589142\n",
      "Sample 9450 - loss: 0.31933102011680603\n",
      "Sample 9451 - loss: 2.648996591567993\n",
      "Sample 9452 - loss: 4.783968925476074\n",
      "Sample 9453 - loss: 1.3546127080917358\n",
      "Sample 9454 - loss: 0.06431212276220322\n",
      "Sample 9455 - loss: 3.1237380504608154\n",
      "Sample 9456 - loss: 0.6266592144966125\n",
      "Sample 9457 - loss: 3.614365816116333\n",
      "Sample 9458 - loss: 0.8378143310546875\n",
      "Sample 9459 - loss: 0.5535203814506531\n",
      "Sample 9460 - loss: 2.3166582584381104\n",
      "Sample 9461 - loss: 0.7258687019348145\n",
      "Sample 9462 - loss: 0.036993492394685745\n",
      "Sample 9463 - loss: 2.261573553085327\n",
      "Sample 9464 - loss: 0.08149610459804535\n",
      "Sample 9465 - loss: 0.29328587651252747\n",
      "Sample 9466 - loss: 5.558857440948486\n",
      "Sample 9467 - loss: 2.221782922744751\n",
      "Sample 9468 - loss: 0.868763267993927\n",
      "Sample 9469 - loss: 0.04191708192229271\n",
      "Sample 9470 - loss: 3.1369545459747314\n",
      "Sample 9471 - loss: 0.0862668827176094\n",
      "Sample 9472 - loss: 2.1292309761047363\n",
      "Sample 9473 - loss: 0.08588214963674545\n",
      "Sample 9474 - loss: 0.09599388390779495\n",
      "Sample 9475 - loss: 0.07514545321464539\n",
      "Sample 9476 - loss: 2.3176002502441406\n",
      "Sample 9477 - loss: 2.395286798477173\n",
      "Sample 9478 - loss: 0.9392042756080627\n",
      "Sample 9479 - loss: 0.8258320689201355\n",
      "Sample 9480 - loss: 2.5667176246643066\n",
      "Sample 9481 - loss: 3.8224475383758545\n",
      "Sample 9482 - loss: 2.3041739463806152\n",
      "Sample 9483 - loss: 0.430012047290802\n",
      "Sample 9484 - loss: 3.297931432723999\n",
      "Sample 9485 - loss: 2.834622383117676\n",
      "Sample 9486 - loss: 5.628811836242676\n",
      "Sample 9487 - loss: 1.7592588663101196\n",
      "Sample 9488 - loss: 0.07245317846536636\n",
      "Sample 9489 - loss: 0.0332629568874836\n",
      "Sample 9490 - loss: 1.1082574129104614\n",
      "Sample 9491 - loss: 4.1211323738098145\n",
      "Sample 9492 - loss: 0.0057171969674527645\n",
      "Sample 9493 - loss: 5.811140060424805\n",
      "Sample 9494 - loss: 0.0400540716946125\n",
      "Sample 9495 - loss: 0.9038949012756348\n",
      "Sample 9496 - loss: 0.2749682366847992\n",
      "Sample 9497 - loss: 0.019960911944508553\n",
      "Sample 9498 - loss: 5.538707256317139\n",
      "Sample 9499 - loss: 0.11626564711332321\n",
      "Sample 9500 - loss: 0.443846195936203\n",
      "Sample 9501 - loss: 2.9157683849334717\n",
      "Sample 9502 - loss: 0.02300702966749668\n",
      "Sample 9503 - loss: 0.1531350463628769\n",
      "Sample 9504 - loss: 6.708859920501709\n",
      "Sample 9505 - loss: 0.9136307239532471\n",
      "Sample 9506 - loss: 0.13159406185150146\n",
      "Sample 9507 - loss: 0.13082264363765717\n",
      "Sample 9508 - loss: 0.03434013947844505\n",
      "Sample 9509 - loss: 0.0032559758983552456\n",
      "Sample 9510 - loss: 0.1283988654613495\n",
      "Sample 9511 - loss: 6.5256667137146\n",
      "Sample 9512 - loss: 0.13848546147346497\n",
      "Sample 9513 - loss: 5.705381870269775\n",
      "Sample 9514 - loss: 0.08964477479457855\n",
      "Sample 9515 - loss: 0.0802321806550026\n",
      "Sample 9516 - loss: 1.4149032831192017\n",
      "Sample 9517 - loss: 1.1347192525863647\n",
      "Sample 9518 - loss: 4.6619439125061035\n",
      "Sample 9519 - loss: 4.404674053192139\n",
      "Sample 9520 - loss: 1.9663593769073486\n",
      "Sample 9521 - loss: 1.730637788772583\n",
      "Sample 9522 - loss: 0.4337906241416931\n",
      "Sample 9523 - loss: 2.0908379554748535\n",
      "Sample 9524 - loss: 4.346916198730469\n",
      "Sample 9525 - loss: 7.786665439605713\n",
      "Sample 9526 - loss: 0.6221560835838318\n",
      "Sample 9527 - loss: 0.2180536687374115\n",
      "Sample 9528 - loss: 2.6148979663848877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9529 - loss: 1.6383700370788574\n",
      "Sample 9530 - loss: 4.289965629577637\n",
      "Sample 9531 - loss: 4.154896259307861\n",
      "Sample 9532 - loss: 0.006832418031990528\n",
      "Sample 9533 - loss: 0.11893346160650253\n",
      "Sample 9534 - loss: 0.0540180578827858\n",
      "Sample 9535 - loss: 0.592068076133728\n",
      "Sample 9536 - loss: 0.4262419641017914\n",
      "Sample 9537 - loss: 0.38167527318000793\n",
      "Sample 9538 - loss: 4.654515743255615\n",
      "Sample 9539 - loss: 1.0427206754684448\n",
      "Sample 9540 - loss: 0.042907584458589554\n",
      "Sample 9541 - loss: 3.2439892292022705\n",
      "Sample 9542 - loss: 5.398022651672363\n",
      "Sample 9543 - loss: 2.971874952316284\n",
      "Sample 9544 - loss: 0.1904691457748413\n",
      "Sample 9545 - loss: 2.544367790222168\n",
      "Sample 9546 - loss: 0.04646407440304756\n",
      "Sample 9547 - loss: 2.071829319000244\n",
      "Sample 9548 - loss: 0.34550994634628296\n",
      "Sample 9549 - loss: 0.09085172414779663\n",
      "Sample 9550 - loss: 4.717578887939453\n",
      "Sample 9551 - loss: 0.17918282747268677\n",
      "Sample 9552 - loss: 2.719651460647583\n",
      "Sample 9553 - loss: 0.5952692627906799\n",
      "Sample 9554 - loss: 1.7225346565246582\n",
      "Sample 9555 - loss: 0.2582845985889435\n",
      "Sample 9556 - loss: 0.8834545016288757\n",
      "Sample 9557 - loss: 2.400858163833618\n",
      "Sample 9558 - loss: 4.451241493225098\n",
      "Sample 9559 - loss: 0.5302073955535889\n",
      "Sample 9560 - loss: 5.232199668884277\n",
      "Sample 9561 - loss: 0.11265598982572556\n",
      "Sample 9562 - loss: 0.39400672912597656\n",
      "Sample 9563 - loss: 0.10479103773832321\n",
      "Sample 9564 - loss: 1.1167584657669067\n",
      "Sample 9565 - loss: 1.1444265842437744\n",
      "Sample 9566 - loss: 1.9788836240768433\n",
      "Sample 9567 - loss: 6.7669572830200195\n",
      "Sample 9568 - loss: 1.8672105073928833\n",
      "Sample 9569 - loss: 0.7588004469871521\n",
      "Sample 9570 - loss: 0.4612940847873688\n",
      "Sample 9571 - loss: 2.7961783409118652\n",
      "Sample 9572 - loss: 0.9568943977355957\n",
      "Sample 9573 - loss: 0.9648171067237854\n",
      "Sample 9574 - loss: 3.537951946258545\n",
      "Sample 9575 - loss: 1.0049374103546143\n",
      "Sample 9576 - loss: 0.06458834558725357\n",
      "Sample 9577 - loss: 3.5940675735473633\n",
      "Sample 9578 - loss: 1.1787362098693848\n",
      "Sample 9579 - loss: 0.28042668104171753\n",
      "Sample 9580 - loss: 0.36368313431739807\n",
      "Sample 9581 - loss: 0.059738632291555405\n",
      "Sample 9582 - loss: 3.0232295989990234\n",
      "Sample 9583 - loss: 0.460480660200119\n",
      "Sample 9584 - loss: 0.6326507329940796\n",
      "Sample 9585 - loss: 0.35224494338035583\n",
      "Sample 9586 - loss: 0.22123658657073975\n",
      "Sample 9587 - loss: 1.498020887374878\n",
      "Sample 9588 - loss: 0.5880232453346252\n",
      "Sample 9589 - loss: 0.2550584077835083\n",
      "Sample 9590 - loss: 1.498470425605774\n",
      "Sample 9591 - loss: 3.5544891357421875\n",
      "Sample 9592 - loss: 0.404318630695343\n",
      "Sample 9593 - loss: 0.018465781584382057\n",
      "Sample 9594 - loss: 1.1650549173355103\n",
      "Sample 9595 - loss: 1.0154956579208374\n",
      "Sample 9596 - loss: 0.5927252769470215\n",
      "Sample 9597 - loss: 2.5662741661071777\n",
      "Sample 9598 - loss: 8.004596710205078\n",
      "Sample 9599 - loss: 0.9631202816963196\n",
      "Sample 9600 - loss: 0.10871133953332901\n",
      "Sample 9601 - loss: 0.6347948312759399\n",
      "Sample 9602 - loss: 0.12440242618322372\n",
      "Sample 9603 - loss: 4.151611328125\n",
      "Sample 9604 - loss: 2.1944658756256104\n",
      "Sample 9605 - loss: 0.08164292573928833\n",
      "Sample 9606 - loss: 3.432770013809204\n",
      "Sample 9607 - loss: 0.010070690885186195\n",
      "Sample 9608 - loss: 2.7869532108306885\n",
      "Sample 9609 - loss: 1.0250777006149292\n",
      "Sample 9610 - loss: 0.35803940892219543\n",
      "Sample 9611 - loss: 1.437662959098816\n",
      "Sample 9612 - loss: 0.47130343317985535\n",
      "Sample 9613 - loss: 1.4307959079742432\n",
      "Sample 9614 - loss: 4.192111968994141\n",
      "Sample 9615 - loss: 2.332829236984253\n",
      "Sample 9616 - loss: 1.6113280057907104\n",
      "Sample 9617 - loss: 0.5534449219703674\n",
      "Sample 9618 - loss: 0.8869006633758545\n",
      "Sample 9619 - loss: 1.0770949125289917\n",
      "Sample 9620 - loss: 1.8667248487472534\n",
      "Sample 9621 - loss: 3.668316602706909\n",
      "Sample 9622 - loss: 7.751203536987305\n",
      "Sample 9623 - loss: 3.380786657333374\n",
      "Sample 9624 - loss: 0.5392633080482483\n",
      "Sample 9625 - loss: 1.3246961832046509\n",
      "Sample 9626 - loss: 0.6527944207191467\n",
      "Sample 9627 - loss: 2.0525026321411133\n",
      "Sample 9628 - loss: 0.3411085605621338\n",
      "Sample 9629 - loss: 0.8932846188545227\n",
      "Sample 9630 - loss: 0.19241121411323547\n",
      "Sample 9631 - loss: 0.03935769945383072\n",
      "Sample 9632 - loss: 0.4090789556503296\n",
      "Sample 9633 - loss: 0.41302430629730225\n",
      "Sample 9634 - loss: 4.822123050689697\n",
      "Sample 9635 - loss: 0.07111459970474243\n",
      "Sample 9636 - loss: 0.08346469700336456\n",
      "Sample 9637 - loss: 5.24924373626709\n",
      "Sample 9638 - loss: 1.171510934829712\n",
      "Sample 9639 - loss: 3.2205474376678467\n",
      "Sample 9640 - loss: 3.935389518737793\n",
      "Sample 9641 - loss: 0.3469628095626831\n",
      "Sample 9642 - loss: 0.22425371408462524\n",
      "Sample 9643 - loss: 5.892956733703613\n",
      "Sample 9644 - loss: 0.3440493047237396\n",
      "Sample 9645 - loss: 0.11473946273326874\n",
      "Sample 9646 - loss: 0.5953090786933899\n",
      "Sample 9647 - loss: 4.853172779083252\n",
      "Sample 9648 - loss: 0.3646688759326935\n",
      "Sample 9649 - loss: 1.339676856994629\n",
      "Sample 9650 - loss: 1.1426624059677124\n",
      "Sample 9651 - loss: 3.6164519786834717\n",
      "Sample 9652 - loss: 4.980580806732178\n",
      "Sample 9653 - loss: 1.1044286489486694\n",
      "Sample 9654 - loss: 0.09406814724206924\n",
      "Sample 9655 - loss: 0.7211482524871826\n",
      "Sample 9656 - loss: 1.2207587957382202\n",
      "Sample 9657 - loss: 4.173128128051758\n",
      "Sample 9658 - loss: 2.674086093902588\n",
      "Sample 9659 - loss: 2.4432928562164307\n",
      "Sample 9660 - loss: 0.17256315052509308\n",
      "Sample 9661 - loss: 0.08742976933717728\n",
      "Sample 9662 - loss: 0.2768082320690155\n",
      "Sample 9663 - loss: 2.5913867950439453\n",
      "Sample 9664 - loss: 0.17908000946044922\n",
      "Sample 9665 - loss: 0.0062479483895003796\n",
      "Sample 9666 - loss: 0.7039141654968262\n",
      "Sample 9667 - loss: 1.3429096937179565\n",
      "Sample 9668 - loss: 3.8329226970672607\n",
      "Sample 9669 - loss: 0.0057497210800647736\n",
      "Sample 9670 - loss: 0.8858462572097778\n",
      "Sample 9671 - loss: 1.310237169265747\n",
      "Sample 9672 - loss: 0.0480823889374733\n",
      "Sample 9673 - loss: 1.8514372110366821\n",
      "Sample 9674 - loss: 6.436801910400391\n",
      "Sample 9675 - loss: 1.523287296295166\n",
      "Sample 9676 - loss: 0.9970932602882385\n",
      "Sample 9677 - loss: 0.8544564247131348\n",
      "Sample 9678 - loss: 0.9881243109703064\n",
      "Sample 9679 - loss: 4.4798903465271\n",
      "Sample 9680 - loss: 1.3401461839675903\n",
      "Sample 9681 - loss: 1.337070345878601\n",
      "Sample 9682 - loss: 0.5506806969642639\n",
      "Sample 9683 - loss: 2.4571104049682617\n",
      "Sample 9684 - loss: 0.007548506371676922\n",
      "Sample 9685 - loss: 0.195373073220253\n",
      "Sample 9686 - loss: 0.06920323520898819\n",
      "Sample 9687 - loss: 1.7960314750671387\n",
      "Sample 9688 - loss: 0.02746819332242012\n",
      "Sample 9689 - loss: 1.5457290410995483\n",
      "Sample 9690 - loss: 3.248197317123413\n",
      "Sample 9691 - loss: 0.08197521418333054\n",
      "Sample 9692 - loss: 0.11286208778619766\n",
      "Sample 9693 - loss: 1.2065536975860596\n",
      "Sample 9694 - loss: 3.6597487926483154\n",
      "Sample 9695 - loss: 0.4458461105823517\n",
      "Sample 9696 - loss: 1.1763349771499634\n",
      "Sample 9697 - loss: 0.7821862101554871\n",
      "Sample 9698 - loss: 1.5323814153671265\n",
      "Sample 9699 - loss: 0.8363496661186218\n",
      "Sample 9700 - loss: 8.419055938720703\n",
      "Sample 9701 - loss: 0.7878965735435486\n",
      "Sample 9702 - loss: 1.3445448875427246\n",
      "Sample 9703 - loss: 0.346671462059021\n",
      "Sample 9704 - loss: 0.008442817255854607\n",
      "Sample 9705 - loss: 2.2888481616973877\n",
      "Sample 9706 - loss: 1.7060210704803467\n",
      "Sample 9707 - loss: 0.6267428994178772\n",
      "Sample 9708 - loss: 1.5771970748901367\n",
      "Sample 9709 - loss: 2.107715129852295\n",
      "Sample 9710 - loss: 1.3601336479187012\n",
      "Sample 9711 - loss: 0.11810530722141266\n",
      "Sample 9712 - loss: 3.8706564903259277\n",
      "Sample 9713 - loss: 0.15049166977405548\n",
      "Sample 9714 - loss: 1.827217698097229\n",
      "Sample 9715 - loss: 0.2672823965549469\n",
      "Sample 9716 - loss: 1.1739451885223389\n",
      "Sample 9717 - loss: 0.06178182736039162\n",
      "Sample 9718 - loss: 2.4506914615631104\n",
      "Sample 9719 - loss: 1.6411125659942627\n",
      "Sample 9720 - loss: 0.039554063230752945\n",
      "Sample 9721 - loss: 0.39157721400260925\n",
      "Sample 9722 - loss: 0.021534809842705727\n",
      "Sample 9723 - loss: 0.3883039355278015\n",
      "Sample 9724 - loss: 2.6879689693450928\n",
      "Sample 9725 - loss: 0.013096697628498077\n",
      "Sample 9726 - loss: 0.031459465622901917\n",
      "Sample 9727 - loss: 2.3359427452087402\n",
      "Sample 9728 - loss: 1.7487596273422241\n",
      "Sample 9729 - loss: 0.0370853990316391\n",
      "Sample 9730 - loss: 0.19763274490833282\n",
      "Sample 9731 - loss: 0.953368067741394\n",
      "Sample 9732 - loss: 2.8928937911987305\n",
      "Sample 9733 - loss: 2.674826145172119\n",
      "Sample 9734 - loss: 3.4498093128204346\n",
      "Sample 9735 - loss: 0.4577041566371918\n",
      "Sample 9736 - loss: 3.8308324813842773\n",
      "Sample 9737 - loss: 1.0875554084777832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9738 - loss: 1.9987502098083496\n",
      "Sample 9739 - loss: 0.6327409744262695\n",
      "Sample 9740 - loss: 0.5914366245269775\n",
      "Sample 9741 - loss: 3.4085683822631836\n",
      "Sample 9742 - loss: 1.7859857082366943\n",
      "Sample 9743 - loss: 0.5874850153923035\n",
      "Sample 9744 - loss: 2.9784677028656006\n",
      "Sample 9745 - loss: 0.9802542924880981\n",
      "Sample 9746 - loss: 2.6093850135803223\n",
      "Sample 9747 - loss: 6.5703125\n",
      "Sample 9748 - loss: 0.6650115251541138\n",
      "Sample 9749 - loss: 0.030250344425439835\n",
      "Sample 9750 - loss: 1.528660774230957\n",
      "Sample 9751 - loss: 0.5486986637115479\n",
      "Sample 9752 - loss: 2.604766845703125\n",
      "Sample 9753 - loss: 0.12192040681838989\n",
      "Sample 9754 - loss: 0.24410659074783325\n",
      "Sample 9755 - loss: 2.0008347034454346\n",
      "Sample 9756 - loss: 0.27129706740379333\n",
      "Sample 9757 - loss: 0.003304262412711978\n",
      "Sample 9758 - loss: 0.5281358957290649\n",
      "Sample 9759 - loss: 0.16500535607337952\n",
      "Sample 9760 - loss: 0.9925757646560669\n",
      "Sample 9761 - loss: 2.8341991901397705\n",
      "Sample 9762 - loss: 0.4831920564174652\n",
      "Sample 9763 - loss: 0.07224812358617783\n",
      "Sample 9764 - loss: 2.671999454498291\n",
      "Sample 9765 - loss: 0.4030285179615021\n",
      "Sample 9766 - loss: 0.19693847000598907\n",
      "Sample 9767 - loss: 0.19095174968242645\n",
      "Sample 9768 - loss: 1.0109387636184692\n",
      "Sample 9769 - loss: 1.5098412036895752\n",
      "Sample 9770 - loss: 1.1105067729949951\n",
      "Sample 9771 - loss: 1.013473629951477\n",
      "Sample 9772 - loss: 0.450529009103775\n",
      "Sample 9773 - loss: 0.794319748878479\n",
      "Sample 9774 - loss: 0.616487979888916\n",
      "Sample 9775 - loss: 1.1580615043640137\n",
      "Sample 9776 - loss: 1.4831182956695557\n",
      "Sample 9777 - loss: 1.1470389366149902\n",
      "Sample 9778 - loss: 0.7057644128799438\n",
      "Sample 9779 - loss: 3.6328277587890625\n",
      "Sample 9780 - loss: 0.7454795241355896\n",
      "Sample 9781 - loss: 0.5572800040245056\n",
      "Sample 9782 - loss: 6.460682392120361\n",
      "Sample 9783 - loss: 0.24667127430438995\n",
      "Sample 9784 - loss: 0.21855440735816956\n",
      "Sample 9785 - loss: 0.1267458200454712\n",
      "Sample 9786 - loss: 3.538079261779785\n",
      "Sample 9787 - loss: 0.1250692903995514\n",
      "Sample 9788 - loss: 1.2480480670928955\n",
      "Sample 9789 - loss: 5.21011209487915\n",
      "Sample 9790 - loss: 0.1280110776424408\n",
      "Sample 9791 - loss: 0.2553171217441559\n",
      "Sample 9792 - loss: 0.12464853376150131\n",
      "Sample 9793 - loss: 0.01582440547645092\n",
      "Sample 9794 - loss: 0.28911903500556946\n",
      "Sample 9795 - loss: 0.9159520864486694\n",
      "Sample 9796 - loss: 2.559596300125122\n",
      "Sample 9797 - loss: 2.792877197265625\n",
      "Sample 9798 - loss: 0.6700792908668518\n",
      "Sample 9799 - loss: 1.9943912029266357\n",
      "Sample 9800 - loss: 1.7509173154830933\n",
      "Sample 9801 - loss: 1.547703504562378\n",
      "Sample 9802 - loss: 2.1977007389068604\n",
      "Sample 9803 - loss: 1.255630612373352\n",
      "Sample 9804 - loss: 2.990743637084961\n",
      "Sample 9805 - loss: 2.1943182945251465\n",
      "Sample 9806 - loss: 0.4345168173313141\n",
      "Sample 9807 - loss: 6.227049350738525\n",
      "Sample 9808 - loss: 0.9312707781791687\n",
      "Sample 9809 - loss: 1.069973349571228\n",
      "Sample 9810 - loss: 0.42091259360313416\n",
      "Sample 9811 - loss: 0.3307960629463196\n",
      "Sample 9812 - loss: 2.071502923965454\n",
      "Sample 9813 - loss: 0.6189714670181274\n",
      "Sample 9814 - loss: 7.18571662902832\n",
      "Sample 9815 - loss: 0.23323094844818115\n",
      "Sample 9816 - loss: 5.309046745300293\n",
      "Sample 9817 - loss: 1.170728325843811\n",
      "Sample 9818 - loss: 0.43743211030960083\n",
      "Sample 9819 - loss: 0.6966118812561035\n",
      "Sample 9820 - loss: 2.1550071239471436\n",
      "Sample 9821 - loss: 0.15488073229789734\n",
      "Sample 9822 - loss: 1.2975959777832031\n",
      "Sample 9823 - loss: 2.1556308269500732\n",
      "Sample 9824 - loss: 1.1654713153839111\n",
      "Sample 9825 - loss: 1.4209802150726318\n",
      "Sample 9826 - loss: 1.3122270107269287\n",
      "Sample 9827 - loss: 0.6786229014396667\n",
      "Sample 9828 - loss: 0.6001474261283875\n",
      "Sample 9829 - loss: 0.7163693308830261\n",
      "Sample 9830 - loss: 1.1561338901519775\n",
      "Sample 9831 - loss: 2.07613205909729\n",
      "Sample 9832 - loss: 0.15368708968162537\n",
      "Sample 9833 - loss: 0.9981338977813721\n",
      "Sample 9834 - loss: 0.042871490120887756\n",
      "Sample 9835 - loss: 0.7092168927192688\n",
      "Sample 9836 - loss: 0.5170235633850098\n",
      "Sample 9837 - loss: 1.2574087381362915\n",
      "Sample 9838 - loss: 5.042768955230713\n",
      "Sample 9839 - loss: 0.46414539217948914\n",
      "Sample 9840 - loss: 4.708793640136719\n",
      "Sample 9841 - loss: 2.2403435707092285\n",
      "Sample 9842 - loss: 0.060100048780441284\n",
      "Sample 9843 - loss: 0.17275722324848175\n",
      "Sample 9844 - loss: 0.3382866680622101\n",
      "Sample 9845 - loss: 1.5219682455062866\n",
      "Sample 9846 - loss: 1.1357216835021973\n",
      "Sample 9847 - loss: 0.2747998535633087\n",
      "Sample 9848 - loss: 2.0567493438720703\n",
      "Sample 9849 - loss: 0.07886175066232681\n",
      "Sample 9850 - loss: 2.0368008613586426\n",
      "Sample 9851 - loss: 1.5889151096343994\n",
      "Sample 9852 - loss: 0.6876268982887268\n",
      "Sample 9853 - loss: 2.388124704360962\n",
      "Sample 9854 - loss: 2.3238985538482666\n",
      "Sample 9855 - loss: 3.808438777923584\n",
      "Sample 9856 - loss: 0.40454909205436707\n",
      "Sample 9857 - loss: 6.192293643951416\n",
      "Sample 9858 - loss: 0.1167120710015297\n",
      "Sample 9859 - loss: 1.2598450183868408\n",
      "Sample 9860 - loss: 0.10338731110095978\n",
      "Sample 9861 - loss: 1.56809663772583\n",
      "Sample 9862 - loss: 0.004564299248158932\n",
      "Sample 9863 - loss: 1.464318037033081\n",
      "Sample 9864 - loss: 0.5041594505310059\n",
      "Sample 9865 - loss: 0.9373655915260315\n",
      "Sample 9866 - loss: 0.27584341168403625\n",
      "Sample 9867 - loss: 1.2686676979064941\n",
      "Sample 9868 - loss: 3.0108416080474854\n",
      "Sample 9869 - loss: 0.27315905690193176\n",
      "Sample 9870 - loss: 0.10993285477161407\n",
      "Sample 9871 - loss: 0.02268385700881481\n",
      "Sample 9872 - loss: 2.629312753677368\n",
      "Sample 9873 - loss: 1.9284511804580688\n",
      "Sample 9874 - loss: 3.428117036819458\n",
      "Sample 9875 - loss: 0.9951615929603577\n",
      "Sample 9876 - loss: 0.12846803665161133\n",
      "Sample 9877 - loss: 3.09359073638916\n",
      "Sample 9878 - loss: 1.1976985931396484\n",
      "Sample 9879 - loss: 0.8490659594535828\n",
      "Sample 9880 - loss: 0.4608103632926941\n",
      "Sample 9881 - loss: 3.5153679847717285\n",
      "Sample 9882 - loss: 0.9200039505958557\n",
      "Sample 9883 - loss: 0.9435991644859314\n",
      "Sample 9884 - loss: 0.8071901798248291\n",
      "Sample 9885 - loss: 7.839275360107422\n",
      "Sample 9886 - loss: 0.012127560563385487\n",
      "Sample 9887 - loss: 0.41921019554138184\n",
      "Sample 9888 - loss: 1.3756625652313232\n",
      "Sample 9889 - loss: 0.20625536143779755\n",
      "Sample 9890 - loss: 0.18005770444869995\n",
      "Sample 9891 - loss: 1.8009775876998901\n",
      "Sample 9892 - loss: 0.0037894784472882748\n",
      "Sample 9893 - loss: 2.7385969161987305\n",
      "Sample 9894 - loss: 4.9061102867126465\n",
      "Sample 9895 - loss: 0.17536771297454834\n",
      "Sample 9896 - loss: 1.4238537549972534\n",
      "Sample 9897 - loss: 2.1262567043304443\n",
      "Sample 9898 - loss: 1.9849026203155518\n",
      "Sample 9899 - loss: 5.334350109100342\n",
      "Sample 9900 - loss: 3.3932671546936035\n",
      "Sample 9901 - loss: 2.2083303928375244\n",
      "Sample 9902 - loss: 0.5025188326835632\n",
      "Sample 9903 - loss: 0.005704082082957029\n",
      "Sample 9904 - loss: 0.339488685131073\n",
      "Sample 9905 - loss: 0.051198810338974\n",
      "Sample 9906 - loss: 0.879088819026947\n",
      "Sample 9907 - loss: 0.5666842460632324\n",
      "Sample 9908 - loss: 0.7841290831565857\n",
      "Sample 9909 - loss: 2.155569076538086\n",
      "Sample 9910 - loss: 0.31511691212654114\n",
      "Sample 9911 - loss: 4.918640613555908\n",
      "Sample 9912 - loss: 0.03221312537789345\n",
      "Sample 9913 - loss: 1.0482604503631592\n",
      "Sample 9914 - loss: 3.1897215843200684\n",
      "Sample 9915 - loss: 6.031217575073242\n",
      "Sample 9916 - loss: 0.2934582233428955\n",
      "Sample 9917 - loss: 0.6406767964363098\n",
      "Sample 9918 - loss: 3.7819182872772217\n",
      "Sample 9919 - loss: 1.6671584844589233\n",
      "Sample 9920 - loss: 2.1113827228546143\n",
      "Sample 9921 - loss: 0.2697291970252991\n",
      "Sample 9922 - loss: 2.9000720977783203\n",
      "Sample 9923 - loss: 0.6708526611328125\n",
      "Sample 9924 - loss: 1.747817039489746\n",
      "Sample 9925 - loss: 0.839701771736145\n",
      "Sample 9926 - loss: 0.014310486614704132\n",
      "Sample 9927 - loss: 5.643548488616943\n",
      "Sample 9928 - loss: 0.1547757387161255\n",
      "Sample 9929 - loss: 1.2078596353530884\n",
      "Sample 9930 - loss: 0.034191980957984924\n",
      "Sample 9931 - loss: 0.24437874555587769\n",
      "Sample 9932 - loss: 0.4157068133354187\n",
      "Sample 9933 - loss: 1.2783842086791992\n",
      "Sample 9934 - loss: 3.5411834716796875\n",
      "Sample 9935 - loss: 1.3289185762405396\n",
      "Sample 9936 - loss: 0.46855515241622925\n",
      "Sample 9937 - loss: 0.17984159290790558\n",
      "Sample 9938 - loss: 3.5885837078094482\n",
      "Sample 9939 - loss: 0.0238651130348444\n",
      "Sample 9940 - loss: 4.513978958129883\n",
      "Sample 9941 - loss: 0.4158022403717041\n",
      "Sample 9942 - loss: 1.3888485431671143\n",
      "Sample 9943 - loss: 0.03892849385738373\n",
      "Sample 9944 - loss: 3.209113836288452\n",
      "Sample 9945 - loss: 1.274983525276184\n",
      "Sample 9946 - loss: 3.5083773136138916\n",
      "Sample 9947 - loss: 0.6806319355964661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9948 - loss: 0.07224477827548981\n",
      "Sample 9949 - loss: 3.5697896480560303\n",
      "Sample 9950 - loss: 0.08073033392429352\n",
      "Sample 9951 - loss: 1.380405306816101\n",
      "Sample 9952 - loss: 0.17938166856765747\n",
      "Sample 9953 - loss: 1.5428601503372192\n",
      "Sample 9954 - loss: 2.981410026550293\n",
      "Sample 9955 - loss: 0.20367364585399628\n",
      "Sample 9956 - loss: 0.02162029966711998\n",
      "Sample 9957 - loss: 0.2585197389125824\n",
      "Sample 9958 - loss: 0.03128225356340408\n",
      "Sample 9959 - loss: 1.0516811609268188\n",
      "Sample 9960 - loss: 0.040456198155879974\n",
      "Sample 9961 - loss: 0.32663559913635254\n",
      "Sample 9962 - loss: 1.3032159805297852\n",
      "Sample 9963 - loss: 3.136690139770508\n",
      "Sample 9964 - loss: 2.8521227836608887\n",
      "Sample 9965 - loss: 0.03657424822449684\n",
      "Sample 9966 - loss: 1.441308617591858\n",
      "Sample 9967 - loss: 0.7785777449607849\n",
      "Sample 9968 - loss: 1.7331738471984863\n",
      "Sample 9969 - loss: 0.6867347955703735\n",
      "Sample 9970 - loss: 0.010908599942922592\n",
      "Sample 9971 - loss: 2.10115385055542\n",
      "Sample 9972 - loss: 4.773292064666748\n",
      "Sample 9973 - loss: 0.3621060252189636\n",
      "Sample 9974 - loss: 2.5700745582580566\n",
      "Sample 9975 - loss: 3.0494937896728516\n",
      "Sample 9976 - loss: 0.8191841244697571\n",
      "Sample 9977 - loss: 3.195061683654785\n",
      "Sample 9978 - loss: 0.012524312362074852\n",
      "Sample 9979 - loss: 0.08238323032855988\n",
      "Sample 9980 - loss: 0.259679913520813\n",
      "Sample 9981 - loss: 0.012516448274254799\n",
      "Sample 9982 - loss: 0.19010895490646362\n",
      "Sample 9983 - loss: 3.873825788497925\n",
      "Sample 9984 - loss: 4.014765739440918\n",
      "Sample 9985 - loss: 2.751976251602173\n",
      "Sample 9986 - loss: 0.24455200135707855\n",
      "Sample 9987 - loss: 0.03144329786300659\n",
      "Sample 9988 - loss: 0.01617792248725891\n",
      "Sample 9989 - loss: 4.554385185241699\n",
      "Sample 9990 - loss: 0.2952357232570648\n",
      "Sample 9991 - loss: 2.288351535797119\n",
      "Sample 9992 - loss: 0.3704346716403961\n",
      "Sample 9993 - loss: 0.2283076047897339\n",
      "Sample 9994 - loss: 3.9462366104125977\n",
      "Sample 9995 - loss: 0.5215120911598206\n",
      "Sample 9996 - loss: 1.5056201219558716\n",
      "Sample 9997 - loss: 4.227956771850586\n",
      "Sample 9998 - loss: 1.2941641807556152\n",
      "Sample 9999 - loss: 0.07292342185974121\n",
      "Sample 10000 - loss: 1.121935248374939\n",
      "Sample 10001 - loss: 0.484068363904953\n",
      "Sample 10002 - loss: 1.0497031211853027\n",
      "Sample 10003 - loss: 1.0612492561340332\n",
      "Sample 10004 - loss: 0.11639408767223358\n",
      "Sample 10005 - loss: 1.892402172088623\n",
      "Sample 10006 - loss: 0.016282465308904648\n",
      "Sample 10007 - loss: 1.8836230039596558\n",
      "Sample 10008 - loss: 1.0025132894515991\n",
      "Sample 10009 - loss: 0.7313191890716553\n",
      "Sample 10010 - loss: 0.027229558676481247\n",
      "Sample 10011 - loss: 1.065169095993042\n",
      "Sample 10012 - loss: 3.659801721572876\n",
      "Sample 10013 - loss: 4.467784881591797\n",
      "Sample 10014 - loss: 0.2100565880537033\n",
      "Sample 10015 - loss: 1.0840861797332764\n",
      "Sample 10016 - loss: 1.6200991868972778\n",
      "Sample 10017 - loss: 0.02522924169898033\n",
      "Sample 10018 - loss: 1.0609737634658813\n",
      "Sample 10019 - loss: 1.249333143234253\n",
      "Sample 10020 - loss: 0.0913756936788559\n",
      "Sample 10021 - loss: 4.373787879943848\n",
      "Sample 10022 - loss: 4.039283275604248\n",
      "Sample 10023 - loss: 0.02994227223098278\n",
      "Sample 10024 - loss: 0.46191924810409546\n",
      "Sample 10025 - loss: 2.965683698654175\n",
      "Sample 10026 - loss: 0.680382490158081\n",
      "Sample 10027 - loss: 0.2428249716758728\n",
      "Sample 10028 - loss: 1.3834364414215088\n",
      "Sample 10029 - loss: 4.466282844543457\n",
      "Sample 10030 - loss: 0.7870728373527527\n",
      "Sample 10031 - loss: 0.6376875042915344\n",
      "Sample 10032 - loss: 1.359643578529358\n",
      "Sample 10033 - loss: 2.8122758865356445\n",
      "Sample 10034 - loss: 5.211174488067627\n",
      "Sample 10035 - loss: 3.1745736598968506\n",
      "Sample 10036 - loss: 0.854037344455719\n",
      "Sample 10037 - loss: 0.15701694786548615\n",
      "Sample 10038 - loss: 2.1647861003875732\n",
      "Sample 10039 - loss: 0.026239102706313133\n",
      "Sample 10040 - loss: 0.7798210382461548\n",
      "Sample 10041 - loss: 4.182430267333984\n",
      "Sample 10042 - loss: 1.0641919374465942\n",
      "Sample 10043 - loss: 1.9894649982452393\n",
      "Sample 10044 - loss: 1.3863147497177124\n",
      "Sample 10045 - loss: 0.84698486328125\n",
      "Sample 10046 - loss: 1.9308140277862549\n",
      "Sample 10047 - loss: 0.6281588673591614\n",
      "Sample 10048 - loss: 0.6768524050712585\n",
      "Sample 10049 - loss: 2.2663462162017822\n",
      "Sample 10050 - loss: 0.14537213742733002\n",
      "Sample 10051 - loss: 0.33173251152038574\n",
      "Sample 10052 - loss: 1.7467291355133057\n",
      "Sample 10053 - loss: 0.039131637662649155\n",
      "Sample 10054 - loss: 0.8820732831954956\n",
      "Sample 10055 - loss: 4.179075717926025\n",
      "Sample 10056 - loss: 0.32491421699523926\n",
      "Sample 10057 - loss: 0.24643610417842865\n",
      "Sample 10058 - loss: 2.181412696838379\n",
      "Sample 10059 - loss: 0.020398639142513275\n",
      "Sample 10060 - loss: 1.926498532295227\n",
      "Sample 10061 - loss: 0.697605311870575\n",
      "Sample 10062 - loss: 0.21699866652488708\n",
      "Sample 10063 - loss: 0.2001066654920578\n",
      "Sample 10064 - loss: 0.1701599657535553\n",
      "Sample 10065 - loss: 2.1479392051696777\n",
      "Sample 10066 - loss: 0.6560091376304626\n",
      "Sample 10067 - loss: 0.2831636667251587\n",
      "Sample 10068 - loss: 0.7525782585144043\n",
      "Sample 10069 - loss: 2.784999370574951\n",
      "Sample 10070 - loss: 0.0654551312327385\n",
      "Sample 10071 - loss: 1.573310136795044\n",
      "Sample 10072 - loss: 0.3148283064365387\n",
      "Sample 10073 - loss: 0.8000313639640808\n",
      "Sample 10074 - loss: 0.1296091079711914\n",
      "Sample 10075 - loss: 0.08994799852371216\n",
      "Sample 10076 - loss: 2.149996757507324\n",
      "Sample 10077 - loss: 0.02165975794196129\n",
      "Sample 10078 - loss: 2.5109708309173584\n",
      "Sample 10079 - loss: 0.8870795965194702\n",
      "Sample 10080 - loss: 0.023447567597031593\n",
      "Sample 10081 - loss: 0.30982163548469543\n",
      "Sample 10082 - loss: 0.0681609958410263\n",
      "Sample 10083 - loss: 0.18718498945236206\n",
      "Sample 10084 - loss: 1.8282065391540527\n",
      "Sample 10085 - loss: 0.047265227884054184\n",
      "Sample 10086 - loss: 2.548954486846924\n",
      "Sample 10087 - loss: 1.4485385417938232\n",
      "Sample 10088 - loss: 3.069045305252075\n",
      "Sample 10089 - loss: 0.49954840540885925\n",
      "Sample 10090 - loss: 0.22605189681053162\n",
      "Sample 10091 - loss: 1.3072985410690308\n",
      "Sample 10092 - loss: 0.8835722208023071\n",
      "Sample 10093 - loss: 1.0249236822128296\n",
      "Sample 10094 - loss: 0.3074764013290405\n",
      "Sample 10095 - loss: 0.8883897662162781\n",
      "Sample 10096 - loss: 0.0486617237329483\n",
      "Sample 10097 - loss: 0.517488420009613\n",
      "Sample 10098 - loss: 1.3330682516098022\n",
      "Sample 10099 - loss: 1.1784141063690186\n",
      "Sample 10100 - loss: 0.05875682830810547\n",
      "Sample 10101 - loss: 1.6173205375671387\n",
      "Sample 10102 - loss: 5.263970851898193\n",
      "Sample 10103 - loss: 0.074432872235775\n",
      "Sample 10104 - loss: 0.39712002873420715\n",
      "Sample 10105 - loss: 2.0913426876068115\n",
      "Sample 10106 - loss: 0.0034434988629072905\n",
      "Sample 10107 - loss: 7.777474403381348\n",
      "Sample 10108 - loss: 0.5318503379821777\n",
      "Sample 10109 - loss: 3.149268865585327\n",
      "Sample 10110 - loss: 0.6115247011184692\n",
      "Sample 10111 - loss: 0.18351174890995026\n",
      "Sample 10112 - loss: 0.4455893635749817\n",
      "Sample 10113 - loss: 0.09127198159694672\n",
      "Sample 10114 - loss: 0.018351901322603226\n",
      "Sample 10115 - loss: 5.432340145111084\n",
      "Sample 10116 - loss: 4.652998924255371\n",
      "Sample 10117 - loss: 0.5125746726989746\n",
      "Sample 10118 - loss: 3.592062473297119\n",
      "Sample 10119 - loss: 0.9652650952339172\n",
      "Sample 10120 - loss: 1.5405833721160889\n",
      "Sample 10121 - loss: 0.34452980756759644\n",
      "Sample 10122 - loss: 0.20713476836681366\n",
      "Sample 10123 - loss: 2.670564889907837\n",
      "Sample 10124 - loss: 0.24896226823329926\n",
      "Sample 10125 - loss: 1.5205910205841064\n",
      "Sample 10126 - loss: 3.906961441040039\n",
      "Sample 10127 - loss: 2.1317224502563477\n",
      "Sample 10128 - loss: 0.7821801900863647\n",
      "Sample 10129 - loss: 0.03900910168886185\n",
      "Sample 10130 - loss: 0.1109168753027916\n",
      "Sample 10131 - loss: 0.9379734992980957\n",
      "Sample 10132 - loss: 1.5761314630508423\n",
      "Sample 10133 - loss: 3.9867544174194336\n",
      "Sample 10134 - loss: 0.9588115215301514\n",
      "Sample 10135 - loss: 2.3180718421936035\n",
      "Sample 10136 - loss: 0.06916256994009018\n",
      "Sample 10137 - loss: 0.1913997232913971\n",
      "Sample 10138 - loss: 0.358031302690506\n",
      "Sample 10139 - loss: 0.07328756153583527\n",
      "Sample 10140 - loss: 0.15812402963638306\n",
      "Sample 10141 - loss: 1.9392445087432861\n",
      "Sample 10142 - loss: 0.8795354962348938\n",
      "Sample 10143 - loss: 3.423870801925659\n",
      "Sample 10144 - loss: 0.011019375175237656\n",
      "Sample 10145 - loss: 0.8397045731544495\n",
      "Sample 10146 - loss: 1.3044453859329224\n",
      "Sample 10147 - loss: 0.21587112545967102\n",
      "Sample 10148 - loss: 0.006673642434179783\n",
      "Sample 10149 - loss: 0.03676092252135277\n",
      "Sample 10150 - loss: 0.7929499745368958\n",
      "Sample 10151 - loss: 0.44804659485816956\n",
      "Sample 10152 - loss: 2.2954297065734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10153 - loss: 3.2430155277252197\n",
      "Sample 10154 - loss: 2.353184461593628\n",
      "Sample 10155 - loss: 1.6162723302841187\n",
      "Sample 10156 - loss: 0.11675313860177994\n",
      "Sample 10157 - loss: 0.31770917773246765\n",
      "Sample 10158 - loss: 4.413632392883301\n",
      "Sample 10159 - loss: 1.2218353748321533\n",
      "Sample 10160 - loss: 1.0834892988204956\n",
      "Sample 10161 - loss: 0.13566423952579498\n",
      "Sample 10162 - loss: 0.08030873537063599\n",
      "Sample 10163 - loss: 0.7169775366783142\n",
      "Sample 10164 - loss: 0.512377917766571\n",
      "Sample 10165 - loss: 0.2615449130535126\n",
      "Sample 10166 - loss: 0.04580436646938324\n",
      "Sample 10167 - loss: 1.453005313873291\n",
      "Sample 10168 - loss: 4.860811233520508\n",
      "Sample 10169 - loss: 2.2127938270568848\n",
      "Sample 10170 - loss: 0.2556341290473938\n",
      "Sample 10171 - loss: 0.5714684128761292\n",
      "Sample 10172 - loss: 1.1515109539031982\n",
      "Sample 10173 - loss: 0.35193344950675964\n",
      "Sample 10174 - loss: 0.3952837884426117\n",
      "Sample 10175 - loss: 1.2432641983032227\n",
      "Sample 10176 - loss: 0.35874009132385254\n",
      "Sample 10177 - loss: 0.2538378834724426\n",
      "Sample 10178 - loss: 0.5750958323478699\n",
      "Sample 10179 - loss: 1.7220373153686523\n",
      "Sample 10180 - loss: 0.7340575456619263\n",
      "Sample 10181 - loss: 1.2663016319274902\n",
      "Sample 10182 - loss: 0.19626478850841522\n",
      "Sample 10183 - loss: 1.8379130363464355\n",
      "Sample 10184 - loss: 0.0072730169631540775\n",
      "Sample 10185 - loss: 0.12721683084964752\n",
      "Sample 10186 - loss: 2.861842632293701\n",
      "Sample 10187 - loss: 0.021316377446055412\n",
      "Sample 10188 - loss: 2.2686476707458496\n",
      "Sample 10189 - loss: 0.3077372908592224\n",
      "Sample 10190 - loss: 1.3666107654571533\n",
      "Sample 10191 - loss: 0.21138505637645721\n",
      "Sample 10192 - loss: 0.7335968017578125\n",
      "Sample 10193 - loss: 0.8091455101966858\n",
      "Sample 10194 - loss: 0.27958688139915466\n",
      "Sample 10195 - loss: 0.6378101110458374\n",
      "Sample 10196 - loss: 1.7926604747772217\n",
      "Sample 10197 - loss: 0.3736009895801544\n",
      "Sample 10198 - loss: 1.8082281351089478\n",
      "Sample 10199 - loss: 0.11528030037879944\n",
      "Sample 10200 - loss: 0.4783931076526642\n",
      "Sample 10201 - loss: 4.153819561004639\n",
      "Sample 10202 - loss: 0.21974673867225647\n",
      "Sample 10203 - loss: 0.11282743513584137\n",
      "Sample 10204 - loss: 0.5622031688690186\n",
      "Sample 10205 - loss: 0.9918131828308105\n",
      "Sample 10206 - loss: 0.43053188920021057\n",
      "Sample 10207 - loss: 1.488362431526184\n",
      "Sample 10208 - loss: 0.4946269989013672\n",
      "Sample 10209 - loss: 2.8567545413970947\n",
      "Sample 10210 - loss: 0.8150315284729004\n",
      "Sample 10211 - loss: 0.8240644335746765\n",
      "Sample 10212 - loss: 0.23917770385742188\n",
      "Sample 10213 - loss: 0.43600741028785706\n",
      "Sample 10214 - loss: 0.4307166337966919\n",
      "Sample 10215 - loss: 0.20732101798057556\n",
      "Sample 10216 - loss: 0.6622327566146851\n",
      "Sample 10217 - loss: 1.2834569215774536\n",
      "Sample 10218 - loss: 0.12728367745876312\n",
      "Sample 10219 - loss: 0.4497639536857605\n",
      "Sample 10220 - loss: 0.13214252889156342\n",
      "Sample 10221 - loss: 4.509030818939209\n",
      "Sample 10222 - loss: 0.04214373230934143\n",
      "Sample 10223 - loss: 2.093122959136963\n",
      "Sample 10224 - loss: 0.46282222867012024\n",
      "Sample 10225 - loss: 0.019898952916264534\n",
      "Sample 10226 - loss: 0.2237885445356369\n",
      "Sample 10227 - loss: 0.1522124856710434\n",
      "Sample 10228 - loss: 1.5339691638946533\n",
      "Sample 10229 - loss: 1.9686493873596191\n",
      "Sample 10230 - loss: 2.30120587348938\n",
      "Sample 10231 - loss: 1.8814728260040283\n",
      "Sample 10232 - loss: 1.270783543586731\n",
      "Sample 10233 - loss: 0.044259730726480484\n",
      "Sample 10234 - loss: 2.3229732513427734\n",
      "Sample 10235 - loss: 6.230245590209961\n",
      "Sample 10236 - loss: 2.5156261920928955\n",
      "Sample 10237 - loss: 0.11494496464729309\n",
      "Sample 10238 - loss: 0.31214964389801025\n",
      "Sample 10239 - loss: 4.411996364593506\n",
      "Sample 10240 - loss: 3.547172784805298\n",
      "Sample 10241 - loss: 3.720895290374756\n",
      "Sample 10242 - loss: 1.5805796384811401\n",
      "Sample 10243 - loss: 0.08102822303771973\n",
      "Sample 10244 - loss: 2.831500768661499\n",
      "Sample 10245 - loss: 0.038366056978702545\n",
      "Sample 10246 - loss: 0.9856755137443542\n",
      "Sample 10247 - loss: 0.10514208674430847\n",
      "Sample 10248 - loss: 3.2497305870056152\n",
      "Sample 10249 - loss: 2.8362619876861572\n",
      "Sample 10250 - loss: 1.1288323402404785\n",
      "Sample 10251 - loss: 1.8661651611328125\n",
      "Sample 10252 - loss: 3.2504470348358154\n",
      "Sample 10253 - loss: 4.607362270355225\n",
      "Sample 10254 - loss: 2.375915288925171\n",
      "Sample 10255 - loss: 1.1773066520690918\n",
      "Sample 10256 - loss: 4.341117858886719\n",
      "Sample 10257 - loss: 0.030416840687394142\n",
      "Sample 10258 - loss: 1.85539972782135\n",
      "Sample 10259 - loss: 0.09829337149858475\n",
      "Sample 10260 - loss: 0.9889625310897827\n",
      "Sample 10261 - loss: 1.5870791673660278\n",
      "Sample 10262 - loss: 0.14672188460826874\n",
      "Sample 10263 - loss: 9.33795166015625\n",
      "Sample 10264 - loss: 3.994631290435791\n",
      "Sample 10265 - loss: 0.01259105559438467\n",
      "Sample 10266 - loss: 0.5369570851325989\n",
      "Sample 10267 - loss: 0.2918434739112854\n",
      "Sample 10268 - loss: 1.1773464679718018\n",
      "Sample 10269 - loss: 2.538515329360962\n",
      "Sample 10270 - loss: 0.9511699080467224\n",
      "Sample 10271 - loss: 1.7476928234100342\n",
      "Sample 10272 - loss: 2.3756613731384277\n",
      "Sample 10273 - loss: 1.491487741470337\n",
      "Sample 10274 - loss: 3.12162446975708\n",
      "Sample 10275 - loss: 0.535301923751831\n",
      "Sample 10276 - loss: 0.0025862432084977627\n",
      "Sample 10277 - loss: 0.39689359068870544\n",
      "Sample 10278 - loss: 4.362887382507324\n",
      "Sample 10279 - loss: 2.7594611644744873\n",
      "Sample 10280 - loss: 0.5703471302986145\n",
      "Sample 10281 - loss: 0.013584461063146591\n",
      "Sample 10282 - loss: 3.195711135864258\n",
      "Sample 10283 - loss: 0.06241052970290184\n",
      "Sample 10284 - loss: 0.013470806181430817\n",
      "Sample 10285 - loss: 2.1157631874084473\n",
      "Sample 10286 - loss: 2.758941888809204\n",
      "Sample 10287 - loss: 1.1680214405059814\n",
      "Sample 10288 - loss: 0.3595823347568512\n",
      "Sample 10289 - loss: 0.12381348013877869\n",
      "Sample 10290 - loss: 0.024260105565190315\n",
      "Sample 10291 - loss: 0.17093731462955475\n",
      "Sample 10292 - loss: 5.7939453125\n",
      "Sample 10293 - loss: 2.5093491077423096\n",
      "Sample 10294 - loss: 6.021466255187988\n",
      "Sample 10295 - loss: 2.4148964881896973\n",
      "Sample 10296 - loss: 2.1584300994873047\n",
      "Sample 10297 - loss: 1.1254650354385376\n",
      "Sample 10298 - loss: 1.0864176750183105\n",
      "Sample 10299 - loss: 0.43882256746292114\n",
      "Sample 10300 - loss: 2.149909019470215\n",
      "Sample 10301 - loss: 1.5663366317749023\n",
      "Sample 10302 - loss: 0.1393107920885086\n",
      "Sample 10303 - loss: 0.9916262626647949\n",
      "Sample 10304 - loss: 0.8417741656303406\n",
      "Sample 10305 - loss: 1.4543462991714478\n",
      "Sample 10306 - loss: 2.410745620727539\n",
      "Sample 10307 - loss: 1.385054588317871\n",
      "Sample 10308 - loss: 0.4135936498641968\n",
      "Sample 10309 - loss: 0.1255580186843872\n",
      "Sample 10310 - loss: 1.002716302871704\n",
      "Sample 10311 - loss: 3.186502456665039\n",
      "Sample 10312 - loss: 0.09529310464859009\n",
      "Sample 10313 - loss: 4.823513984680176\n",
      "Sample 10314 - loss: 0.4420475363731384\n",
      "Sample 10315 - loss: 0.0889335349202156\n",
      "Sample 10316 - loss: 0.6896952986717224\n",
      "Sample 10317 - loss: 6.175617218017578\n",
      "Sample 10318 - loss: 2.7275171279907227\n",
      "Sample 10319 - loss: 0.24858501553535461\n",
      "Sample 10320 - loss: 0.25826844573020935\n",
      "Sample 10321 - loss: 0.153593510389328\n",
      "Sample 10322 - loss: 0.1875087022781372\n",
      "Sample 10323 - loss: 0.6718966960906982\n",
      "Sample 10324 - loss: 1.1545569896697998\n",
      "Sample 10325 - loss: 0.00720610935240984\n",
      "Sample 10326 - loss: 1.9104324579238892\n",
      "Sample 10327 - loss: 0.19646643102169037\n",
      "Sample 10328 - loss: 3.9987549781799316\n",
      "Sample 10329 - loss: 0.11110435426235199\n",
      "Sample 10330 - loss: 4.017236709594727\n",
      "Sample 10331 - loss: 2.77244234085083\n",
      "Sample 10332 - loss: 2.6020467281341553\n",
      "Sample 10333 - loss: 1.348117709159851\n",
      "Sample 10334 - loss: 0.049736496061086655\n",
      "Sample 10335 - loss: 0.6619428992271423\n",
      "Sample 10336 - loss: 0.8539091348648071\n",
      "Sample 10337 - loss: 3.07035756111145\n",
      "Sample 10338 - loss: 0.29620400071144104\n",
      "Sample 10339 - loss: 1.35374116897583\n",
      "Sample 10340 - loss: 0.8502717614173889\n",
      "Sample 10341 - loss: 0.23378367722034454\n",
      "Sample 10342 - loss: 3.5225493907928467\n",
      "Sample 10343 - loss: 1.1690517663955688\n",
      "Sample 10344 - loss: 0.15314309298992157\n",
      "Sample 10345 - loss: 0.6895828247070312\n",
      "Sample 10346 - loss: 2.359562635421753\n",
      "Sample 10347 - loss: 0.07522910833358765\n",
      "Sample 10348 - loss: 1.2572598457336426\n",
      "Sample 10349 - loss: 3.081869602203369\n",
      "Sample 10350 - loss: 0.27370956540107727\n",
      "Sample 10351 - loss: 0.7093026041984558\n",
      "Sample 10352 - loss: 0.5215139985084534\n",
      "Sample 10353 - loss: 0.013861733488738537\n",
      "Sample 10354 - loss: 0.24993379414081573\n",
      "Sample 10355 - loss: 4.128866672515869\n",
      "Sample 10356 - loss: 0.7387861609458923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10357 - loss: 1.2087602615356445\n",
      "Sample 10358 - loss: 0.8613163828849792\n",
      "Sample 10359 - loss: 3.4094583988189697\n",
      "Sample 10360 - loss: 0.0557747520506382\n",
      "Sample 10361 - loss: 0.3320407569408417\n",
      "Sample 10362 - loss: 0.015768717974424362\n",
      "Sample 10363 - loss: 1.9746967554092407\n",
      "Sample 10364 - loss: 1.903222680091858\n",
      "Sample 10365 - loss: 2.443389415740967\n",
      "Sample 10366 - loss: 2.0293521881103516\n",
      "Sample 10367 - loss: 0.1627223789691925\n",
      "Sample 10368 - loss: 3.8188371658325195\n",
      "Sample 10369 - loss: 0.0023246523924171925\n",
      "Sample 10370 - loss: 3.9760923385620117\n",
      "Sample 10371 - loss: 1.598594307899475\n",
      "Sample 10372 - loss: 1.4885388612747192\n",
      "Sample 10373 - loss: 0.6832050085067749\n",
      "Sample 10374 - loss: 3.8473827838897705\n",
      "Sample 10375 - loss: 1.6314548254013062\n",
      "Sample 10376 - loss: 0.8175871968269348\n",
      "Sample 10377 - loss: 0.2650606632232666\n",
      "Sample 10378 - loss: 3.044919490814209\n",
      "Sample 10379 - loss: 0.05481642857193947\n",
      "Sample 10380 - loss: 0.12071195244789124\n",
      "Sample 10381 - loss: 0.10078160464763641\n",
      "Sample 10382 - loss: 0.9898373484611511\n",
      "Sample 10383 - loss: 2.155942440032959\n",
      "Sample 10384 - loss: 0.5083935260772705\n",
      "Sample 10385 - loss: 1.6835864782333374\n",
      "Sample 10386 - loss: 4.367542266845703\n",
      "Sample 10387 - loss: 3.897486686706543\n",
      "Sample 10388 - loss: 0.10860252380371094\n",
      "Sample 10389 - loss: 2.266794443130493\n",
      "Sample 10390 - loss: 0.058312080800533295\n",
      "Sample 10391 - loss: 0.09966924041509628\n",
      "Sample 10392 - loss: 0.9031164646148682\n",
      "Sample 10393 - loss: 0.6184845566749573\n",
      "Sample 10394 - loss: 0.22926165163516998\n",
      "Sample 10395 - loss: 5.382411956787109\n",
      "Sample 10396 - loss: 0.2729451060295105\n",
      "Sample 10397 - loss: 1.7241019010543823\n",
      "Sample 10398 - loss: 4.313384056091309\n",
      "Sample 10399 - loss: 2.83644437789917\n",
      "Sample 10400 - loss: 0.8432031869888306\n",
      "Sample 10401 - loss: 1.825422763824463\n",
      "Sample 10402 - loss: 1.9015122652053833\n",
      "Sample 10403 - loss: 0.1607692539691925\n",
      "Sample 10404 - loss: 1.760884404182434\n",
      "Sample 10405 - loss: 0.02905268408358097\n",
      "Sample 10406 - loss: 0.14564479887485504\n",
      "Sample 10407 - loss: 2.0343947410583496\n",
      "Sample 10408 - loss: 3.7346105575561523\n",
      "Sample 10409 - loss: 2.4461278915405273\n",
      "Sample 10410 - loss: 2.3994760513305664\n",
      "Sample 10411 - loss: 0.0849536880850792\n",
      "Sample 10412 - loss: 1.1237105131149292\n",
      "Sample 10413 - loss: 1.4880491495132446\n",
      "Sample 10414 - loss: 0.007720570079982281\n",
      "Sample 10415 - loss: 0.657784104347229\n",
      "Sample 10416 - loss: 0.8440592288970947\n",
      "Sample 10417 - loss: 0.04371780529618263\n",
      "Sample 10418 - loss: 3.449403762817383\n",
      "Sample 10419 - loss: 1.698330283164978\n",
      "Sample 10420 - loss: 0.024285588413476944\n",
      "Sample 10421 - loss: 0.04691202566027641\n",
      "Sample 10422 - loss: 3.5922608375549316\n",
      "Sample 10423 - loss: 0.3120191693305969\n",
      "Sample 10424 - loss: 0.27593228220939636\n",
      "Sample 10425 - loss: 0.02547510340809822\n",
      "Sample 10426 - loss: 0.3397983908653259\n",
      "Sample 10427 - loss: 0.677661120891571\n",
      "Sample 10428 - loss: 2.2957494258880615\n",
      "Sample 10429 - loss: 0.19459085166454315\n",
      "Sample 10430 - loss: 0.17465557157993317\n",
      "Sample 10431 - loss: 0.03938170149922371\n",
      "Sample 10432 - loss: 0.9926555156707764\n",
      "Sample 10433 - loss: 0.34479740262031555\n",
      "Sample 10434 - loss: 2.1049704551696777\n",
      "Sample 10435 - loss: 2.379387140274048\n",
      "Sample 10436 - loss: 0.10225901007652283\n",
      "Sample 10437 - loss: 0.24721910059452057\n",
      "Sample 10438 - loss: 0.8824563026428223\n",
      "Sample 10439 - loss: 1.6560194492340088\n",
      "Sample 10440 - loss: 1.107398509979248\n",
      "Sample 10441 - loss: 0.14725983142852783\n",
      "Sample 10442 - loss: 0.036772917956113815\n",
      "Sample 10443 - loss: 2.5392956733703613\n",
      "Sample 10444 - loss: 0.8454833030700684\n",
      "Sample 10445 - loss: 0.3465946614742279\n",
      "Sample 10446 - loss: 1.912049412727356\n",
      "Sample 10447 - loss: 1.416609287261963\n",
      "Sample 10448 - loss: 0.15144672989845276\n",
      "Sample 10449 - loss: 0.007025836501270533\n",
      "Sample 10450 - loss: 1.5617437362670898\n",
      "Sample 10451 - loss: 0.42104724049568176\n",
      "Sample 10452 - loss: 0.9494307041168213\n",
      "Sample 10453 - loss: 1.4508944749832153\n",
      "Sample 10454 - loss: 2.3664908409118652\n",
      "Sample 10455 - loss: 0.44564828276634216\n",
      "Sample 10456 - loss: 0.8829882740974426\n",
      "Sample 10457 - loss: 0.005486717447638512\n",
      "Sample 10458 - loss: 1.9145010709762573\n",
      "Sample 10459 - loss: 0.7839661240577698\n",
      "Sample 10460 - loss: 0.9131929278373718\n",
      "Sample 10461 - loss: 2.7083520889282227\n",
      "Sample 10462 - loss: 3.929154396057129\n",
      "Sample 10463 - loss: 0.15628564357757568\n",
      "Sample 10464 - loss: 0.4127841293811798\n",
      "Sample 10465 - loss: 0.5254399180412292\n",
      "Sample 10466 - loss: 1.0818185806274414\n",
      "Sample 10467 - loss: 0.1950618177652359\n",
      "Sample 10468 - loss: 2.0951905250549316\n",
      "Sample 10469 - loss: 1.9324017763137817\n",
      "Sample 10470 - loss: 1.4465703964233398\n",
      "Sample 10471 - loss: 0.006128653418272734\n",
      "Sample 10472 - loss: 2.4187395572662354\n",
      "Sample 10473 - loss: 1.381475806236267\n",
      "Sample 10474 - loss: 0.15233105421066284\n",
      "Sample 10475 - loss: 0.5747156739234924\n",
      "Sample 10476 - loss: 1.7788662910461426\n",
      "Sample 10477 - loss: 0.2653476893901825\n",
      "Sample 10478 - loss: 0.44685599207878113\n",
      "Sample 10479 - loss: 0.4499025046825409\n",
      "Sample 10480 - loss: 0.6352965831756592\n",
      "Sample 10481 - loss: 0.13942888379096985\n",
      "Sample 10482 - loss: 0.6478994488716125\n",
      "Sample 10483 - loss: 0.51340252161026\n",
      "Sample 10484 - loss: 2.862821102142334\n",
      "Sample 10485 - loss: 0.7361325025558472\n",
      "Sample 10486 - loss: 3.7765309810638428\n",
      "Sample 10487 - loss: 0.023009132593870163\n",
      "Sample 10488 - loss: 0.12356489896774292\n",
      "Sample 10489 - loss: 0.630239725112915\n",
      "Sample 10490 - loss: 3.803906202316284\n",
      "Sample 10491 - loss: 0.011950630694627762\n",
      "Sample 10492 - loss: 2.4837849140167236\n",
      "Sample 10493 - loss: 0.1696345955133438\n",
      "Sample 10494 - loss: 0.42575153708457947\n",
      "Sample 10495 - loss: 1.1416298151016235\n",
      "Sample 10496 - loss: 4.407392501831055\n",
      "Sample 10497 - loss: 0.15602976083755493\n",
      "Sample 10498 - loss: 5.241851806640625\n",
      "Sample 10499 - loss: 1.0823893547058105\n",
      "Sample 10500 - loss: 2.282308578491211\n",
      "Sample 10501 - loss: 0.9842717051506042\n",
      "Sample 10502 - loss: 0.018869932740926743\n",
      "Sample 10503 - loss: 0.2792244255542755\n",
      "Sample 10504 - loss: 0.9601734280586243\n",
      "Sample 10505 - loss: 2.3507893085479736\n",
      "Sample 10506 - loss: 5.867199897766113\n",
      "Sample 10507 - loss: 0.03683268278837204\n",
      "Sample 10508 - loss: 0.07005216181278229\n",
      "Sample 10509 - loss: 2.2244791984558105\n",
      "Sample 10510 - loss: 2.0235140323638916\n",
      "Sample 10511 - loss: 1.0336235761642456\n",
      "Sample 10512 - loss: 3.007296085357666\n",
      "Sample 10513 - loss: 0.053572334349155426\n",
      "Sample 10514 - loss: 3.665165424346924\n",
      "Sample 10515 - loss: 0.7688542008399963\n",
      "Sample 10516 - loss: 3.5224967002868652\n",
      "Sample 10517 - loss: 0.4360560476779938\n",
      "Sample 10518 - loss: 0.3363257646560669\n",
      "Sample 10519 - loss: 0.48658353090286255\n",
      "Sample 10520 - loss: 2.821685552597046\n",
      "Sample 10521 - loss: 0.19822585582733154\n",
      "Sample 10522 - loss: 2.0831987857818604\n",
      "Sample 10523 - loss: 1.279488444328308\n",
      "Sample 10524 - loss: 1.690545916557312\n",
      "Sample 10525 - loss: 0.4855496287345886\n",
      "Sample 10526 - loss: 0.005307413171976805\n",
      "Sample 10527 - loss: 0.009474271908402443\n",
      "Sample 10528 - loss: 0.47239920496940613\n",
      "Sample 10529 - loss: 2.197584629058838\n",
      "Sample 10530 - loss: 0.16708938777446747\n",
      "Sample 10531 - loss: 1.6131051778793335\n",
      "Sample 10532 - loss: 0.49658203125\n",
      "Sample 10533 - loss: 1.8548377752304077\n",
      "Sample 10534 - loss: 1.0213613510131836\n",
      "Sample 10535 - loss: 1.0313246250152588\n",
      "Sample 10536 - loss: 3.121612787246704\n",
      "Sample 10537 - loss: 0.019535670056939125\n",
      "Sample 10538 - loss: 0.4783037602901459\n",
      "Sample 10539 - loss: 1.93798828125\n",
      "Sample 10540 - loss: 2.293949842453003\n",
      "Sample 10541 - loss: 2.5509467124938965\n",
      "Sample 10542 - loss: 0.19095933437347412\n",
      "Sample 10543 - loss: 0.9316383600234985\n",
      "Sample 10544 - loss: 0.18131978809833527\n",
      "Sample 10545 - loss: 0.011955621652305126\n",
      "Sample 10546 - loss: 0.16916583478450775\n",
      "Sample 10547 - loss: 0.8751111626625061\n",
      "Sample 10548 - loss: 0.0955466479063034\n",
      "Sample 10549 - loss: 0.7159774303436279\n",
      "Sample 10550 - loss: 3.0698587894439697\n",
      "Sample 10551 - loss: 0.06125302240252495\n",
      "Sample 10552 - loss: 0.22669094800949097\n",
      "Sample 10553 - loss: 0.6930578351020813\n",
      "Sample 10554 - loss: 0.16691404581069946\n",
      "Sample 10555 - loss: 3.4018161296844482\n",
      "Sample 10556 - loss: 1.1849379539489746\n",
      "Sample 10557 - loss: 5.68658447265625\n",
      "Sample 10558 - loss: 0.34891995787620544\n",
      "Sample 10559 - loss: 1.4405510425567627\n",
      "Sample 10560 - loss: 2.8575069904327393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10561 - loss: 2.158703565597534\n",
      "Sample 10562 - loss: 3.0017659664154053\n",
      "Sample 10563 - loss: 0.37379100918769836\n",
      "Sample 10564 - loss: 0.5959801077842712\n",
      "Sample 10565 - loss: 1.9244178533554077\n",
      "Sample 10566 - loss: 0.5556574463844299\n",
      "Sample 10567 - loss: 0.7098726034164429\n",
      "Sample 10568 - loss: 1.8580187559127808\n",
      "Sample 10569 - loss: 1.2468284368515015\n",
      "Sample 10570 - loss: 2.662393569946289\n",
      "Sample 10571 - loss: 0.1666599065065384\n",
      "Sample 10572 - loss: 0.032896023243665695\n",
      "Sample 10573 - loss: 1.4708008766174316\n",
      "Sample 10574 - loss: 2.685337543487549\n",
      "Sample 10575 - loss: 0.4815690517425537\n",
      "Sample 10576 - loss: 5.146152973175049\n",
      "Sample 10577 - loss: 0.10487287491559982\n",
      "Sample 10578 - loss: 0.20586301386356354\n",
      "Sample 10579 - loss: 5.839280605316162\n",
      "Sample 10580 - loss: 6.296014308929443\n",
      "Sample 10581 - loss: 3.0603652000427246\n",
      "Sample 10582 - loss: 0.16756784915924072\n",
      "Sample 10583 - loss: 1.3423411846160889\n",
      "Sample 10584 - loss: 0.8768627643585205\n",
      "Sample 10585 - loss: 0.4984961748123169\n",
      "Sample 10586 - loss: 5.529647350311279\n",
      "Sample 10587 - loss: 0.21416541934013367\n",
      "Sample 10588 - loss: 0.016544828191399574\n",
      "Sample 10589 - loss: 0.19563797116279602\n",
      "Sample 10590 - loss: 4.434032440185547\n",
      "Sample 10591 - loss: 0.8738853931427002\n",
      "Sample 10592 - loss: 0.4171086251735687\n",
      "Sample 10593 - loss: 0.04364817589521408\n",
      "Sample 10594 - loss: 4.098383903503418\n",
      "Sample 10595 - loss: 2.8235528469085693\n",
      "Sample 10596 - loss: 0.17902351915836334\n",
      "Sample 10597 - loss: 0.1695433259010315\n",
      "Sample 10598 - loss: 2.1395092010498047\n",
      "Sample 10599 - loss: 1.0626220703125\n",
      "Sample 10600 - loss: 1.0706555843353271\n",
      "Sample 10601 - loss: 0.1392386257648468\n",
      "Sample 10602 - loss: 1.3856343030929565\n",
      "Sample 10603 - loss: 2.054365634918213\n",
      "Sample 10604 - loss: 0.9634265303611755\n",
      "Sample 10605 - loss: 1.956467628479004\n",
      "Sample 10606 - loss: 2.098867893218994\n",
      "Sample 10607 - loss: 3.7498462200164795\n",
      "Sample 10608 - loss: 0.17776569724082947\n",
      "Sample 10609 - loss: 3.530686378479004\n",
      "Sample 10610 - loss: 1.378397822380066\n",
      "Sample 10611 - loss: 0.1744108647108078\n",
      "Sample 10612 - loss: 0.3499206304550171\n",
      "Sample 10613 - loss: 0.16724587976932526\n",
      "Sample 10614 - loss: 0.4558945596218109\n",
      "Sample 10615 - loss: 0.25879496335983276\n",
      "Sample 10616 - loss: 1.6286755800247192\n",
      "Sample 10617 - loss: 0.010485858656466007\n",
      "Sample 10618 - loss: 0.08460446447134018\n",
      "Sample 10619 - loss: 0.0962139144539833\n",
      "Sample 10620 - loss: 0.9918800592422485\n",
      "Sample 10621 - loss: 0.9195411801338196\n",
      "Sample 10622 - loss: 0.44040459394454956\n",
      "Sample 10623 - loss: 0.9617292284965515\n",
      "Sample 10624 - loss: 0.0839308351278305\n",
      "Sample 10625 - loss: 1.708412528038025\n",
      "Sample 10626 - loss: 0.7723824381828308\n",
      "Sample 10627 - loss: 0.05070843547582626\n",
      "Sample 10628 - loss: 0.2524876296520233\n",
      "Sample 10629 - loss: 1.0428262948989868\n",
      "Sample 10630 - loss: 1.0948703289031982\n",
      "Sample 10631 - loss: 2.460815191268921\n",
      "Sample 10632 - loss: 2.3299312591552734\n",
      "Sample 10633 - loss: 0.006598568521440029\n",
      "Sample 10634 - loss: 0.049762483686208725\n",
      "Sample 10635 - loss: 2.6467928886413574\n",
      "Sample 10636 - loss: 2.318411350250244\n",
      "Sample 10637 - loss: 0.5080070495605469\n",
      "Sample 10638 - loss: 0.2191144973039627\n",
      "Sample 10639 - loss: 2.9313037395477295\n",
      "Sample 10640 - loss: 4.295694828033447\n",
      "Sample 10641 - loss: 0.37406909465789795\n",
      "Sample 10642 - loss: 3.909353256225586\n",
      "Sample 10643 - loss: 1.2470604181289673\n",
      "Sample 10644 - loss: 0.2295922487974167\n",
      "Sample 10645 - loss: 4.3450117111206055\n",
      "Sample 10646 - loss: 0.25441399216651917\n",
      "Sample 10647 - loss: 0.5003971457481384\n",
      "Sample 10648 - loss: 3.6069045066833496\n",
      "Sample 10649 - loss: 3.085557222366333\n",
      "Sample 10650 - loss: 1.7255773544311523\n",
      "Sample 10651 - loss: 0.5957460403442383\n",
      "Sample 10652 - loss: 0.6543946862220764\n",
      "Sample 10653 - loss: 0.8060076832771301\n",
      "Sample 10654 - loss: 0.1182137280702591\n",
      "Sample 10655 - loss: 4.319829940795898\n",
      "Sample 10656 - loss: 0.7880372405052185\n",
      "Sample 10657 - loss: 0.2816765606403351\n",
      "Sample 10658 - loss: 0.3701847195625305\n",
      "Sample 10659 - loss: 3.6377713680267334\n",
      "Sample 10660 - loss: 0.178146094083786\n",
      "Sample 10661 - loss: 0.04427368566393852\n",
      "Sample 10662 - loss: 0.7524300217628479\n",
      "Sample 10663 - loss: 3.3112845420837402\n",
      "Sample 10664 - loss: 0.29549354314804077\n",
      "Sample 10665 - loss: 4.275969982147217\n",
      "Sample 10666 - loss: 2.618112802505493\n",
      "Sample 10667 - loss: 0.8263906240463257\n",
      "Sample 10668 - loss: 0.09607832133769989\n",
      "Sample 10669 - loss: 2.2091004848480225\n",
      "Sample 10670 - loss: 1.7333163022994995\n",
      "Sample 10671 - loss: 2.5915791988372803\n",
      "Sample 10672 - loss: 0.041608091443777084\n",
      "Sample 10673 - loss: 1.094130039215088\n",
      "Sample 10674 - loss: 1.8460745811462402\n",
      "Sample 10675 - loss: 0.8010821342468262\n",
      "Sample 10676 - loss: 0.34012743830680847\n",
      "Sample 10677 - loss: 0.32053419947624207\n",
      "Sample 10678 - loss: 0.3745720684528351\n",
      "Sample 10679 - loss: 0.693378746509552\n",
      "Sample 10680 - loss: 0.027658360078930855\n",
      "Sample 10681 - loss: 1.5227103233337402\n",
      "Sample 10682 - loss: 0.9040778875350952\n",
      "Sample 10683 - loss: 0.25299203395843506\n",
      "Sample 10684 - loss: 0.23153327405452728\n",
      "Sample 10685 - loss: 0.10113093256950378\n",
      "Sample 10686 - loss: 1.618681788444519\n",
      "Sample 10687 - loss: 2.528970718383789\n",
      "Sample 10688 - loss: 1.3096089363098145\n",
      "Sample 10689 - loss: 0.9968027472496033\n",
      "Sample 10690 - loss: 0.19512443244457245\n",
      "Sample 10691 - loss: 0.9062660336494446\n",
      "Sample 10692 - loss: 2.988022565841675\n",
      "Sample 10693 - loss: 0.8245065808296204\n",
      "Sample 10694 - loss: 1.8704121112823486\n",
      "Sample 10695 - loss: 0.7647882699966431\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-63343eafe00b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mlr2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     }\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrads_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdater\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sample {} - loss: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\chatbot\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "SAMPLES = 50000\n",
    "X_val = np.expand_dims(np.linspace(-5,5,100), axis=-1)\n",
    "loss_history = []\n",
    "\n",
    "for i in range(SAMPLES):\n",
    "    a = np.random.uniform(0.1, 5)\n",
    "    b = np.random.uniform(0, 2*np.pi)\n",
    "    X_train = np.random.uniform(-5,5, size=(20,1))\n",
    "    Y_train = a * np.sin(X_train + b)\n",
    "    Y_val = a * np.sin(X_val + b)\n",
    "    feed_dict = {\n",
    "        x_train: X_train,\n",
    "        x_val: X_val,\n",
    "        y_train: Y_train,\n",
    "        y_val: Y_val,\n",
    "        lr1: 1e-4,\n",
    "        lr2: 5e-4    \n",
    "    }\n",
    "    grads, losses, _, show_loss = sess.run([grads_col, losses_col, updater, loss], feed_dict=feed_dict)\n",
    "    loss_history.append(show_loss)\n",
    "    print('Sample {} - loss: {}'.format(i, show_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP4boYmqykqYlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29ed16342e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.uniform(0.1, 5)\n",
    "b = np.random.uniform(0, 2*np.pi)\n",
    "X_train = np.random.uniform(-5,5, size=(20,1))\n",
    "Y_train = a * np.sin(X_train + b)\n",
    "Y_val = a * np.sin(X_val + b)\n",
    "feed_dict = {\n",
    "    x_train: X_train,\n",
    "    x_val: X_val,\n",
    "    y_train: Y_train,\n",
    "    y_val: Y_val,\n",
    "    lr1: 1e-4,\n",
    "    lr2:1e-3\n",
    "}\n",
    "grad, w0, y = sess.run([grads_col, new_weights[0], hidden], feed_dict=feed_dict)\n",
    "plt.scatter(X_train, Y_train)\n",
    "plt.plot(X_val, Y_val)\n",
    "plt.plot(X_val, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chatbot]",
   "language": "python",
   "name": "conda-env-chatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
